package core

import (
	"crypto/md5"
	"encoding/hex"
	"fmt"
	"net/url"
	"sort"
	"strings"
	"sync"
)

// URLPatternLimiter URLæ¨¡å¼é™æµå™¨
// é™åˆ¶ç›¸åŒURLæ¨¡å¼çš„çˆ¬å–æ•°é‡ï¼Œé¿å…èµ„æºæµªè´¹
type URLPatternLimiter struct {
	mutex sync.RWMutex
	
	// URLæ¨¡å¼åˆ°çˆ¬å–æ¬¡æ•°çš„æ˜ å°„
	patternCounts map[string]int
	
	// URLæ¨¡å¼çš„è¯¦ç»†ä¿¡æ¯
	patternInfo map[string]*PatternLimitInfo
	
	// é…ç½®
	config PatternLimiterConfig
	
	// ç»Ÿè®¡
	stats LimiterStats
}

// PatternLimitInfo æ¨¡å¼é™æµä¿¡æ¯
type PatternLimitInfo struct {
	Pattern      string   // URLæ¨¡å¼ï¼ˆä¾‹å¦‚ï¼š/product.php?id=ï¼‰
	CrawledURLs  []string // å·²çˆ¬å–çš„URLåˆ—è¡¨ï¼ˆé‡‡æ ·ï¼‰
	SkippedCount int      // è·³è¿‡çš„URLæ•°é‡
	FirstURL     string   // ç¬¬ä¸€ä¸ªURL
	Hash         string   // æ¨¡å¼hash
}

// PatternLimiterConfig æ¨¡å¼é™æµå™¨é…ç½®
type PatternLimiterConfig struct {
	// ç›¸åŒæ¨¡å¼URLçš„æœ€å¤§çˆ¬å–æ•°é‡ï¼ˆ0è¡¨ç¤ºä¸é™åˆ¶ï¼‰
	MaxURLsPerPattern int
	
	// æƒé‡ç­–ç•¥ï¼šä¸åŒç±»å‹çš„URLæœ‰ä¸åŒçš„é™åˆ¶
	WeightedLimits map[string]int
	
	// æ˜¯å¦å¯ç”¨æ™ºèƒ½æ¨¡å¼ï¼ˆæ ¹æ®URLé‡è¦æ€§åŠ¨æ€è°ƒæ•´ï¼‰
	EnableSmartMode bool
	
	// é‡‡æ ·æ•°é‡ï¼ˆä¿ç•™å‰Nä¸ªURLä½œä¸ºæ ·æœ¬ï¼‰
	SampleSize int
}

// LimiterStats é™æµå™¨ç»Ÿè®¡
type LimiterStats struct {
	TotalURLs       int // æ€»æ£€æŸ¥URLæ•°
	UniquePatterns  int // å”¯ä¸€æ¨¡å¼æ•°
	LimitedURLs     int // è¢«é™æµçš„URLæ•°
	AllowedURLs     int // å…è®¸çˆ¬å–çš„URLæ•°
}

// NewURLPatternLimiter åˆ›å»ºURLæ¨¡å¼é™æµå™¨
func NewURLPatternLimiter(config PatternLimiterConfig) *URLPatternLimiter {
	// è®¾ç½®é»˜è®¤å€¼
	if config.MaxURLsPerPattern == 0 {
		config.MaxURLsPerPattern = 3 // é»˜è®¤æ¯ä¸ªæ¨¡å¼æœ€å¤šçˆ¬3ä¸ª
	}
	if config.SampleSize == 0 {
		config.SampleSize = 5 // é»˜è®¤ä¿ç•™5ä¸ªæ ·æœ¬
	}
	
	// é»˜è®¤æƒé‡ç­–ç•¥
	if config.WeightedLimits == nil {
		config.WeightedLimits = map[string]int{
			"api":      5,  // APIç«¯ç‚¹å¯ä»¥å¤šçˆ¬å‡ ä¸ª
			"form":     5,  // è¡¨å•ç›¸å…³
			"image":    2,  // å›¾ç‰‡åªçˆ¬2ä¸ª
			"static":   1,  // é™æ€èµ„æºåªçˆ¬1ä¸ª
			"normal":   3,  // æ™®é€šé¡µé¢3ä¸ª
		}
	}
	
	return &URLPatternLimiter{
		patternCounts: make(map[string]int),
		patternInfo:   make(map[string]*PatternLimitInfo),
		config:        config,
		stats:         LimiterStats{},
	}
}

// ShouldCrawl åˆ¤æ–­URLæ˜¯å¦åº”è¯¥çˆ¬å–
// è¿”å›ï¼š(æ˜¯å¦å…è®¸çˆ¬å–, åŸå› , æ¨¡å¼ä¿¡æ¯)
func (l *URLPatternLimiter) ShouldCrawl(rawURL string) (bool, string, *PatternLimitInfo) {
	l.mutex.Lock()
	defer l.mutex.Unlock()
	
	l.stats.TotalURLs++
	
	// æå–URLæ¨¡å¼
	pattern, urlType := l.extractURLPattern(rawURL)
	if pattern == "" {
		// æ— æ³•æå–æ¨¡å¼ï¼Œå…è®¸çˆ¬å–
		l.stats.AllowedURLs++
		return true, "æ— æ³•æå–URLæ¨¡å¼ï¼Œå…è®¸çˆ¬å–", nil
	}
	
	// è®¡ç®—æ¨¡å¼hash
	patternHash := l.calculateHash(pattern)
	
	// è·å–æˆ–åˆ›å»ºæ¨¡å¼ä¿¡æ¯
	info, exists := l.patternInfo[patternHash]
	if !exists {
		info = &PatternLimitInfo{
			Pattern:      pattern,
			CrawledURLs:  make([]string, 0, l.config.SampleSize),
			SkippedCount: 0,
			FirstURL:     rawURL,
			Hash:         patternHash,
		}
		l.patternInfo[patternHash] = info
		l.stats.UniquePatterns++
	}
	
	// è·å–å½“å‰è®¡æ•°
	currentCount := l.patternCounts[patternHash]
	
	// ç¡®å®šé™åˆ¶æ•°é‡ï¼ˆæ ¹æ®URLç±»å‹ï¼‰
	limit := l.getLimit(urlType)
	
	// åˆ¤æ–­æ˜¯å¦è¶…è¿‡é™åˆ¶
	if currentCount >= limit {
		// è¶…è¿‡é™åˆ¶ï¼Œæ‹’ç»çˆ¬å–
		info.SkippedCount++
		l.stats.LimitedURLs++
		
		reason := fmt.Sprintf("URLæ¨¡å¼é™æµ - å·²çˆ¬å–%dä¸ªç›¸åŒæ¨¡å¼URLï¼ˆé™åˆ¶:%dï¼‰ï¼Œæ¨¡å¼: %s", 
			currentCount, limit, pattern)
		
		return false, reason, info
	}
	
	// å…è®¸çˆ¬å–
	l.patternCounts[patternHash]++
	
	// æ·»åŠ åˆ°é‡‡æ ·åˆ—è¡¨ï¼ˆåªä¿ç•™å‰Nä¸ªï¼‰
	if len(info.CrawledURLs) < l.config.SampleSize {
		info.CrawledURLs = append(info.CrawledURLs, rawURL)
	}
	
	l.stats.AllowedURLs++
	
	reason := fmt.Sprintf("å…è®¸çˆ¬å– - ç¬¬%dä¸ªè¯¥æ¨¡å¼URLï¼ˆé™åˆ¶:%dï¼‰", currentCount+1, limit)
	return true, reason, info
}

// extractURLPattern æå–URLæ¨¡å¼ï¼ˆå»é™¤å‚æ•°å€¼ï¼‰
// è¿”å›ï¼š(URLæ¨¡å¼, URLç±»å‹)
func (l *URLPatternLimiter) extractURLPattern(rawURL string) (string, string) {
	parsedURL, err := url.Parse(rawURL)
	if err != nil {
		return "", "unknown"
	}
	
	// æ„é€ åŸºç¡€æ¨¡å¼ï¼šscheme + host + path
	pattern := parsedURL.Scheme + "://" + parsedURL.Host + parsedURL.Path
	
	// å¦‚æœæœ‰æŸ¥è¯¢å‚æ•°ï¼Œæå–å‚æ•°åï¼ˆä¸å«å€¼ï¼‰
	if parsedURL.RawQuery != "" {
		queryParams := parsedURL.Query()
		
		// å¯¹å‚æ•°åæ’åº
		var paramNames []string
		for name := range queryParams {
			paramNames = append(paramNames, name)
		}
		sort.Strings(paramNames)
		
		// æ„å»ºå‚æ•°æ¨¡å¼ï¼ˆåªä¿ç•™å‚æ•°åï¼‰
		if len(paramNames) > 0 {
			pattern += "?" + strings.Join(paramNames, "&") + "="
		}
	}
	
	// åˆ¤æ–­URLç±»å‹
	urlType := l.classifyURLType(rawURL, parsedURL)
	
	return pattern, urlType
}

// classifyURLType åˆ†ç±»URLç±»å‹
func (l *URLPatternLimiter) classifyURLType(rawURL string, parsedURL *url.URL) string {
	lowerPath := strings.ToLower(parsedURL.Path)
	
	// é™æ€èµ„æº
	staticExts := []string{
		".jpg", ".jpeg", ".png", ".gif", ".svg", ".ico", ".webp", ".bmp",
		".css", ".scss", ".sass", ".less",
		".js", ".ts", ".jsx", ".tsx",
		".woff", ".woff2", ".ttf", ".eot", ".otf",
		".mp4", ".mp3", ".avi", ".mov", ".wmv", ".flv", ".webm",
		".pdf", ".doc", ".docx", ".xls", ".xlsx", ".ppt", ".pptx",
		".zip", ".rar", ".tar", ".gz", ".7z",
	}
	
	for _, ext := range staticExts {
		if strings.HasSuffix(lowerPath, ext) {
			if strings.Contains(ext, "jpg") || strings.Contains(ext, "png") || 
			   strings.Contains(ext, "gif") || strings.Contains(ext, "svg") {
				return "image"
			}
			return "static"
		}
	}
	
	// APIç«¯ç‚¹
	if strings.Contains(lowerPath, "api") || strings.Contains(lowerPath, "ajax") ||
	   strings.Contains(lowerPath, "/v1/") || strings.Contains(lowerPath, "/v2/") {
		return "api"
	}
	
	// è¡¨å•ç›¸å…³
	if strings.Contains(lowerPath, "login") || strings.Contains(lowerPath, "register") ||
	   strings.Contains(lowerPath, "signup") || strings.Contains(lowerPath, "form") ||
	   strings.Contains(lowerPath, "submit") {
		return "form"
	}
	
	return "normal"
}

// getLimit è·å–é™åˆ¶æ•°é‡ï¼ˆæ ¹æ®URLç±»å‹ï¼‰
func (l *URLPatternLimiter) getLimit(urlType string) int {
	if limit, exists := l.config.WeightedLimits[urlType]; exists {
		return limit
	}
	return l.config.MaxURLsPerPattern
}

// calculateHash è®¡ç®—å­—ç¬¦ä¸²çš„hash
func (l *URLPatternLimiter) calculateHash(s string) string {
	hasher := md5.New()
	hasher.Write([]byte(s))
	return hex.EncodeToString(hasher.Sum(nil))
}

// GetStats è·å–ç»Ÿè®¡ä¿¡æ¯
func (l *URLPatternLimiter) GetStats() LimiterStats {
	l.mutex.RLock()
	defer l.mutex.RUnlock()
	return l.stats
}

// PrintReport æ‰“å°é™æµæŠ¥å‘Š
func (l *URLPatternLimiter) PrintReport() {
	l.mutex.RLock()
	defer l.mutex.RUnlock()
	
	fmt.Println("\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
	fmt.Println("ğŸ“Š URLæ¨¡å¼é™æµæŠ¥å‘Š")
	fmt.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
	fmt.Printf("ğŸ” æ€»æ£€æŸ¥URLæ•°: %d\n", l.stats.TotalURLs)
	fmt.Printf("ğŸ“¦ å”¯ä¸€æ¨¡å¼æ•°: %d\n", l.stats.UniquePatterns)
	fmt.Printf("âœ… å…è®¸çˆ¬å–: %d\n", l.stats.AllowedURLs)
	fmt.Printf("ğŸš« é™æµæ‹’ç»: %d\n", l.stats.LimitedURLs)
	
	if l.stats.TotalURLs > 0 {
		limitRate := float64(l.stats.LimitedURLs) / float64(l.stats.TotalURLs) * 100
		fmt.Printf("ğŸ“ˆ é™æµç‡: %.1f%%\n", limitRate)
	}
	
	fmt.Println("\nã€æ¨¡å¼è¯¦æƒ…ï¼ˆæŒ‰è·³è¿‡æ•°é‡æ’åºï¼‰ã€‘")
	
	// æ”¶é›†æ‰€æœ‰æ¨¡å¼ä¿¡æ¯
	type patternStat struct {
		Pattern      string
		CrawledCount int
		SkippedCount int
		FirstURL     string
		Samples      []string
	}
	
	var patterns []patternStat
	for hash, info := range l.patternInfo {
		count := l.patternCounts[hash]
		patterns = append(patterns, patternStat{
			Pattern:      info.Pattern,
			CrawledCount: count,
			SkippedCount: info.SkippedCount,
			FirstURL:     info.FirstURL,
			Samples:      info.CrawledURLs,
		})
	}
	
	// æŒ‰è·³è¿‡æ•°é‡æ’åº
	sort.Slice(patterns, func(i, j int) bool {
		return patterns[i].SkippedCount > patterns[j].SkippedCount
	})
	
	// åªæ˜¾ç¤ºå‰10ä¸ª
	displayCount := 10
	if len(patterns) < displayCount {
		displayCount = len(patterns)
	}
	
	for i := 0; i < displayCount; i++ {
		p := patterns[i]
		fmt.Printf("\n%d. æ¨¡å¼: %s\n", i+1, p.Pattern)
		fmt.Printf("   çˆ¬å–: %dä¸ª | è·³è¿‡: %dä¸ª\n", p.CrawledCount, p.SkippedCount)
		fmt.Printf("   é¦–ä¸ªURL: %s\n", p.FirstURL)
		
		if len(p.Samples) > 0 {
			fmt.Printf("   é‡‡æ ·:\n")
			for j, sample := range p.Samples {
				if j < 3 { // åªæ˜¾ç¤ºå‰3ä¸ª
					fmt.Printf("     â€¢ %s\n", sample)
				}
			}
		}
	}
	
	fmt.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n")
}

