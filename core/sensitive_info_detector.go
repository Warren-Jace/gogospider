package core

import (
	"encoding/json"
	"fmt"
	"os"
	"regexp"
	"strings"
)

// SensitiveInfo æ•æ„Ÿä¿¡æ¯
type SensitiveInfo struct {
	Type       string // ç±»å‹
	Value      string // å€¼ï¼ˆè„±æ•åï¼‰
	FullValue  string // å®Œæ•´å€¼
	Location   string // ä½ç½®
	Severity   string // ä¸¥é‡ç¨‹åº¦: HIGH/MEDIUM/LOW
	SourceURL  string // æ¥æºURL
	LineNumber int    // è¡Œå·
}

// SensitiveInfoDetector æ•æ„Ÿä¿¡æ¯æ£€æµ‹å™¨
type SensitiveInfoDetector struct {
	patterns      map[string]*SensitivePattern
	findings      []*SensitiveInfo
	totalScanned  int
	totalFindings int
}

// SensitivePattern æ•æ„Ÿä¿¡æ¯æ¨¡å¼
type SensitivePattern struct {
	Name        string
	Pattern     *regexp.Regexp
	Severity    string
	Mask        bool   // æ˜¯å¦éœ€è¦è„±æ•
	Description string // è§„åˆ™æè¿°
}

// RuleConfig å¤–éƒ¨è§„åˆ™é…ç½®æ–‡ä»¶ç»“æ„
type RuleConfig struct {
	Rules map[string]RulePattern `json:"rules"`
}

// RulePattern å¤–éƒ¨è§„åˆ™æ¨¡å¼
type RulePattern struct {
	Pattern     string `json:"pattern"`
	Severity    string `json:"severity"`
	Mask        bool   `json:"mask"`
	Description string `json:"description"`
}

// NewSensitiveInfoDetector åˆ›å»ºæ•æ„Ÿä¿¡æ¯æ£€æµ‹å™¨
func NewSensitiveInfoDetector() *SensitiveInfoDetector {
	sid := &SensitiveInfoDetector{
		patterns: make(map[string]*SensitivePattern),
		findings: make([]*SensitiveInfo, 0),
	}
	
	sid.initializePatterns()
	
	return sid
}

// initializePatterns åˆå§‹åŒ–æ£€æµ‹æ¨¡å¼
// ğŸ”§ v3.1: ç§»é™¤æ‰€æœ‰å†…ç½®è§„åˆ™ï¼Œå®Œå…¨ä¾èµ–å¤–éƒ¨é…ç½®æ–‡ä»¶
// å¦‚æœç”¨æˆ·ä¸æä¾›è§„åˆ™æ–‡ä»¶ï¼Œæ£€æµ‹å™¨å°†ä¸ºç©ºï¼ˆä¸ä¼šè¿›è¡Œä»»ä½•æ£€æµ‹ï¼‰
func (sid *SensitiveInfoDetector) initializePatterns() {
	// æ‰€æœ‰è§„åˆ™é€šè¿‡å¤–éƒ¨JSONæ–‡ä»¶åŠ è½½
	// ä½¿ç”¨ LoadRulesFromFile() æˆ– MergeRulesFromFile() æ–¹æ³•åŠ è½½è§„åˆ™
	fmt.Println("[æ•æ„Ÿä¿¡æ¯] ç­‰å¾…åŠ è½½å¤–éƒ¨è§„åˆ™æ–‡ä»¶...")
}

// addPattern æ·»åŠ æ£€æµ‹æ¨¡å¼
func (sid *SensitiveInfoDetector) addPattern(name string, pattern *regexp.Regexp, severity string, mask bool) {
	sid.patterns[name] = &SensitivePattern{
		Name:     name,
		Pattern:  pattern,
		Severity: severity,
		Mask:     mask,
	}
}

// LoadRulesFromFile ä»å¤–éƒ¨JSONæ–‡ä»¶åŠ è½½è§„åˆ™
func (sid *SensitiveInfoDetector) LoadRulesFromFile(filename string) error {
	// è¯»å–æ–‡ä»¶
	data, err := os.ReadFile(filename)
	if err != nil {
		return fmt.Errorf("è¯»å–è§„åˆ™æ–‡ä»¶å¤±è´¥: %v", err)
	}
	
	// ğŸ”§ ä¿®å¤: ä½¿ç”¨map[string]interface{}æ¥å¤„ç†æ··åˆç±»å‹çš„JSON
	var rawConfig map[string]interface{}
	if err := json.Unmarshal(data, &rawConfig); err != nil {
		return fmt.Errorf("è§£æè§„åˆ™æ–‡ä»¶å¤±è´¥: %v", err)
	}
	
	// è·å–ruleså­—æ®µ
	rulesInterface, ok := rawConfig["rules"]
	if !ok {
		return fmt.Errorf("è§„åˆ™æ–‡ä»¶ä¸­æœªæ‰¾åˆ°'rules'å­—æ®µ")
	}
	
	rulesMap, ok := rulesInterface.(map[string]interface{})
	if !ok {
		return fmt.Errorf("'rules'å­—æ®µæ ¼å¼ä¸æ­£ç¡®")
	}
	
	// æ¸…ç©ºç°æœ‰è§„åˆ™
	sid.patterns = make(map[string]*SensitivePattern)
	
	// åŠ è½½æ–°è§„åˆ™
	loadedCount := 0
	for name, ruleInterface := range rulesMap {
		// è·³è¿‡æ³¨é‡Šå­—æ®µï¼ˆä»¥_å¼€å¤´æˆ–_commentå¼€å¤´ï¼‰
		if strings.HasPrefix(name, "_comment") || strings.HasPrefix(name, "_") {
			continue
		}
		
		// æ£€æŸ¥æ˜¯å¦ä¸ºå­—ç¬¦ä¸²ç±»å‹ï¼ˆæ³¨é‡Šï¼‰
		if _, ok := ruleInterface.(string); ok {
			continue
		}
		
		// è½¬æ¢ä¸ºRulePattern
		ruleMap, ok := ruleInterface.(map[string]interface{})
		if !ok {
			fmt.Printf("è­¦å‘Š: è§„åˆ™ '%s' æ ¼å¼ä¸æ­£ç¡®ï¼Œè·³è¿‡\n", name)
			continue
		}
		
		// æå–è§„åˆ™å­—æ®µ
		pattern, _ := ruleMap["pattern"].(string)
		severity, _ := ruleMap["severity"].(string)
		mask, _ := ruleMap["mask"].(bool)
		description, _ := ruleMap["description"].(string)
		
		if pattern == "" {
			fmt.Printf("è­¦å‘Š: è§„åˆ™ '%s' ç¼ºå°‘patternå­—æ®µï¼Œè·³è¿‡\n", name)
			continue
		}
		
		// ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
		regex, err := regexp.Compile(pattern)
		if err != nil {
			fmt.Printf("è­¦å‘Š: è§„åˆ™ '%s' çš„æ­£åˆ™è¡¨è¾¾å¼ç¼–è¯‘å¤±è´¥: %v\n", name, err)
			continue
		}
		
		// æ·»åŠ åˆ°æ£€æµ‹å™¨
		sid.patterns[name] = &SensitivePattern{
			Name:        name,
			Pattern:     regex,
			Severity:    severity,
			Mask:        mask,
			Description: description,
		}
		loadedCount++
	}
	
	fmt.Printf("[æ•æ„Ÿè§„åˆ™] ä» %s åŠ è½½äº† %d æ¡è§„åˆ™\n", filename, loadedCount)
	return nil
}

// MergeRulesFromFile ä»å¤–éƒ¨JSONæ–‡ä»¶åˆå¹¶è§„åˆ™ï¼ˆä¸æ¸…ç©ºç°æœ‰è§„åˆ™ï¼‰
func (sid *SensitiveInfoDetector) MergeRulesFromFile(filename string) error {
	// è¯»å–æ–‡ä»¶
	data, err := os.ReadFile(filename)
	if err != nil {
		return fmt.Errorf("è¯»å–è§„åˆ™æ–‡ä»¶å¤±è´¥: %v", err)
	}
	
	// ğŸ”§ ä¿®å¤: ä½¿ç”¨map[string]interface{}æ¥å¤„ç†æ··åˆç±»å‹çš„JSON
	var rawConfig map[string]interface{}
	if err := json.Unmarshal(data, &rawConfig); err != nil {
		return fmt.Errorf("è§£æè§„åˆ™æ–‡ä»¶å¤±è´¥: %v", err)
	}
	
	// è·å–ruleså­—æ®µ
	rulesInterface, ok := rawConfig["rules"]
	if !ok {
		return fmt.Errorf("è§„åˆ™æ–‡ä»¶ä¸­æœªæ‰¾åˆ°'rules'å­—æ®µ")
	}
	
	rulesMap, ok := rulesInterface.(map[string]interface{})
	if !ok {
		return fmt.Errorf("'rules'å­—æ®µæ ¼å¼ä¸æ­£ç¡®")
	}
	
	// åˆå¹¶è§„åˆ™
	loadedCount := 0
	for name, ruleInterface := range rulesMap {
		// è·³è¿‡æ³¨é‡Šå­—æ®µ
		if strings.HasPrefix(name, "_comment") || strings.HasPrefix(name, "_") {
			continue
		}
		
		// æ£€æŸ¥æ˜¯å¦ä¸ºå­—ç¬¦ä¸²ç±»å‹ï¼ˆæ³¨é‡Šï¼‰
		if _, ok := ruleInterface.(string); ok {
			continue
		}
		
		// è½¬æ¢ä¸ºRulePattern
		ruleMap, ok := ruleInterface.(map[string]interface{})
		if !ok {
			fmt.Printf("è­¦å‘Š: è§„åˆ™ '%s' æ ¼å¼ä¸æ­£ç¡®ï¼Œè·³è¿‡\n", name)
			continue
		}
		
		// æå–è§„åˆ™å­—æ®µ
		pattern, _ := ruleMap["pattern"].(string)
		severity, _ := ruleMap["severity"].(string)
		mask, _ := ruleMap["mask"].(bool)
		description, _ := ruleMap["description"].(string)
		
		if pattern == "" {
			fmt.Printf("è­¦å‘Š: è§„åˆ™ '%s' ç¼ºå°‘patternå­—æ®µï¼Œè·³è¿‡\n", name)
			continue
		}
		
		// ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
		regex, err := regexp.Compile(pattern)
		if err != nil {
			fmt.Printf("è­¦å‘Š: è§„åˆ™ '%s' çš„æ­£åˆ™è¡¨è¾¾å¼ç¼–è¯‘å¤±è´¥: %v\n", name, err)
			continue
		}
		
		// æ·»åŠ åˆ°æ£€æµ‹å™¨ï¼ˆä¼šè¦†ç›–åŒåè§„åˆ™ï¼‰
		sid.patterns[name] = &SensitivePattern{
			Name:        name,
			Pattern:     regex,
			Severity:    severity,
			Mask:        mask,
			Description: description,
		}
		loadedCount++
	}
	
	fmt.Printf("[æ•æ„Ÿè§„åˆ™] ä» %s åˆå¹¶äº† %d æ¡è§„åˆ™ï¼Œå½“å‰å…± %d æ¡è§„åˆ™\n", filename, loadedCount, len(sid.patterns))
	return nil
}

// Scan æ‰«æå†…å®¹
func (sid *SensitiveInfoDetector) Scan(content string, sourceURL string) []*SensitiveInfo {
	sid.totalScanned++
	findings := make([]*SensitiveInfo, 0)
	
	// åˆ†è¡Œå¤„ç†ï¼Œè®°å½•è¡Œå·
	lines := strings.Split(content, "\n")
	
	for lineNum, line := range lines {
		for _, pattern := range sid.patterns {
			matches := pattern.Pattern.FindAllStringSubmatch(line, -1)
			
			for _, match := range matches {
				if len(match) > 0 {
					// ğŸ”§ ä¿®å¤: å§‹ç»ˆä½¿ç”¨match[0]ï¼ˆå®Œæ•´åŒ¹é…ï¼‰ä½œä¸ºæ•æ„Ÿä¿¡æ¯çš„å®Œæ•´å€¼
					// å¦‚æœè§„åˆ™éœ€è¦æå–ç‰¹å®šéƒ¨åˆ†ï¼Œåº”è¯¥åœ¨è§„åˆ™è®¾è®¡æ—¶ä½¿ç”¨éæ•è·ç»„(?:...)
					fullValue := match[0]
					
					// è„±æ•å¤„ç†
					displayValue := fullValue
					if pattern.Mask {
						displayValue = sid.maskValue(fullValue)
					}
					
					info := &SensitiveInfo{
						Type:       pattern.Name,
						Value:      displayValue,  // è„±æ•åçš„å€¼
						FullValue:  fullValue,     // å®Œæ•´çš„åŸå§‹å€¼
						Location:   fmt.Sprintf("Line %d", lineNum+1),
						Severity:   pattern.Severity,
						SourceURL:  sourceURL,
						LineNumber: lineNum + 1,
					}
					
					findings = append(findings, info)
					sid.totalFindings++
				}
			}
		}
	}
	
	// ä¿å­˜åˆ°æ€»findings
	sid.findings = append(sid.findings, findings...)
	
	return findings
}

// ScanResponse æ‰«æHTTPå“åº”
func (sid *SensitiveInfoDetector) ScanResponse(content string, headers map[string][]string, sourceURL string) []*SensitiveInfo {
	allFindings := make([]*SensitiveInfo, 0)
	
	// æ‰«æå“åº”ä½“
	bodyFindings := sid.Scan(content, sourceURL)
	allFindings = append(allFindings, bodyFindings...)
	
	// æ‰«æå“åº”å¤´
	for headerName, headerValues := range headers {
		for _, headerValue := range headerValues {
			headerContent := headerName + ": " + headerValue
			headerFindings := sid.Scan(headerContent, sourceURL+" (Header)")
			allFindings = append(allFindings, headerFindings...)
		}
	}
	
	return allFindings
}

// maskValue è„±æ•å¤„ç†
func (sid *SensitiveInfoDetector) maskValue(value string) string {
	if len(value) <= 8 {
		return strings.Repeat("*", len(value))
	}
	
	// æ˜¾ç¤ºå‰4ä½å’Œå4ä½
	return value[:4] + strings.Repeat("*", len(value)-8) + value[len(value)-4:]
}

// GetFindings è·å–æ‰€æœ‰å‘ç°
func (sid *SensitiveInfoDetector) GetFindings() []*SensitiveInfo {
	return sid.findings
}

// GetFindingsByType æŒ‰ç±»å‹è·å–å‘ç°
func (sid *SensitiveInfoDetector) GetFindingsByType(infoType string) []*SensitiveInfo {
	findings := make([]*SensitiveInfo, 0)
	
	for _, finding := range sid.findings {
		if finding.Type == infoType {
			findings = append(findings, finding)
		}
	}
	
	return findings
}

// GetFindingsBySeverity æŒ‰ä¸¥é‡ç¨‹åº¦è·å–å‘ç°
func (sid *SensitiveInfoDetector) GetFindingsBySeverity(severity string) []*SensitiveInfo {
	findings := make([]*SensitiveInfo, 0)
	
	for _, finding := range sid.findings {
		if finding.Severity == severity {
			findings = append(findings, finding)
		}
	}
	
	return findings
}

// GetStatistics è·å–ç»Ÿè®¡ä¿¡æ¯
func (sid *SensitiveInfoDetector) GetStatistics() map[string]interface{} {
	stats := make(map[string]interface{})
	
	stats["total_scanned"] = sid.totalScanned
	stats["total_findings"] = sid.totalFindings
	
	// æŒ‰ä¸¥é‡ç¨‹åº¦ç»Ÿè®¡
	highCount := len(sid.GetFindingsBySeverity("HIGH"))
	mediumCount := len(sid.GetFindingsBySeverity("MEDIUM"))
	lowCount := len(sid.GetFindingsBySeverity("LOW"))
	
	stats["high_severity"] = highCount
	stats["medium_severity"] = mediumCount
	stats["low_severity"] = lowCount
	
	// æŒ‰ç±»å‹ç»Ÿè®¡
	typeCount := make(map[string]int)
	for _, finding := range sid.findings {
		typeCount[finding.Type]++
	}
	stats["findings_by_type"] = typeCount
	
	return stats
}

// GenerateReport ç”ŸæˆæŠ¥å‘Š
func (sid *SensitiveInfoDetector) GenerateReport() string {
	if len(sid.findings) == 0 {
		return "æœªå‘ç°æ•æ„Ÿä¿¡æ¯æ³„éœ²"
	}
	
	var report strings.Builder
	
	report.WriteString("=== æ•æ„Ÿä¿¡æ¯æ³„éœ²æ£€æµ‹æŠ¥å‘Š ===\n\n")
	
	// é«˜å±å‘ç°
	highFindings := sid.GetFindingsBySeverity("HIGH")
	if len(highFindings) > 0 {
		report.WriteString(fmt.Sprintf("ã€é«˜å±ã€‘å‘ç° %d å¤„é«˜å±æ•æ„Ÿä¿¡æ¯\n", len(highFindings)))
		for i, finding := range highFindings {
			if i >= 10 {
				report.WriteString(fmt.Sprintf("  ... è¿˜æœ‰ %d å¤„é«˜å±å‘ç°\n", len(highFindings)-10))
				break
			}
			report.WriteString(fmt.Sprintf("  [%d] %s\n", i+1, finding.Type))
			report.WriteString(fmt.Sprintf("      å€¼: %s\n", finding.Value))
			report.WriteString(fmt.Sprintf("      ä½ç½®: %s (%s)\n", finding.SourceURL, finding.Location))
		}
		report.WriteString("\n")
	}
	
	// ä¸­å±å‘ç°
	mediumFindings := sid.GetFindingsBySeverity("MEDIUM")
	if len(mediumFindings) > 0 {
		report.WriteString(fmt.Sprintf("ã€ä¸­å±ã€‘å‘ç° %d å¤„ä¸­å±æ•æ„Ÿä¿¡æ¯\n", len(mediumFindings)))
		for i, finding := range mediumFindings {
			if i >= 5 {
				report.WriteString(fmt.Sprintf("  ... è¿˜æœ‰ %d å¤„ä¸­å±å‘ç°\n", len(mediumFindings)-5))
				break
			}
			report.WriteString(fmt.Sprintf("  [%d] %s: %s\n", i+1, finding.Type, finding.Value))
		}
		report.WriteString("\n")
	}
	
	// ä½å±å‘ç°ï¼ˆåªæ˜¾ç¤ºæ•°é‡ï¼‰
	lowFindings := sid.GetFindingsBySeverity("LOW")
	if len(lowFindings) > 0 {
		report.WriteString(fmt.Sprintf("ã€ä½å±ã€‘å‘ç° %d å¤„ä½å±æ•æ„Ÿä¿¡æ¯\n", len(lowFindings)))
		
		// æŒ‰ç±»å‹ç»Ÿè®¡
		typeCount := make(map[string]int)
		for _, finding := range lowFindings {
			typeCount[finding.Type]++
		}
		
		for infoType, count := range typeCount {
			report.WriteString(fmt.Sprintf("  - %s: %dä¸ª\n", infoType, count))
		}
	}
	
	return report.String()
}

// GetSummary è·å–æ‘˜è¦
func (sid *SensitiveInfoDetector) GetSummary() string {
	highCount := len(sid.GetFindingsBySeverity("HIGH"))
	mediumCount := len(sid.GetFindingsBySeverity("MEDIUM"))
	lowCount := len(sid.GetFindingsBySeverity("LOW"))
	
	if sid.totalFindings == 0 {
		return "âœ… æœªå‘ç°æ•æ„Ÿä¿¡æ¯æ³„éœ²"
	}
	
	return fmt.Sprintf("âš ï¸  å‘ç° %d å¤„æ•æ„Ÿä¿¡æ¯ (é«˜å±:%d, ä¸­å±:%d, ä½å±:%d)", 
		sid.totalFindings, highCount, mediumCount, lowCount)
}

// Clear æ¸…ç©ºå‘ç°è®°å½•
func (sid *SensitiveInfoDetector) Clear() {
	sid.findings = make([]*SensitiveInfo, 0)
	sid.totalScanned = 0
	sid.totalFindings = 0
}

// AddCustomPattern æ·»åŠ è‡ªå®šä¹‰æ£€æµ‹æ¨¡å¼
func (sid *SensitiveInfoDetector) AddCustomPattern(name string, pattern string, severity string, mask bool) error {
	regex, err := regexp.Compile(pattern)
	if err != nil {
		return err
	}
	
	sid.addPattern(name, regex, severity, mask)
	return nil
}

// ExportFindings å¯¼å‡ºå‘ç°ï¼ˆç”¨äºå¤–éƒ¨å¤„ç†ï¼‰
func (sid *SensitiveInfoDetector) ExportFindings() []map[string]interface{} {
	exports := make([]map[string]interface{}, 0)
	
	for _, finding := range sid.findings {
		export := make(map[string]interface{})
		export["type"] = finding.Type
		export["value"] = finding.Value          // è„±æ•åçš„å€¼
		export["full_value"] = finding.FullValue // å®Œæ•´å€¼
		export["location"] = finding.Location
		export["severity"] = finding.Severity
		export["source_url"] = finding.SourceURL
		export["line_number"] = finding.LineNumber
		
		exports = append(exports, export)
	}
	
	return exports
}

