package core

import (
	"crypto/md5"
	"encoding/hex"
	"math"
	"net/url"
	"sort"
	"strings"
	"sync"
)

// DuplicateHandler å»é‡å¤„ç†å™¨
type DuplicateHandler struct {
	// ğŸ”§ ä¿®å¤ï¼šæ·»åŠ äº’æ–¥é”ä¿æŠ¤å¹¶å‘è®¿é—®
	mutex sync.RWMutex
	
	// å·²å¤„ç†URLçš„å“ˆå¸Œé›†åˆ
	processedURLs map[string]bool
	
	// å·²å¤„ç†å†…å®¹çš„å“ˆå¸Œé›†åˆ
	processedContent map[string]bool
	
	// ç›¸ä¼¼åº¦é˜ˆå€¼
	similarityThreshold float64
}

// NewDuplicateHandler åˆ›å»ºå»é‡å¤„ç†å™¨å®ä¾‹
func NewDuplicateHandler(threshold float64) *DuplicateHandler {
	return &DuplicateHandler{
		processedURLs:      make(map[string]bool),
		processedContent:   make(map[string]bool),
		similarityThreshold: threshold,
	}
}

// IsDuplicateURL æ£€æŸ¥URLæ˜¯å¦é‡å¤
func (d *DuplicateHandler) IsDuplicateURL(rawURL string) bool {
	// è§£æURL
	parsedURL, err := url.Parse(rawURL)
	if err != nil {
		// å¦‚æœæ— æ³•è§£æURLï¼Œåˆ™ä½¿ç”¨åŸå§‹å»é‡é€»è¾‘
		hash := d.calculateMD5(rawURL)
		
		// ğŸ”§ ä¿®å¤ï¼šåŠ é”ä¿æŠ¤å¹¶å‘è®¿é—®
		d.mutex.Lock()
		defer d.mutex.Unlock()
		
		if _, exists := d.processedURLs[hash]; exists {
			return true
		}
		d.processedURLs[hash] = true
		return false
	}
	
	// æ„é€ ç”¨äºå»é‡æ£€æŸ¥çš„URLé”®å€¼
	// åŒ…å«åè®®ã€ä¸»æœºå’Œè·¯å¾„ï¼Œä½†ä¸åŒ…å«æŸ¥è¯¢å‚æ•°
	urlKey := parsedURL.Scheme + "://" + parsedURL.Host + parsedURL.Path
	
	// å¦‚æœæœ‰æŸ¥è¯¢å‚æ•°ï¼Œåˆ™å°†å…¶åŒ…å«åœ¨é”®å€¼ä¸­
	if parsedURL.RawQuery != "" {
		// è§£ææŸ¥è¯¢å‚æ•°
		queryParams := parsedURL.Query()
		
		// å¯¹æŸ¥è¯¢å‚æ•°è¿›è¡Œæ’åºä»¥ç¡®ä¿ä¸€è‡´æ€§
		var paramKeys []string
		for key := range queryParams {
			paramKeys = append(paramKeys, key)
		}
		sort.Strings(paramKeys)
		
		// æ„å»ºæ’åºåçš„æŸ¥è¯¢å­—ç¬¦ä¸²
		var queryParts []string
		for _, key := range paramKeys {
			for _, value := range queryParams[key] {
				queryParts = append(queryParts, key+"="+value)
			}
		}
		
		if len(queryParts) > 0 {
			urlKey += "?" + strings.Join(queryParts, "&")
		}
	}
	
	// è®¡ç®—URLé”®å€¼çš„MD5å“ˆå¸Œ
	hash := d.calculateMD5(urlKey)
	
	// ğŸ”§ ä¿®å¤ï¼šåŠ é”ä¿æŠ¤å¹¶å‘è®¿é—®
	d.mutex.Lock()
	defer d.mutex.Unlock()
	
	// æ£€æŸ¥æ˜¯å¦å·²å¤„ç†è¿‡
	if _, exists := d.processedURLs[hash]; exists {
		return true
	}
	
	// æ·»åŠ åˆ°å·²å¤„ç†é›†åˆ
	d.processedURLs[hash] = true
	return false
}

// IsDuplicateContent æ£€æŸ¥å†…å®¹æ˜¯å¦é‡å¤
func (d *DuplicateHandler) IsDuplicateContent(content string) bool {
	// è®¡ç®—å†…å®¹çš„MD5å“ˆå¸Œ
	hash := d.calculateMD5(content)
	
	// ğŸ”§ ä¿®å¤ï¼šåŠ é”ä¿æŠ¤å¹¶å‘è®¿é—®
	d.mutex.Lock()
	defer d.mutex.Unlock()
	
	// æ£€æŸ¥æ˜¯å¦å·²å¤„ç†è¿‡
	if _, exists := d.processedContent[hash]; exists {
		return true
	}
	
	// æ·»åŠ åˆ°å·²å¤„ç†é›†åˆ
	d.processedContent[hash] = true
	return false
}

// IsSimilarContent åŸºäºç›¸ä¼¼åº¦æ£€æŸ¥å†…å®¹æ˜¯å¦ç›¸ä¼¼
func (d *DuplicateHandler) IsSimilarContent(content1, content2 string) bool {
	similarity := d.calculateSimilarity(content1, content2)
	return similarity >= d.similarityThreshold
}

// calculateMD5 è®¡ç®—å­—ç¬¦ä¸²çš„MD5å“ˆå¸Œå€¼
func (d *DuplicateHandler) calculateMD5(text string) string {
	hasher := md5.New()
	hasher.Write([]byte(text))
	return hex.EncodeToString(hasher.Sum(nil))
}

// calculateSimilarity è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦ï¼ˆä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ç®€åŒ–ç‰ˆï¼‰
func (d *DuplicateHandler) calculateSimilarity(text1, text2 string) float64 {
	// è½¬æ¢ä¸ºå°å†™å¹¶åˆ†å‰²ä¸ºè¯æ±‡
	words1 := strings.Fields(strings.ToLower(text1))
	words2 := strings.Fields(strings.ToLower(text2))
	
	// åˆ›å»ºè¯æ±‡é¢‘ç‡æ˜ å°„
	freq1 := make(map[string]int)
	freq2 := make(map[string]int)
	
	for _, word := range words1 {
		// ç®€å•æ¸…ç†è¯æ±‡ï¼ˆç§»é™¤æ ‡ç‚¹ç¬¦å·ï¼‰
		cleanWord := d.cleanWord(word)
		if cleanWord != "" {
			freq1[cleanWord]++
		}
	}
	
	for _, word := range words2 {
		// ç®€å•æ¸…ç†è¯æ±‡ï¼ˆç§»é™¤æ ‡ç‚¹ç¬¦å·ï¼‰
		cleanWord := d.cleanWord(word)
		if cleanWord != "" {
			freq2[cleanWord]++
		}
	}
	
	// è®¡ç®—ç‚¹ç§¯
	dotProduct := 0.0
	for word, freq := range freq1 {
		if freq2[word] > 0 {
			dotProduct += float64(freq * freq2[word])
		}
	}
	
	// è®¡ç®—å‘é‡çš„æ¨¡
	magnitude1 := 0.0
	magnitude2 := 0.0
	
	for _, freq := range freq1 {
		magnitude1 += float64(freq * freq)
	}
	
	for _, freq := range freq2 {
		magnitude2 += float64(freq * freq)
	}
	
	// è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
	if magnitude1 == 0 || magnitude2 == 0 {
		return 0.0
	}
	
	similarity := dotProduct / (math.Sqrt(magnitude1) * math.Sqrt(magnitude2))
	return similarity
}

// cleanWord æ¸…ç†è¯æ±‡ï¼Œç§»é™¤æ ‡ç‚¹ç¬¦å·
func (d *DuplicateHandler) cleanWord(word string) string {
	// ç§»é™¤å¸¸è§çš„æ ‡ç‚¹ç¬¦å·
	cleaned := strings.Trim(word, ".,;:!?()[]{}\"'`-")
	return strings.ToLower(cleaned)
}

// IsSimilarDOM åŸºäºDOMç»“æ„æ£€æŸ¥ç›¸ä¼¼æ€§
func (d *DuplicateHandler) IsSimilarDOM(dom1, dom2 string) bool {
	// æå–DOMç»“æ„ç‰¹å¾
	features1 := d.extractDOMFeatures(dom1)
	features2 := d.extractDOMFeatures(dom2)
	
	// è®¡ç®—ç‰¹å¾ç›¸ä¼¼åº¦
	similarity := d.calculateFeatureSimilarity(features1, features2)
	return similarity >= d.similarityThreshold
}

// extractDOMFeatures æå–DOMç»“æ„ç‰¹å¾
func (d *DuplicateHandler) extractDOMFeatures(dom string) map[string]int {
	features := make(map[string]int)
	
	// ç®€åŒ–çš„DOMç‰¹å¾æå–
	// å®é™…åº”ç”¨ä¸­å¯ä»¥ä½¿ç”¨HTMLè§£æå™¨æå–æ›´ç²¾ç¡®çš„ç‰¹å¾
	
	// ç»Ÿè®¡æ ‡ç­¾ç±»å‹
	tagPatterns := []string{"<div", "<span", "<a", "<img", "<form", "<input", "<button"}
	
	for _, pattern := range tagPatterns {
		count := strings.Count(dom, pattern)
		if count > 0 {
			features[pattern] = count
		}
	}
	
	// ç»Ÿè®¡ç±»åå’ŒID
	// è¿™é‡Œç®€åŒ–å¤„ç†
	classCount := strings.Count(dom, "class=")
	idCount := strings.Count(dom, "id=")
	
	if classCount > 0 {
		features["class"] = classCount
	}
	
	if idCount > 0 {
		features["id"] = idCount
	}
	
	return features
}

// calculateFeatureSimilarity è®¡ç®—ç‰¹å¾ç›¸ä¼¼åº¦
func (d *DuplicateHandler) calculateFeatureSimilarity(features1, features2 map[string]int) float64 {
	// è®¡ç®—ç‚¹ç§¯
	dotProduct := 0.0
	for feature, freq := range features1 {
		if features2[feature] > 0 {
			dotProduct += float64(freq * features2[feature])
		}
	}
	
	// è®¡ç®—å‘é‡çš„æ¨¡
	magnitude1 := 0.0
	magnitude2 := 0.0
	
	for _, freq := range features1 {
		magnitude1 += float64(freq * freq)
	}
	
	for _, freq := range features2 {
		magnitude2 += float64(freq * freq)
	}
	
	// è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
	if magnitude1 == 0 || magnitude2 == 0 {
		return 0.0
	}
	
	similarity := dotProduct / (math.Sqrt(magnitude1) * math.Sqrt(magnitude2))
	return similarity
}

// ClearProcessed æ¸…ç©ºå·²å¤„ç†è®°å½•
func (d *DuplicateHandler) ClearProcessed() {
	// ğŸ”§ ä¿®å¤ï¼šåŠ é”ä¿æŠ¤å¹¶å‘è®¿é—®
	d.mutex.Lock()
	defer d.mutex.Unlock()
	
	d.processedURLs = make(map[string]bool)
	d.processedContent = make(map[string]bool)
}