package core

import (
	"fmt"
	"io"
	"net/http"
	"net/url"
	"strings"
	"sync"
	"time"
	
	"spider-golang/config"
)

// Spider ä¸»çˆ¬è™«åè°ƒå™¨
type Spider struct {
	config             *config.Config
	staticCrawler      StaticCrawler
	dynamicCrawler     DynamicCrawler
	jsAnalyzer         *JSAnalyzer
	paramHandler       *ParamHandler
	duplicateHandler   *DuplicateHandler
	smartDeduplication *SmartDeduplication
	hiddenPathDiscovery *HiddenPathDiscovery
	cdnDetector        *CDNDetector // CDNæ£€æµ‹å™¨
	workerPool         *WorkerPool  // å¹¶å‘å·¥ä½œæ± 
	
	// æ–°å¢ä¼˜åŒ–ç»„ä»¶
	formFiller         *SmartFormFiller        // æ™ºèƒ½è¡¨å•å¡«å……å™¨
	advancedScope      *AdvancedScope          // é«˜çº§ä½œç”¨åŸŸæ§åˆ¶
	perfOptimizer      *PerformanceOptimizer   // æ€§èƒ½ä¼˜åŒ–å™¨
	
	// é«˜çº§åŠŸèƒ½ç»„ä»¶
	techDetector       *TechStackDetector      // æŠ€æœ¯æ ˆæ£€æµ‹å™¨
	sensitiveDetector  *SensitiveInfoDetector  // æ•æ„Ÿä¿¡æ¯æ£€æµ‹å™¨
	passiveCrawler     *PassiveCrawler         // è¢«åŠ¨çˆ¬å–å™¨
	subdomainExtractor *SubdomainExtractor     // å­åŸŸåæå–å™¨
	
	results            []*Result
	externalLinks      []string // è®°å½•å¤–éƒ¨é“¾æ¥
	hiddenPaths        []string // è®°å½•éšè—è·¯å¾„
	securityFindings   []string // è®°å½•å®‰å…¨å‘ç°
	crossDomainJS      []string // è®°å½•è·¨åŸŸJSå‘ç°çš„URL
	detectedTechs      []*TechInfo // æ£€æµ‹åˆ°çš„æŠ€æœ¯æ ˆ
	sensitiveFindings  []*SensitiveInfo // æ•æ„Ÿä¿¡æ¯å‘ç°
	mutex              sync.Mutex
	targetDomain       string          // ç›®æ ‡åŸŸå
	visitedURLs        map[string]bool // å·²è®¿é—®URL
}

// NewSpider åˆ›å»ºçˆ¬è™«å®ä¾‹
func NewSpider(cfg *config.Config) *Spider {
	// åˆ›å»ºç»“æœé€šé“å’Œåœæ­¢é€šé“
	resultChan := make(chan Result, 100)
	stopChan := make(chan struct{})
	
	// è®¡ç®—å¹¶å‘workeræ•°é‡ï¼ˆé»˜è®¤10ä¸ªï¼Œå¯é…ç½®ï¼‰
	workerCount := 10
	if cfg.DepthSettings.MaxDepth > 2 {
		workerCount = 15 // æ·±åº¦çˆ¬å–æ—¶å¢åŠ workeræ•°
	}
	
	// é€Ÿç‡é™åˆ¶ï¼ˆæ¯ç§’æœ€å¤š20ä¸ªè¯·æ±‚ï¼Œé¿å…è¿‡è½½ï¼‰
	maxQPS := 20
	
	spider := &Spider{
		config:             cfg,
		staticCrawler:      NewStaticCrawler(cfg, resultChan, stopChan),
		dynamicCrawler:     NewDynamicCrawler(),
		jsAnalyzer:         NewJSAnalyzer(),
		paramHandler:       NewParamHandler(),
		duplicateHandler:   NewDuplicateHandler(cfg.DeduplicationSettings.SimilarityThreshold),
		smartDeduplication: NewSmartDeduplication(), // åˆå§‹åŒ–æ™ºèƒ½å»é‡
		cdnDetector:        NewCDNDetector(), // åˆå§‹åŒ–CDNæ£€æµ‹å™¨
		workerPool:         NewWorkerPool(workerCount, maxQPS), // åˆå§‹åŒ–å·¥ä½œæ± 
		
		// åˆå§‹åŒ–æ–°å¢ç»„ä»¶
		formFiller:         NewSmartFormFiller(),          // æ™ºèƒ½è¡¨å•å¡«å……å™¨
		advancedScope:      nil,                           // å°†åœ¨Startä¸­åˆå§‹åŒ–
		perfOptimizer:      NewPerformanceOptimizer(500),  // æ€§èƒ½ä¼˜åŒ–å™¨ï¼ˆé™åˆ¶500MBï¼‰
		
		// åˆå§‹åŒ–é«˜çº§åŠŸèƒ½ç»„ä»¶
		techDetector:       NewTechStackDetector(),        // æŠ€æœ¯æ ˆæ£€æµ‹å™¨
		sensitiveDetector:  NewSensitiveInfoDetector(),    // æ•æ„Ÿä¿¡æ¯æ£€æµ‹å™¨
		passiveCrawler:     nil,                           // æŒ‰éœ€åˆ›å»º
		
		hiddenPathDiscovery: nil, // å°†åœ¨Startæ–¹æ³•ä¸­åˆå§‹åŒ–ï¼Œéœ€è¦ç”¨æˆ·ä»£ç†
		results:            make([]*Result, 0),
		externalLinks:      make([]string, 0),
		hiddenPaths:        make([]string, 0),
		securityFindings:   make([]string, 0),
		crossDomainJS:      make([]string, 0),
		detectedTechs:      make([]*TechInfo, 0),
		sensitiveFindings:  make([]*SensitiveInfo, 0),
		visitedURLs:        make(map[string]bool),
	}
	
	// é…ç½®å„ä¸ªç»„ä»¶
	spider.staticCrawler.Configure(cfg)
	spider.dynamicCrawler.Configure(cfg)
	
	// è®¾ç½®JSåˆ†æå™¨çš„ç›®æ ‡åŸŸå
	spider.jsAnalyzer.SetTargetDomain(cfg.TargetURL)
	
	return spider
}

// Start å¼€å§‹çˆ¬å–
func (s *Spider) Start(targetURL string) error {
	// è§£æç›®æ ‡URLå¹¶æå–åŸŸå
	parsedURL, err := url.Parse(targetURL)
	if err != nil {
		return fmt.Errorf("æ— æ•ˆçš„URL: %v", err)
	}
	s.targetDomain = parsedURL.Host
	
	// è®¾ç½®JSåˆ†æå™¨çš„ç›®æ ‡åŸŸå
	s.jsAnalyzer.SetTargetDomain(s.targetDomain)
	
	// åˆå§‹åŒ–é«˜çº§ä½œç”¨åŸŸæ§åˆ¶
	s.advancedScope = NewAdvancedScope(s.targetDomain)
	s.advancedScope.SetMode(ScopeRDN) // æ ¹åŸŸåæ¨¡å¼
	s.advancedScope.PresetStaticFilterScope() // è¿‡æ»¤é™æ€èµ„æº
	
	// åˆå§‹åŒ–å­åŸŸåæå–å™¨
	s.subdomainExtractor = NewSubdomainExtractor(targetURL)
	
	// æ£€æŸ¥æ˜¯å¦é‡å¤
	if s.duplicateHandler.IsDuplicateURL(targetURL) {
		return fmt.Errorf("URLå·²å¤„ç†è¿‡: %s", targetURL)
	}
	
	fmt.Printf("å¼€å§‹çˆ¬å–URL: %s\n", targetURL)
	fmt.Printf("é™åˆ¶åŸŸåèŒƒå›´: %s\n", s.targetDomain)
	fmt.Printf("\nã€å·²å¯ç”¨åŠŸèƒ½ã€‘\n")
	fmt.Printf("  âœ“ è·¨åŸŸJSåˆ†æï¼ˆæ”¯æŒ60+ä¸ªCDNï¼‰\n")
	fmt.Printf("  âœ“ æ™ºèƒ½è¡¨å•å¡«å……ï¼ˆæ”¯æŒ20+ç§å­—æ®µç±»å‹ï¼‰\n")
	fmt.Printf("  âœ“ ä½œç”¨åŸŸç²¾ç¡®æ§åˆ¶ï¼ˆ10ä¸ªè¿‡æ»¤ç»´åº¦ï¼‰\n")
	fmt.Printf("  âœ“ æ€§èƒ½ä¼˜åŒ–ï¼ˆå¯¹è±¡æ± +è¿æ¥æ± ï¼‰\n")
	fmt.Printf("  âœ“ æŠ€æœ¯æ ˆè¯†åˆ«ï¼ˆ15+ç§æ¡†æ¶ï¼‰\n")
	fmt.Printf("  âœ“ æ•æ„Ÿä¿¡æ¯æ£€æµ‹ï¼ˆ30+ç§æ¨¡å¼ï¼‰\n")
	fmt.Printf("  âœ“ JavaScriptäº‹ä»¶è§¦å‘ï¼ˆç‚¹å‡»ã€æ‚¬åœã€è¾“å…¥ã€æ»šåŠ¨ï¼‰ğŸ†•\n")
	fmt.Printf("\n")
	
	// åˆå§‹åŒ–éšè—è·¯å¾„å‘ç°å™¨
	userAgent := ""
	if len(s.config.AntiDetectionSettings.UserAgents) > 0 {
		userAgent = s.config.AntiDetectionSettings.UserAgents[0]
	}
	s.hiddenPathDiscovery = NewHiddenPathDiscovery(targetURL, userAgent)
	
	// å¼€å§‹éšè—è·¯å¾„å‘ç°
	fmt.Println("å¼€å§‹éšè—è·¯å¾„å‘ç°...")
	hiddenPaths := s.hiddenPathDiscovery.DiscoverAllHiddenPaths()
	s.mutex.Lock()
	s.hiddenPaths = append(s.hiddenPaths, hiddenPaths...)
	s.mutex.Unlock()
	fmt.Printf("å‘ç° %d ä¸ªéšè—è·¯å¾„\n", len(hiddenPaths))
	
	// æ ¹æ®é…ç½®å†³å®šä½¿ç”¨å“ªç§çˆ¬è™«ç­–ç•¥
	if s.config.StrategySettings.EnableStaticCrawler {
		fmt.Println("ä½¿ç”¨é™æ€çˆ¬è™«...")
		result, err := s.staticCrawler.Crawl(parsedURL)
		if err != nil {
			fmt.Printf("é™æ€çˆ¬è™«é”™è¯¯: %v\n", err)
		} else {
			s.addResult(result)
			fmt.Printf("é™æ€çˆ¬è™«å®Œæˆï¼Œå‘ç° %d ä¸ªé“¾æ¥, %d ä¸ªèµ„æº, %d ä¸ªè¡¨å•, %d ä¸ªAPI\n", 
				len(result.Links), len(result.Assets), len(result.Forms), len(result.APIs))
		}
	}
	
	// å¦‚æœå¯ç”¨äº†åŠ¨æ€çˆ¬è™«ä¸”é™æ€çˆ¬è™«æœªæ‰¾åˆ°è¶³å¤Ÿå†…å®¹ï¼Œä½¿ç”¨åŠ¨æ€çˆ¬è™«
	if s.config.StrategySettings.EnableDynamicCrawler && 
		(len(s.results) == 0 || s.shouldUseDynamicCrawler()) {
		fmt.Println("ä½¿ç”¨åŠ¨æ€çˆ¬è™«...")
		result, err := s.dynamicCrawler.Crawl(parsedURL)
		if err != nil {
			fmt.Printf("åŠ¨æ€çˆ¬è™«é”™è¯¯: %v\n", err)
		} else {
			s.addResult(result)
			fmt.Printf("åŠ¨æ€çˆ¬è™«å®Œæˆï¼Œå‘ç° %d ä¸ªé“¾æ¥, %d ä¸ªèµ„æº, %d ä¸ªè¡¨å•, %d ä¸ªAPI\n", 
				len(result.Links), len(result.Assets), len(result.Forms), len(result.APIs))
		}
	}
	
	// å¤„ç†å‘ç°çš„å‚æ•°
	s.processParams(targetURL)
	
	// åˆ†æè·¨åŸŸJSæ–‡ä»¶ï¼ˆåœ¨é€’å½’çˆ¬å–ä¹‹å‰ï¼‰
	s.processCrossDomainJS()
	
	// å¦‚æœå¯ç”¨äº†é€’å½’çˆ¬å–ï¼Œç»§ç»­çˆ¬å–å‘ç°çš„é“¾æ¥
	if s.config.DepthSettings.MaxDepth > 1 {
		s.crawlRecursively()
	}
	
	return nil
}

// shouldUseDynamicCrawler åˆ¤æ–­æ˜¯å¦éœ€è¦ä½¿ç”¨åŠ¨æ€çˆ¬è™«
func (s *Spider) shouldUseDynamicCrawler() bool {
	// å¦‚æœæ²¡æœ‰å‘ç°è¶³å¤Ÿçš„é“¾æ¥æˆ–APIï¼Œå¯èƒ½éœ€è¦åŠ¨æ€çˆ¬è™«
	if len(s.results) == 0 {
		return true
	}
	
	// æ£€æŸ¥æœ€è¿‘çš„ç»“æœ
	lastResult := s.results[len(s.results)-1]
	// é™ä½è§¦å‘åŠ¨æ€çˆ¬è™«çš„é˜ˆå€¼
	if len(lastResult.Links) < 10 && len(lastResult.APIs) < 5 {
		return true
	}
	
	return false
}

// addResult æ·»åŠ çˆ¬å–ç»“æœï¼ˆå¢å¼ºç‰ˆï¼šåŒ…å«æŠ€æœ¯æ ˆæ£€æµ‹å’Œæ•æ„Ÿä¿¡æ¯æ£€æµ‹ï¼‰
func (s *Spider) addResult(result *Result) {
	s.mutex.Lock()
	defer s.mutex.Unlock()
	
	s.results = append(s.results, result)
	
	// å¦‚æœæœ‰HTMLå†…å®¹ï¼Œè¿›è¡Œé«˜çº§æ£€æµ‹
	if result.HTMLContent != "" {
		// æŠ€æœ¯æ ˆæ£€æµ‹
		if s.techDetector != nil {
			techs := s.techDetector.DetectFromContent(result.HTMLContent, result.Headers)
			s.detectedTechs = append(s.detectedTechs, techs...)
			
			if len(techs) > 0 {
				techNames := make([]string, 0)
				for _, tech := range techs {
					if tech.Version != "" {
						techNames = append(techNames, tech.Name+" "+tech.Version)
					} else {
						techNames = append(techNames, tech.Name)
					}
				}
				fmt.Printf("  [æŠ€æœ¯æ ˆ] æ£€æµ‹åˆ°: %s\n", strings.Join(techNames, ", "))
			}
		}
		
		// æ•æ„Ÿä¿¡æ¯æ£€æµ‹
		if s.sensitiveDetector != nil {
			// æ‰«æHTMLå†…å®¹
			findings := s.sensitiveDetector.Scan(result.HTMLContent, result.URL)
			s.sensitiveFindings = append(s.sensitiveFindings, findings...)
			
			// æ‰«æHTTPå¤´
			if len(result.Headers) > 0 {
				headerContent := ""
				for key, value := range result.Headers {
					headerContent += key + ": " + value + "\n"
				}
				headerFindings := s.sensitiveDetector.Scan(headerContent, result.URL+" (Headers)")
				s.sensitiveFindings = append(s.sensitiveFindings, headerFindings...)
				findings = append(findings, headerFindings...)
			}
			
			if len(findings) > 0 {
				highCount := 0
				for _, finding := range findings {
					if finding.Severity == "HIGH" {
						highCount++
					}
				}
				
				if highCount > 0 {
					fmt.Printf("  [æ•æ„Ÿä¿¡æ¯] âš ï¸  å‘ç° %d å¤„é«˜å±æ•æ„Ÿä¿¡æ¯ï¼\n", highCount)
				} else if len(findings) > 0 {
					fmt.Printf("  [æ•æ„Ÿä¿¡æ¯] å‘ç° %d å¤„æ•æ„Ÿä¿¡æ¯\n", len(findings))
				}
			}
		}
	}
}

// addResultWithDetection æ·»åŠ ç»“æœå¹¶è¿›è¡Œæ£€æµ‹
func (s *Spider) addResultWithDetection(result *Result, response *http.Response, htmlContent string) {
	s.mutex.Lock()
	defer s.mutex.Unlock()
	
	s.results = append(s.results, result)
	
	// æŠ€æœ¯æ ˆæ£€æµ‹
	if response != nil && s.techDetector != nil {
		techs := s.techDetector.Detect(response, htmlContent)
		s.detectedTechs = append(s.detectedTechs, techs...)
		
		if len(techs) > 0 {
			fmt.Printf("  [æŠ€æœ¯æ ˆ] æ£€æµ‹åˆ°: ")
			techNames := make([]string, 0)
			for _, tech := range techs {
				if tech.Version != "" {
					techNames = append(techNames, tech.Name+" "+tech.Version)
				} else {
					techNames = append(techNames, tech.Name)
				}
			}
			fmt.Printf("%s\n", strings.Join(techNames, ", "))
		}
	}
	
	// æ•æ„Ÿä¿¡æ¯æ£€æµ‹
	if s.sensitiveDetector != nil {
		findings := s.sensitiveDetector.Scan(htmlContent, result.URL)
		s.sensitiveFindings = append(s.sensitiveFindings, findings...)
		
		if len(findings) > 0 {
			highCount := 0
			for _, finding := range findings {
				if finding.Severity == "HIGH" {
					highCount++
				}
			}
			
			if highCount > 0 {
				fmt.Printf("  [æ•æ„Ÿä¿¡æ¯] âš ï¸  å‘ç° %d å¤„é«˜å±æ•æ„Ÿä¿¡æ¯ï¼\n", highCount)
			} else {
				fmt.Printf("  [æ•æ„Ÿä¿¡æ¯] å‘ç° %d å¤„æ•æ„Ÿä¿¡æ¯\n", len(findings))
			}
		}
	}
	
	// å­åŸŸåæå–
	if s.subdomainExtractor != nil && htmlContent != "" {
		// ä»HTMLå†…å®¹æå–å­åŸŸå
		subdomains := s.subdomainExtractor.ExtractFromHTML(htmlContent)
		if len(subdomains) > 0 {
			fmt.Printf("  [å­åŸŸå] å‘ç° %d ä¸ªæ–°å­åŸŸå\n", len(subdomains))
		}
		
		// ä»URLæœ¬èº«æå–
		s.subdomainExtractor.ExtractFromURL(result.URL)
	}
}

// GetResults è·å–æ‰€æœ‰çˆ¬å–ç»“æœ
func (s *Spider) GetResults() []*Result {
	s.mutex.Lock()
	defer s.mutex.Unlock()
	
	// è¿”å›ç»“æœå‰¯æœ¬
	results := make([]*Result, len(s.results))
	copy(results, s.results)
	return results
}

// processParams å¤„ç†å‚æ•°å˜ä½“ç”Ÿæˆå’Œå®‰å…¨åˆ†æ
func (s *Spider) processParams(rawURL string) []string {
	// æå–å‚æ•°
	params, err := s.paramHandler.ExtractParams(rawURL)
	if err != nil {
		// å¦‚æœæå–å‚æ•°å¤±è´¥ï¼Œè‡³å°‘è¿”å›åŸå§‹URL
		return []string{rawURL}
	}
	
	// å¯¹æ¯ä¸ªå‚æ•°è¿›è¡Œå®‰å…¨åˆ†æ
	for paramName := range params {
		risk, level := s.paramHandler.AnalyzeParameterSecurity(paramName)
		if level >= 2 { // ä¸­ç­‰é£é™©ä»¥ä¸Š
			finding := fmt.Sprintf("SECURITY_PARAM: %s - %s (Risk Level: %d)", paramName, risk, level)
			s.mutex.Lock()
			s.securityFindings = append(s.securityFindings, finding)
			s.mutex.Unlock()
			fmt.Printf("å®‰å…¨å‘ç°: %s\n", finding)
		}
	}
	
	// ç”Ÿæˆå‚æ•°å˜ä½“
	variations := s.paramHandler.GenerateParamVariations(rawURL)
	
	// ç”Ÿæˆå®‰å…¨æµ‹è¯•å˜ä½“
	securityVariations := s.paramHandler.GenerateSecurityTestVariations(rawURL)
	variations = append(variations, securityVariations...)
	
	// å¦‚æœæ²¡æœ‰ç”Ÿæˆå˜ä½“ï¼Œè¿”å›åŸå§‹URL
	if len(variations) == 0 {
		return []string{rawURL}
	}
	
	// æ‰“å°ç”Ÿæˆçš„å˜ä½“
	fmt.Printf("ä¸ºURL %s ç”Ÿæˆ %d ä¸ªå‚æ•°å˜ä½“ï¼ˆåŒ…æ‹¬å®‰å…¨æµ‹è¯•ï¼‰\n", rawURL, len(variations))
	for i, variation := range variations {
		if i < 10 { // åªæ˜¾ç¤ºå‰10ä¸ªï¼Œé¿å…è¾“å‡ºè¿‡å¤š
			fmt.Printf("  å˜ä½“: %s\n", variation)
		}
	}
	if len(variations) > 10 {
		fmt.Printf("  ... è¿˜æœ‰ %d ä¸ªå˜ä½“\n", len(variations)-10)
	}
	
	return variations
}

// processCrossDomainJS å¤„ç†è·¨åŸŸJSæ–‡ä»¶
func (s *Spider) processCrossDomainJS() {
	fmt.Println("\nå¼€å§‹åˆ†æè·¨åŸŸJSæ–‡ä»¶...")
	
	// æ”¶é›†æ‰€æœ‰èµ„æºé“¾æ¥
	allAssets := make(map[string]bool)
	
	s.mutex.Lock()
	for _, result := range s.results {
		for _, asset := range result.Assets {
			allAssets[asset] = true
		}
		// ä¹Ÿæ£€æŸ¥Linksä¸­çš„JSæ–‡ä»¶
		for _, link := range result.Links {
			if strings.HasSuffix(strings.ToLower(link), ".js") {
				allAssets[link] = true
			}
		}
	}
	s.mutex.Unlock()
	
	// è¿‡æ»¤å‡ºéœ€è¦åˆ†æçš„JSæ–‡ä»¶
	jsToAnalyze := make([]string, 0)
	for asset := range allAssets {
		// æ£€æŸ¥æ˜¯å¦ä¸ºJSæ–‡ä»¶
		if !strings.HasSuffix(strings.ToLower(asset), ".js") {
			continue
		}
		
		// è§£æURL
		parsedURL, err := url.Parse(asset)
		if err != nil {
			continue
		}
		
		domain := parsedURL.Host
		if domain == "" {
			continue
		}
		
		// æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ†æ
		shouldAnalyze := false
		reason := ""
		
		// 1. æ˜¯ç›®æ ‡åŸŸå - å·²ç»æ­£å¸¸çˆ¬å–äº†ï¼Œä¸éœ€è¦ç‰¹æ®Šå¤„ç†
		if domain == s.targetDomain {
			continue
		}
		
		// 2. æ˜¯åŒæºåŸŸå
		if s.cdnDetector.IsSameBaseDomain(domain, s.targetDomain) {
			shouldAnalyze = true
			reason = "åŒæºåŸŸå"
		}
		
		// 3. æ˜¯å·²çŸ¥CDN
		if s.cdnDetector.IsCDN(domain) {
			shouldAnalyze = true
			cdnInfo := s.cdnDetector.GetCDNInfo(domain)
			reason = cdnInfo
		}
		
		if shouldAnalyze {
			jsToAnalyze = append(jsToAnalyze, asset)
			fmt.Printf("  å‘ç°è·¨åŸŸJS: %s (%s)\n", asset, reason)
		}
	}
	
	if len(jsToAnalyze) == 0 {
		fmt.Println("æœªå‘ç°éœ€è¦åˆ†æçš„è·¨åŸŸJSæ–‡ä»¶")
		return
	}
	
	fmt.Printf("å‡†å¤‡åˆ†æ %d ä¸ªè·¨åŸŸJSæ–‡ä»¶...\n", len(jsToAnalyze))
	
	// åˆ†ææ¯ä¸ªJSæ–‡ä»¶
	totalURLsFound := 0
	for _, jsURL := range jsToAnalyze {
		urls := s.analyzeExternalJS(jsURL)
		if len(urls) > 0 {
			fmt.Printf("  ä» %s æå–äº† %d ä¸ªURL\n", jsURL, len(urls))
			totalURLsFound += len(urls)
			
			// æ·»åŠ åˆ°è·¨åŸŸJSå‘ç°åˆ—è¡¨
			s.mutex.Lock()
			s.crossDomainJS = append(s.crossDomainJS, urls...)
			s.mutex.Unlock()
			
			// æ·»åŠ åˆ°çˆ¬å–é˜Ÿåˆ—ï¼ˆå¦‚æœå¯ç”¨é€’å½’çˆ¬å–ï¼‰
			if s.config.DepthSettings.MaxDepth > 1 {
				for _, u := range urls {
					// æ·»åŠ åˆ°ç»“æœä¸­ï¼ˆä½œä¸ºå‘ç°çš„é“¾æ¥ï¼‰
					if len(s.results) > 0 {
						s.results[0].Links = append(s.results[0].Links, u)
					}
				}
			}
		}
	}
	
	fmt.Printf("è·¨åŸŸJSåˆ†æå®Œæˆï¼å…±ä» %d ä¸ªJSæ–‡ä»¶ä¸­æå–äº† %d ä¸ªç›®æ ‡åŸŸåURL\n\n", len(jsToAnalyze), totalURLsFound)
}

// analyzeExternalJS ä¸‹è½½å¹¶åˆ†æå¤–éƒ¨JSæ–‡ä»¶ï¼ˆä½¿ç”¨æ€§èƒ½ä¼˜åŒ–ï¼‰
func (s *Spider) analyzeExternalJS(jsURL string) []string {
	// ä½¿ç”¨æ€§èƒ½ä¼˜åŒ–çš„HTTPå®¢æˆ·ç«¯
	req, err := http.NewRequest("GET", jsURL, nil)
	if err != nil {
		fmt.Printf("    åˆ›å»ºè¯·æ±‚å¤±è´¥: %v\n", err)
		return []string{}
	}
	
	// è®¾ç½®User-Agent
	if len(s.config.AntiDetectionSettings.UserAgents) > 0 {
		req.Header.Set("User-Agent", s.config.AntiDetectionSettings.UserAgents[0])
	} else {
		req.Header.Set("User-Agent", "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36")
	}
	
	// ä½¿ç”¨ä¼˜åŒ–çš„HTTPå®¢æˆ·ç«¯ï¼ˆå¸¦è¿æ¥æ± ï¼‰
	resp, err := s.perfOptimizer.DoRequest(req)
	if err != nil {
		fmt.Printf("    ä¸‹è½½å¤±è´¥: %v\n", err)
		return []string{}
	}
	defer resp.Body.Close()
	
	// æ£€æŸ¥çŠ¶æ€ç 
	if resp.StatusCode != 200 {
		fmt.Printf("    HTTP %d\n", resp.StatusCode)
		return []string{}
	}
	
	// ä½¿ç”¨Bufferæ± è¯»å–å†…å®¹
	buf := s.perfOptimizer.GetBuffer()
	defer s.perfOptimizer.PutBuffer(buf)
	
	// é™åˆ¶æ–‡ä»¶å¤§å°ï¼ˆæœ€å¤§5MBï¼‰
	const maxSize = 5 * 1024 * 1024
	limitedReader := &io.LimitedReader{R: resp.Body, N: maxSize}
	
	_, err = buf.ReadFrom(limitedReader)
	if err != nil {
		fmt.Printf("    è¯»å–å†…å®¹å¤±è´¥: %v\n", err)
		return []string{}
	}
	
	// ä½¿ç”¨JSåˆ†æå™¨æå–URL
	urls := s.jsAnalyzer.ExtractRelativeURLs(buf.String())
	
	return urls
}

// crawlRecursively é€’å½’çˆ¬å–å‘ç°çš„é“¾æ¥ï¼ˆå¹¶å‘ç‰ˆæœ¬ï¼‰
func (s *Spider) crawlRecursively() {
	fmt.Println("å¼€å§‹å¹¶å‘é€’å½’çˆ¬å–...")
	
	// æ”¶é›†æ‰€æœ‰å‘ç°çš„é“¾æ¥
	allLinks := make(map[string]bool)
	externalLinks := make([]string, 0)
	
	s.mutex.Lock()
	for _, result := range s.results {
		for _, link := range result.Links {
			// è§£æé“¾æ¥åŸŸå
			parsedURL, err := url.Parse(link)
			if err != nil {
				continue
			}
			
			// ä½¿ç”¨é«˜çº§ä½œç”¨åŸŸæ§åˆ¶
			inScope, reason := s.advancedScope.InScope(link)
			if inScope {
				// è§„èŒƒåŒ–URL
				normalizedURL, err := s.paramHandler.NormalizeURL(link)
				if err == nil {
					allLinks[normalizedURL] = true
				} else {
					allLinks[link] = true
				}
			} else {
				// è®°å½•å¤–éƒ¨é“¾æ¥æˆ–è¢«è¿‡æ»¤çš„é“¾æ¥
				if parsedURL.Host != s.targetDomain && parsedURL.Host != "" {
				externalLinks = append(externalLinks, link)
				}
				// å¯ä»¥è®°å½•è¢«è¿‡æ»¤çš„åŸå› ç”¨äºè°ƒè¯•
				_ = reason
			}
		}
	}
	s.mutex.Unlock()
	
	// è®°å½•å¤–éƒ¨é“¾æ¥
	if len(externalLinks) > 0 {
		s.mutex.Lock()
		s.externalLinks = append(s.externalLinks, externalLinks...)
		s.mutex.Unlock()
		fmt.Printf("å‘ç° %d ä¸ªå¤–éƒ¨é“¾æ¥ï¼ˆå·²è®°å½•ä½†ä¸çˆ¬å–ï¼‰\n", len(externalLinks))
	}
	
	// é™åˆ¶é€’å½’æ·±åº¦
	if s.config.DepthSettings.MaxDepth <= 1 {
		return
	}
	
	// è¿‡æ»¤å¹¶å‡†å¤‡å¾…çˆ¬å–çš„URL
	tasksToSubmit := make([]string, 0)
	for link := range allLinks {
		// æ£€æŸ¥æ˜¯å¦é‡å¤
		s.mutex.Lock()
		if s.visitedURLs[link] {
			s.mutex.Unlock()
			continue
		}
		s.visitedURLs[link] = true
		s.mutex.Unlock()
		
		// æ£€æŸ¥æ˜¯å¦å·²è¢«å»é‡å¤„ç†å™¨å¤„ç†è¿‡
		if s.duplicateHandler.IsDuplicateURL(link) {
			continue
		}
		
		// éªŒè¯é“¾æ¥æ ¼å¼
		if !IsValidURL(link) {
			continue
		}
		
		tasksToSubmit = append(tasksToSubmit, link)
		
		// é™åˆ¶æœ€å¤§çˆ¬å–æ•°é‡
		if len(tasksToSubmit) >= 100 {
			break
		}
	}
	
	if len(tasksToSubmit) == 0 {
		fmt.Println("æ²¡æœ‰éœ€è¦é€’å½’çˆ¬å–çš„é“¾æ¥")
		return
	}
	
	fmt.Printf("å‡†å¤‡å¹¶å‘çˆ¬å– %d ä¸ªé“¾æ¥...\n", len(tasksToSubmit))
	
	// å¯åŠ¨å·¥ä½œæ± 
	s.workerPool.Start(func(task Task) (*Result, error) {
		return s.crawlURL(task.URL)
	})
	
	// æäº¤æ‰€æœ‰ä»»åŠ¡
	for _, link := range tasksToSubmit {
		task := Task{
			URL:   link,
			Depth: s.config.DepthSettings.MaxDepth - 1,
		}
		if err := s.workerPool.Submit(task); err != nil {
			fmt.Printf("æäº¤ä»»åŠ¡å¤±è´¥ %s: %v\n", link, err)
		}
	}
	
	// æ˜¾ç¤ºè¿›åº¦
	go s.showProgress()
	
	// ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
	s.workerPool.Wait()
	
	// æ”¶é›†ç»“æœ
	results := s.workerPool.GetResults()
	s.mutex.Lock()
	s.results = append(s.results, results...)
	s.mutex.Unlock()
	
	// åœæ­¢å·¥ä½œæ± 
	s.workerPool.Stop()
	
	// æ˜¾ç¤ºç»Ÿè®¡
	stats := s.workerPool.GetStats()
	fmt.Printf("\nå¹¶å‘çˆ¬å–å®Œæˆï¼\n")
	fmt.Printf("  æ€»ä»»åŠ¡: %d\n", stats["total"])
	fmt.Printf("  æˆåŠŸ: %d\n", stats["completed"]-stats["failed"])
	fmt.Printf("  å¤±è´¥: %d\n", stats["failed"])
}

// crawlURL çˆ¬å–å•ä¸ªURLï¼ˆä¾›å·¥ä½œæ± ä½¿ç”¨ï¼‰
func (s *Spider) crawlURL(targetURL string) (*Result, error) {
	// è§£æURL
	parsedURL, err := url.Parse(targetURL)
	if err != nil {
		return nil, fmt.Errorf("URLè§£æå¤±è´¥: %v", err)
	}
	
	// ä½¿ç”¨é™æ€çˆ¬è™«
	result, err := s.staticCrawler.Crawl(parsedURL)
	if err != nil {
		// å¦‚æœé™æ€çˆ¬è™«å¤±è´¥ï¼Œå°è¯•åŠ¨æ€çˆ¬è™«
		if s.config.StrategySettings.EnableDynamicCrawler {
			result, err = s.dynamicCrawler.Crawl(parsedURL)
		if err != nil {
				return nil, fmt.Errorf("çˆ¬å–å¤±è´¥: %v", err)
			}
		} else {
			return nil, fmt.Errorf("é™æ€çˆ¬è™«å¤±è´¥: %v", err)
		}
	}
	
	return result, nil
}

// showProgress æ˜¾ç¤ºçˆ¬å–è¿›åº¦
func (s *Spider) showProgress() {
	ticker := time.NewTicker(2 * time.Second)
	defer ticker.Stop()
	
	for {
		select {
		case <-ticker.C:
			progress := s.workerPool.GetProgress()
			stats := s.workerPool.GetStats()
			
			// è®¡ç®—è¿›åº¦æ¡
			barWidth := 30
			filled := int(progress * float64(barWidth) / 100)
			bar := strings.Repeat("â–ˆ", filled) + strings.Repeat("â–‘", barWidth-filled)
			
			fmt.Printf("\r[è¿›åº¦] %s %.1f%% (%d/%d)", bar, progress, stats["completed"], stats["total"])
			
			if stats["completed"] >= stats["total"] {
				fmt.Println()
				return
			}
		}
	}
}

// ImportFromBurp ä»Burp Suiteæ–‡ä»¶å¯¼å…¥
func (s *Spider) ImportFromBurp(filename string) error {
	fmt.Printf("ä»Burp Suiteå¯¼å…¥æµé‡: %s\n", filename)
	
	// åˆ›å»ºè¢«åŠ¨çˆ¬å–å™¨
	s.passiveCrawler = NewPassiveCrawler("burp")
	
	// åŠ è½½Burpæ–‡ä»¶
	err := s.passiveCrawler.LoadFromBurp(filename)
	if err != nil {
		return err
	}
	
	// è¿‡æ»¤ç›®æ ‡åŸŸåçš„URL
	targetURLs := s.passiveCrawler.FilterByDomain(s.targetDomain)
	fmt.Printf("è¿‡æ»¤åå¾—åˆ°ç›®æ ‡åŸŸåURL: %dä¸ª\n", len(targetURLs))
	
	// å°†å¯¼å…¥çš„URLå’Œè¡¨å•åŠ å…¥ç»“æœ
	passiveResult := s.passiveCrawler.ExportToResult(s.targetDomain)
	s.addResult(passiveResult)
	
	return nil
}

// ImportFromHAR ä»HARæ–‡ä»¶å¯¼å…¥
func (s *Spider) ImportFromHAR(filename string) error {
	fmt.Printf("ä»HARæ–‡ä»¶å¯¼å…¥æµé‡: %s\n", filename)
	
	// åˆ›å»ºè¢«åŠ¨çˆ¬å–å™¨
	s.passiveCrawler = NewPassiveCrawler("har")
	
	// åŠ è½½HARæ–‡ä»¶
	err := s.passiveCrawler.LoadFromHAR(filename)
	if err != nil {
		return err
	}
	
	// è¿‡æ»¤ç›®æ ‡åŸŸåçš„URL
	targetURLs := s.passiveCrawler.FilterByDomain(s.targetDomain)
	fmt.Printf("è¿‡æ»¤åå¾—åˆ°ç›®æ ‡åŸŸåURL: %dä¸ª\n", len(targetURLs))
	
	// å°†å¯¼å…¥çš„URLå’Œè¡¨å•åŠ å…¥ç»“æœ
	passiveResult := s.passiveCrawler.ExportToResult(s.targetDomain)
	s.addResult(passiveResult)
	
	return nil
}

// Stop åœæ­¢çˆ¬å–
func (s *Spider) Stop() {
	fmt.Println("åœæ­¢çˆ¬å–...")
	s.staticCrawler.Stop()
	s.dynamicCrawler.Stop()
	
	// å…³é—­æ€§èƒ½ä¼˜åŒ–å™¨
	if s.perfOptimizer != nil {
		s.perfOptimizer.Close()
	}
}

// IsValidURL æ£€æŸ¥URLæ˜¯å¦ä¸ºæœ‰æ•ˆçš„HTTP/HTTPSé“¾æ¥
func IsValidURL(url string) bool {
	// æ£€æŸ¥æ˜¯å¦ä¸ºç©º
	if url == "" {
		return false
	}
	
	// æ£€æŸ¥æ˜¯å¦ä¸ºjavascript:æˆ–mailto:ç­‰éHTTPé“¾æ¥
	if strings.HasPrefix(url, "javascript:") || 
	   strings.HasPrefix(url, "mailto:") || 
	   strings.HasPrefix(url, "tel:") || 
	   strings.HasPrefix(url, "sms:") || 
	   strings.HasPrefix(url, "ftp:") || 
	   strings.HasPrefix(url, "file:") {
		return false
	}
	
	// æ£€æŸ¥æ˜¯å¦ä¸ºç›¸å¯¹é“¾æ¥ï¼ˆä¸åŒ…å«åè®®ï¼‰
	if !strings.Contains(url, "://") && !strings.HasPrefix(url, "//") {
		return true
	}
	
	// æ£€æŸ¥æ˜¯å¦ä¸ºHTTP/HTTPSåè®®
	if strings.HasPrefix(url, "http://") || strings.HasPrefix(url, "https://") {
		return true
	}
	
	// å…¶ä»–æƒ…å†µè§†ä¸ºæ— æ•ˆ
	return false
}

// ExportResults å¯¼å‡ºç»“æœ
func (s *Spider) ExportResults() map[string]interface{} {
	s.mutex.Lock()
	defer s.mutex.Unlock()
	
	exportData := make(map[string]interface{})
	exportData["total_results"] = len(s.results)
	
	// ç»Ÿè®¡ä¿¡æ¯
	totalLinks := 0
	totalAssets := 0
	totalForms := 0
	totalAPIs := 0
	
	// è¯¦ç»†ç»“æœæ•°æ®
	detailedResults := make([]map[string]interface{}, 0)
	allLinks := make([]string, 0)
	allAPIs := make([]string, 0)
	
	// ä½¿ç”¨æ™ºèƒ½å»é‡å¤„ç†æ‰€æœ‰URLå’Œè¡¨å•
	for _, result := range s.results {
		totalLinks += len(result.Links)
		totalAssets += len(result.Assets)
		totalForms += len(result.Forms)
		totalAPIs += len(result.APIs)
		
		// ä¿å­˜è¯¦ç»†ç»“æœ
		resultData := make(map[string]interface{})
		resultData["url"] = result.URL
		resultData["status_code"] = result.StatusCode
		resultData["content_type"] = result.ContentType
		resultData["links"] = result.Links
		resultData["assets"] = result.Assets
		resultData["forms"] = result.Forms
		resultData["apis"] = result.APIs
		detailedResults = append(detailedResults, resultData)
		
		// å¤„ç†é“¾æ¥è¿›è¡Œæ™ºèƒ½å»é‡
		for _, link := range result.Links {
			s.smartDeduplication.ProcessURL(link)
		}
		
		// å¤„ç†è¡¨å•è¿›è¡Œæ™ºèƒ½å»é‡
		for _, form := range result.Forms {
			s.smartDeduplication.ProcessForm(form)
		}
		
		// æ”¶é›†æ‰€æœ‰é“¾æ¥
		allLinks = append(allLinks, result.Links...)
		allAPIs = append(allAPIs, result.APIs...)
	}
	
	exportData["total_links"] = totalLinks
	exportData["total_assets"] = totalAssets
	exportData["total_forms"] = totalForms
	exportData["total_apis"] = totalAPIs
	exportData["detailed_results"] = detailedResults
	exportData["links"] = allLinks
	exportData["apis"] = allAPIs
	exportData["external_links"] = s.externalLinks
	exportData["hidden_paths"] = s.hiddenPaths
	exportData["security_findings"] = s.securityFindings
	exportData["cross_domain_js_urls"] = s.crossDomainJS
	exportData["total_hidden_paths"] = len(s.hiddenPaths)
	exportData["total_security_findings"] = len(s.securityFindings)
	exportData["total_cross_domain_js_urls"] = len(s.crossDomainJS)
	
	// æ·»åŠ æ™ºèƒ½å»é‡ç»Ÿè®¡
	exportData["deduplication_stats"] = s.smartDeduplication.GetDeduplicationStats()
	exportData["unique_url_patterns"] = s.smartDeduplication.GetUniqueURLs()
	exportData["unique_form_patterns"] = s.smartDeduplication.GetUniqueForms()
	
	// æ·»åŠ æ–°åŠŸèƒ½ç»Ÿè®¡
	if s.advancedScope != nil {
		exportData["scope_stats"] = s.advancedScope.GetStatistics()
	}
	if s.perfOptimizer != nil {
		exportData["performance_stats"] = s.perfOptimizer.GetStatistics()
	}
	if s.formFiller != nil {
		exportData["form_filler_stats"] = s.formFiller.GetStatistics()
	}
	
	// æ·»åŠ é«˜çº§åŠŸèƒ½ç»Ÿè®¡
	exportData["detected_technologies"] = s.detectedTechs
	exportData["tech_stack_summary"] = s.techDetector.GetTechStackSummary(s.detectedTechs)
	exportData["sensitive_findings"] = s.sensitiveFindings
	exportData["sensitive_stats"] = s.sensitiveDetector.GetStatistics()
	exportData["total_sensitive_findings"] = len(s.sensitiveFindings)
	
	// è¢«åŠ¨çˆ¬å–ç»Ÿè®¡ï¼ˆå¦‚æœä½¿ç”¨ï¼‰
	if s.passiveCrawler != nil {
		exportData["passive_stats"] = s.passiveCrawler.GetStatistics()
	}
	
	// å­åŸŸåæå–ç»Ÿè®¡
	if s.subdomainExtractor != nil {
		exportData["subdomains"] = s.subdomainExtractor.ExportSubdomains()
		exportData["subdomain_stats"] = s.subdomainExtractor.GetStatistics()
		exportData["total_subdomains"] = s.subdomainExtractor.GetSubdomainCount()
	}
	
	return exportData
}