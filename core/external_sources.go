package core

import (
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"net/url"
	"strings"
	"time"
)

// ExternalSourceConfig å¤–éƒ¨æ•°æ®æºé…ç½®
type ExternalSourceConfig struct {
	EnableWaybackMachine bool   // å¯ç”¨Wayback Machine
	EnableVirusTotal     bool   // å¯ç”¨VirusTotal
	EnableCommonCrawl    bool   // å¯ç”¨CommonCrawl
	
	VirusTotalAPIKey     string // VirusTotal APIå¯†é’¥
	MaxResultsPerSource  int    // æ¯ä¸ªæ•°æ®æºæœ€å¤§ç»“æœæ•°
	Timeout              int    // è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
}

// ExternalDataSource å¤–éƒ¨æ•°æ®æºæ¥å£
type ExternalDataSource interface {
	FetchURLs(domain string) ([]string, error)
	GetName() string
}

// WaybackMachineSource Wayback Machineæ•°æ®æº
type WaybackMachineSource struct {
	maxResults int
	timeout    time.Duration
	client     *http.Client
}

// NewWaybackMachineSource åˆ›å»ºWayback Machineæ•°æ®æº
func NewWaybackMachineSource(maxResults int, timeout time.Duration) *WaybackMachineSource {
	return &WaybackMachineSource{
		maxResults: maxResults,
		timeout:    timeout,
		client: &http.Client{
			Timeout: timeout,
		},
	}
}

// GetName è·å–æ•°æ®æºåç§°
func (wm *WaybackMachineSource) GetName() string {
	return "Wayback Machine"
}

// FetchURLs ä»Wayback Machineè·å–å†å²URL
func (wm *WaybackMachineSource) FetchURLs(domain string) ([]string, error) {
	// æ„å»ºAPI URL
	apiURL := fmt.Sprintf(
		"http://web.archive.org/cdx/search/cdx?url=%s/*&output=json&fl=original&collapse=urlkey&limit=%d",
		domain,
		wm.maxResults,
	)
	
	// å‘é€è¯·æ±‚
	resp, err := wm.client.Get(apiURL)
	if err != nil {
		return nil, fmt.Errorf("è¯·æ±‚Wayback Machineå¤±è´¥: %v", err)
	}
	defer resp.Body.Close()
	
	if resp.StatusCode != 200 {
		return nil, fmt.Errorf("Wayback Machineè¿”å›é”™è¯¯: %d", resp.StatusCode)
	}
	
	// è§£æJSONå“åº”
	var results [][]string
	if err := json.NewDecoder(resp.Body).Decode(&results); err != nil {
		return nil, fmt.Errorf("è§£æå“åº”å¤±è´¥: %v", err)
	}
	
	// æå–URLï¼ˆè·³è¿‡ç¬¬ä¸€è¡Œheaderï¼‰
	urls := make([]string, 0)
	for i, result := range results {
		if i == 0 {
			continue // è·³è¿‡header
		}
		if len(result) > 0 {
			urls = append(urls, result[0])
		}
	}
	
	return urls, nil
}

// VirusTotalSource VirusTotalæ•°æ®æº
type VirusTotalSource struct {
	apiKey     string
	maxResults int
	timeout    time.Duration
	client     *http.Client
}

// NewVirusTotalSource åˆ›å»ºVirusTotalæ•°æ®æº
func NewVirusTotalSource(apiKey string, maxResults int, timeout time.Duration) *VirusTotalSource {
	return &VirusTotalSource{
		apiKey:     apiKey,
		maxResults: maxResults,
		timeout:    timeout,
		client: &http.Client{
			Timeout: timeout,
		},
	}
}

// GetName è·å–æ•°æ®æºåç§°
func (vt *VirusTotalSource) GetName() string {
	return "VirusTotal"
}

// FetchURLs ä»VirusTotalè·å–URL
func (vt *VirusTotalSource) FetchURLs(domain string) ([]string, error) {
	if vt.apiKey == "" {
		return nil, fmt.Errorf("VirusTotal APIå¯†é’¥æœªé…ç½®")
	}
	
	// æ„å»ºAPI URL
	apiURL := fmt.Sprintf("https://www.virustotal.com/api/v3/domains/%s/urls?limit=%d", domain, vt.maxResults)
	
	// åˆ›å»ºè¯·æ±‚
	req, err := http.NewRequest("GET", apiURL, nil)
	if err != nil {
		return nil, err
	}
	
	// æ·»åŠ APIå¯†é’¥
	req.Header.Set("x-apikey", vt.apiKey)
	
	// å‘é€è¯·æ±‚
	resp, err := vt.client.Do(req)
	if err != nil {
		return nil, fmt.Errorf("è¯·æ±‚VirusTotalå¤±è´¥: %v", err)
	}
	defer resp.Body.Close()
	
	if resp.StatusCode != 200 {
		body, _ := io.ReadAll(resp.Body)
		return nil, fmt.Errorf("VirusTotalè¿”å›é”™è¯¯: %d, %s", resp.StatusCode, string(body))
	}
	
	// è§£æå“åº”
	var result struct {
		Data []struct {
			Attributes struct {
				URL string `json:"url"`
			} `json:"attributes"`
		} `json:"data"`
	}
	
	if err := json.NewDecoder(resp.Body).Decode(&result); err != nil {
		return nil, fmt.Errorf("è§£æå“åº”å¤±è´¥: %v", err)
	}
	
	// æå–URL
	urls := make([]string, 0)
	for _, item := range result.Data {
		if item.Attributes.URL != "" {
			urls = append(urls, item.Attributes.URL)
		}
	}
	
	return urls, nil
}

// CommonCrawlSource CommonCrawlæ•°æ®æº
type CommonCrawlSource struct {
	maxResults int
	timeout    time.Duration
	client     *http.Client
}

// NewCommonCrawlSource åˆ›å»ºCommonCrawlæ•°æ®æº
func NewCommonCrawlSource(maxResults int, timeout time.Duration) *CommonCrawlSource {
	return &CommonCrawlSource{
		maxResults: maxResults,
		timeout:    timeout,
		client: &http.Client{
			Timeout: timeout,
		},
	}
}

// GetName è·å–æ•°æ®æºåç§°
func (cc *CommonCrawlSource) GetName() string {
	return "CommonCrawl"
}

// FetchURLs ä»CommonCrawlè·å–URL
func (cc *CommonCrawlSource) FetchURLs(domain string) ([]string, error) {
	// CommonCrawl Index API
	apiURL := fmt.Sprintf(
		"http://index.commoncrawl.org/CC-MAIN-2024-10-index?url=%s&output=json&limit=%d",
		url.QueryEscape(domain+"/*"),
		cc.maxResults,
	)
	
	resp, err := cc.client.Get(apiURL)
	if err != nil {
		return nil, fmt.Errorf("è¯·æ±‚CommonCrawlå¤±è´¥: %v", err)
	}
	defer resp.Body.Close()
	
	if resp.StatusCode != 200 {
		return nil, fmt.Errorf("CommonCrawlè¿”å›é”™è¯¯: %d", resp.StatusCode)
	}
	
	// è¯»å–å“åº”
	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return nil, err
	}
	
	// CommonCrawlè¿”å›JSONLæ ¼å¼ï¼ˆæ¯è¡Œä¸€ä¸ªJSONï¼‰
	lines := strings.Split(string(body), "\n")
	urls := make([]string, 0)
	
	for _, line := range lines {
		if line == "" {
			continue
		}
		
		var result struct {
			URL string `json:"url"`
		}
		
		if err := json.Unmarshal([]byte(line), &result); err != nil {
			continue
		}
		
		if result.URL != "" {
			urls = append(urls, result.URL)
		}
	}
	
	return urls, nil
}

// ExternalSourceManager å¤–éƒ¨æ•°æ®æºç®¡ç†å™¨
type ExternalSourceManager struct {
	sources []ExternalDataSource
	config  ExternalSourceConfig
}

// NewExternalSourceManager åˆ›å»ºå¤–éƒ¨æ•°æ®æºç®¡ç†å™¨
func NewExternalSourceManager(config ExternalSourceConfig) *ExternalSourceManager {
	manager := &ExternalSourceManager{
		sources: make([]ExternalDataSource, 0),
		config:  config,
	}
	
	timeout := time.Duration(config.Timeout) * time.Second
	if timeout == 0 {
		timeout = 30 * time.Second
	}
	
	maxResults := config.MaxResultsPerSource
	if maxResults == 0 {
		maxResults = 1000
	}
	
	// æ ¹æ®é…ç½®æ·»åŠ æ•°æ®æº
	if config.EnableWaybackMachine {
		manager.sources = append(manager.sources,
			NewWaybackMachineSource(maxResults, timeout))
	}
	
	if config.EnableVirusTotal && config.VirusTotalAPIKey != "" {
		manager.sources = append(manager.sources,
			NewVirusTotalSource(config.VirusTotalAPIKey, maxResults, timeout))
	}
	
	if config.EnableCommonCrawl {
		manager.sources = append(manager.sources,
			NewCommonCrawlSource(maxResults, timeout))
	}
	
	return manager
}

// FetchAllURLs ä»æ‰€æœ‰æ•°æ®æºè·å–URL
func (esm *ExternalSourceManager) FetchAllURLs(domain string) map[string][]string {
	results := make(map[string][]string)
	
	for _, source := range esm.sources {
		fmt.Printf("ğŸ“¡ æ­£åœ¨ä» %s è·å–å†å²URL...\n", source.GetName())
		
		urls, err := source.FetchURLs(domain)
		if err != nil {
			fmt.Printf("  âš ï¸  %s è·å–å¤±è´¥: %v\n", source.GetName(), err)
			continue
		}
		
		results[source.GetName()] = urls
		fmt.Printf("  âœ… %s å‘ç° %d ä¸ªURL\n", source.GetName(), len(urls))
	}
	
	return results
}

// GetUniqueURLs è·å–å»é‡åçš„æ‰€æœ‰URL
func (esm *ExternalSourceManager) GetUniqueURLs(domain string) []string {
	allResults := esm.FetchAllURLs(domain)
	
	// ä½¿ç”¨mapå»é‡
	uniqueURLs := make(map[string]bool)
	for _, urls := range allResults {
		for _, url := range urls {
			uniqueURLs[url] = true
		}
	}
	
	// è½¬æ¢ä¸ºæ•°ç»„
	result := make([]string, 0, len(uniqueURLs))
	for url := range uniqueURLs {
		result = append(result, url)
	}
	
	return result
}

// PrintStatistics æ‰“å°ç»Ÿè®¡ä¿¡æ¯
func (esm *ExternalSourceManager) PrintStatistics(domain string) {
	results := esm.FetchAllURLs(domain)
	
	fmt.Println("\n" + strings.Repeat("=", 70))
	fmt.Println("          å¤–éƒ¨æ•°æ®æºç»Ÿè®¡")
	fmt.Println(strings.Repeat("=", 70))
	
	totalURLs := 0
	for source, urls := range results {
		fmt.Printf("%-20s: %d ä¸ªURL\n", source, len(urls))
		totalURLs += len(urls)
	}
	
	fmt.Println(strings.Repeat("-", 70))
	
	// å»é‡ç»Ÿè®¡
	uniqueURLs := make(map[string]bool)
	for _, urls := range results {
		for _, url := range urls {
			uniqueURLs[url] = true
		}
	}
	
	fmt.Printf("æ€»è®¡URL:              %d ä¸ª\n", totalURLs)
	fmt.Printf("å»é‡åURL:            %d ä¸ª\n", len(uniqueURLs))
	if totalURLs > 0 {
		deduplicationRate := float64(totalURLs-len(uniqueURLs)) / float64(totalURLs) * 100
		fmt.Printf("å»é‡ç‡:               %.1f%%\n", deduplicationRate)
	}
	
	fmt.Println(strings.Repeat("=", 70))
}

