# ğŸ”§ çˆ¬è™«ç¨‹åºå…¨é¢ä¿®å¤æ–¹æ¡ˆ - æŠ€æœ¯æ‰‹å†Œ

> **ä¸“å®¶è¯„å®¡**ï¼šGolang çˆ¬è™«/ç®—æ³•/æ¼æ´æŒ–æ˜ä¸“å®¶
> **æ—¥æœŸ**ï¼š2025å¹´10æœˆ27æ—¥
> **ç‰ˆæœ¬**ï¼šv1.0

---

## ğŸ“‹ ç›®å½•

1. [é«˜å±‚é—®é¢˜ç¡®è®¤](#1-é«˜å±‚é—®é¢˜ç¡®è®¤ä¸ä¸¥é‡åº¦è¯„ä¼°)
2. [é“¾æ¥æå–ä¸è§„èŒƒåŒ–](#2-é“¾æ¥æå–ä¸è§„èŒƒåŒ–)
3. [å‚æ•°æå–ä¸æ­£å¸¸åŒ–](#3-å‚æ•°æå–ä¸æ­£å¸¸åŒ–)
4. [è¿‡æ»¤ç­–ç•¥è®¾è®¡](#4-è¿‡æ»¤ç­–ç•¥è®¾è®¡)
5. [å¹¶å‘é˜Ÿåˆ—ä¸èµ„æºæ§åˆ¶](#5-å¹¶å‘é˜Ÿåˆ—ä¸èµ„æºæ§åˆ¶)
6. [å®‰å…¨åˆè§„æ³¨æ„](#6-å®‰å…¨åˆè§„æ³¨æ„)
7. [å•å…ƒæµ‹è¯•å»ºè®®](#7-å•å…ƒæµ‹è¯•é›†æˆæµ‹è¯•å»ºè®®)
8. [æœ€å°å¯è¿è¡Œä»£ç ](#8-æœ€å°å¯è¿è¡Œä»£ç ç‰‡æ®µ)
9. [ä¼˜å…ˆçº§ä¸è¿­ä»£è®¡åˆ’](#9-ä¼˜å…ˆçº§ä¸è¿­ä»£è®¡åˆ’)

---

## 1) é«˜å±‚é—®é¢˜ç¡®è®¤ä¸ä¸¥é‡åº¦è¯„ä¼°

### A. é“¾æ¥ä¸å‚æ•°æå–ï¼ˆä¸¥é‡åº¦ï¼šé«˜ âš ï¸ï¼‰

#### é—®é¢˜1.1ï¼šç¼ºå°‘`<base>`æ ‡ç­¾æ”¯æŒ
- **ä¸¥é‡åº¦**ï¼šé«˜
- **ä½ç½®**ï¼š`static_crawler.go:133`ä½¿ç”¨`e.Request.AbsoluteURL(link)`
- **è¯æ®**ï¼š
  ```html
  <!-- ç¤ºä¾‹é¡µé¢ -->
  <base href="/api/v2/">
  <a href="users">ç”¨æˆ·åˆ—è¡¨</a>
  ```
  å½“å‰è§£æä¸ºï¼š`/users`ï¼ˆé”™è¯¯ï¼‰
  æ­£ç¡®åº”ä¸ºï¼š`/api/v2/users`

- **æµ‹è¯•URL**ï¼š`https://x.lydaas.com/admin/panel.html`
- **ä¿®å¤ä¼˜å…ˆçº§**ï¼šP0ï¼ˆç«‹å³ä¿®å¤ï¼‰

#### é—®é¢˜1.2ï¼šç¼ºå°‘ä¸“ä¸šHTML tokenizer
- **ä¸¥é‡åº¦**ï¼šä¸­
- **ä½ç½®**ï¼š`url_extractor_fix.go:35`ä½¿ç”¨æ­£åˆ™`(https?://...)`
- **é—®é¢˜**ï¼š
  - æ— æ³•æ­£ç¡®å¤„ç†HTMLå®ä½“ï¼š`&lt;a href=&quot;test&quot;&gt;`
  - è¯¯æŠ¥CDATAä¸­çš„URL
  - æ³¨é‡Šä¸­çš„URLè¢«æå–ï¼š`<!-- TODO: http://example.com -->`

#### é—®é¢˜1.3ï¼šURLè§„èŒƒåŒ–ä¸å®Œæ•´
- **ä¸¥é‡åº¦**ï¼šé«˜
- **ç¼ºå¤±åŠŸèƒ½**ï¼š
  1. IDNåŸŸåè½¬Punycodeï¼ˆä¸­æ–‡åŸŸåï¼‰
  2. Percent-decodingè§„èŒƒåŒ–
  3. é‡å¤æ–œæ å¤„ç†ï¼š`//api///users` -> `/api/users`
  4. é»˜è®¤ç«¯å£å‰¥ç¦»ï¼š`:80`ã€`:443`

### B. é“¾æ¥/å‚æ•°è¿‡æ»¤ï¼ˆä¸¥é‡åº¦ï¼šé«˜ âš ï¸ï¼‰

#### é—®é¢˜2.1ï¼šTrackingå‚æ•°æœªè¿‡æ»¤
- **ä¸¥é‡åº¦**ï¼šä¸­
- **å½±å“**ï¼šåŒä¸€é¡µé¢å› trackingå‚æ•°ä¸åŒè¢«é‡å¤çˆ¬å–
- **ç¤ºä¾‹**ï¼š
  ```
  http://example.com/page?id=1&utm_source=google
  http://example.com/page?id=1&utm_source=facebook
  http://example.com/page?id=1&gclid=abc123
  ```
  åº”è§„èŒƒåŒ–ä¸ºï¼š`http://example.com/page?id=1`

- **å¸¸è§Trackingå‚æ•°**ï¼š
  ```
  utm_*  ç³»åˆ—ï¼šutm_source, utm_medium, utm_campaign, utm_content, utm_term
  å¹¿å‘Šè¿½è¸ªï¼šgclid, fbclid, msclkid, mc_cid, mc_eid
  åˆ†æå·¥å…·ï¼š_ga, _gid, _gac
  æ¨èæ¥æºï¼šref, referrer, source
  ```

#### é—®é¢˜2.2ï¼šæ•æ„Ÿå‚æ•°æ£€æµ‹è¯¯æŠ¥é«˜
- **ä¸¥é‡åº¦**ï¼šä¸­
- **ä½ç½®**ï¼š`param_handler.go:508`
- **é—®é¢˜ä»£ç **ï¼š
  ```go
  if strings.Contains(paramLower, "id") {
  	return "SQL_INJECTION: å¯èƒ½å­˜åœ¨SQLæ³¨å…¥æ¼æ´", 2
  }
  ```
- **è¯¯æŠ¥ç¤ºä¾‹**ï¼š
  ```
  video_id âŒ è¢«æ ‡è®°ä¸ºSQLæ³¨å…¥é£é™©
  grid_id  âŒ 
  uid      âŒ 
  valid    âŒ
  ```

### C. é¢å¤–å‘ç°çš„é—®é¢˜

#### é—®é¢˜3.1ï¼šç¼ºå°‘robots.txtè§£æ
- **ä¸¥é‡åº¦**ï¼šä¸­
- **åˆè§„é£é™©**ï¼šå¯èƒ½è¿åç½‘ç«™çˆ¬è™«åè®®
- **å»ºè®®**ï¼šå‚è€ƒ[robotstxt.orgè§„èŒƒ](https://www.robotstxt.org/)

#### é—®é¢˜3.2ï¼šæ•æ„Ÿæ•°æ®å­˜å‚¨æœªå®Œå…¨è„±æ•
- **ä¸¥é‡åº¦**ï¼šé«˜
- **ä½ç½®**ï¼š`sensitive_info_detector.go:177`
- **é£é™©ä»£ç **ï¼š
  ```go
  FullValue:  fullValue,  // å®Œæ•´æ•æ„Ÿä¿¡æ¯æœªåŠ å¯†å­˜å‚¨
  ```

---

## 2) é“¾æ¥æå–ä¸è§„èŒƒåŒ–ï¼ˆå¿…é¡»åŒ…å«ï¼‰

### 2.1 ç›¸å¯¹URLä¸`<base>`æ ‡ç­¾æ”¯æŒ

#### å®ç°ç­–ç•¥

```go
// core/url_resolver.go
package core

import (
	"net/url"
	"strings"
	"golang.org/x/net/html"
)

// URLResolver å®Œæ•´çš„URLè§£æå™¨
type URLResolver struct {
	baseURL     *url.URL  // å®é™…çš„base URL
	documentURL *url.URL  // æ–‡æ¡£URL
	baseHref    string    // HTML <base>æ ‡ç­¾çš„href
}

// NewURLResolver åˆ›å»ºURLè§£æå™¨
func NewURLResolver(documentURL string) (*URLResolver, error) {
	parsed, err := url.Parse(documentURL)
	if err != nil {
		return nil, err
	}
	
	return &URLResolver{
		baseURL:     parsed,
		documentURL: parsed,
	}, nil
}

// SetBaseHref è®¾ç½®HTML <base>æ ‡ç­¾çš„href
func (r *URLResolver) SetBaseHref(href string) error {
	if href == "" {
		r.baseHref = ""
		return nil
	}
	
	// è§£æbase hrefï¼ˆå¯ä»¥æ˜¯ç›¸å¯¹æˆ–ç»å¯¹URLï¼‰
	baseURL, err := r.documentURL.Parse(href)
	if err != nil {
		return err
	}
	
	r.baseURL = baseURL
	r.baseHref = href
	return nil
}

// ResolveURL è§£æç›¸å¯¹URLä¸ºç»å¯¹URL
func (r *URLResolver) ResolveURL(relativeURL string) (string, error) {
	trimmed := strings.TrimSpace(relativeURL)
	if trimmed == "" {
		return "", nil
	}
	
	// ä½¿ç”¨baseURLï¼ˆå¦‚æœè®¾ç½®äº†<base>åˆ™ä½¿ç”¨baseï¼Œå¦åˆ™ä½¿ç”¨documentURLï¼‰
	resolved, err := r.baseURL.Parse(trimmed)
	if err != nil {
		return "", err
	}
	
	return resolved.String(), nil
}

// ExtractBaseHref ä»HTMLä¸­æå–<base>æ ‡ç­¾çš„href
func ExtractBaseHref(htmlContent string) string {
	doc, err := html.Parse(strings.NewReader(htmlContent))
	if err != nil {
		return ""
	}
	
	var findBase func(*html.Node) string
	findBase = func(n *html.Node) string {
		if n.Type == html.ElementNode && n.Data == "base" {
			for _, attr := range n.Attr {
				if attr.Key == "href" {
					return attr.Val
				}
			}
		}
		for c := n.FirstChild; c != nil; c = c.NextSibling {
			if result := findBase(c); result != "" {
				return result
			}
		}
		return ""
	}
	
	return findBase(doc)
}
```

**ä½¿ç”¨ç¤ºä¾‹**ï¼š
```go
// åœ¨StaticCrawlerä¸­é›†æˆ
resolver, _ := NewURLResolver("https://example.com/admin/panel.html")

// æå–å¹¶è®¾ç½®baseæ ‡ç­¾
baseHref := ExtractBaseHref(htmlContent)
if baseHref != "" {
	resolver.SetBaseHref(baseHref)
	fmt.Printf("[BASE] æ£€æµ‹åˆ°<base>æ ‡ç­¾: %s\n", baseHref)
}

// è§£æç›¸å¯¹URL
absoluteURL, _ := resolver.ResolveURL("users")
// ç»“æœï¼šhttps://example.com/api/v2/usersï¼ˆå¦‚æœ<base href="/api/v2/">ï¼‰
```

### 2.2 HTML Tokenizationï¼ˆæ¨èåº“ï¼‰

#### æ–¹æ¡ˆ1ï¼šä½¿ç”¨æ ‡å‡†åº“ `golang.org/x/net/html`ï¼ˆæ¨è â­â­â­â­â­ï¼‰

**ä¼˜ç‚¹**ï¼š
- å®˜æ–¹æ ‡å‡†åº“ï¼Œç¨³å®šå¯é 
- å®Œæ•´çš„HTML5è§£æå™¨
- è‡ªåŠ¨å¤„ç†HTMLå®ä½“ã€CDATAã€æ³¨é‡Š

**å®‰è£…**ï¼š
```bash
go get golang.org/x/net/html
```

**ç¤ºä¾‹ä»£ç **ï¼š
```go
package core

import (
	"golang.org/x/net/html"
	"io"
	"strings"
)

// TokenBasedExtractor åŸºäºtokenizerçš„URLæå–å™¨
type TokenBasedExtractor struct{}

// URLWithContext å¸¦ä¸Šä¸‹æ–‡çš„URL
type URLWithContext struct {
	URL     string
	Context string // link, resource, form, meta-refreshç­‰
	Tag     string // æ ‡ç­¾å
}

// ExtractURLsFromHTML ä»HTMLä¸­æå–æ‰€æœ‰URL
func (e *TokenBasedExtractor) ExtractURLsFromHTML(htmlReader io.Reader) []URLWithContext {
	urls := make([]URLWithContext, 0)
	tokenizer := html.NewTokenizer(htmlReader)
	
	for {
		tokenType := tokenizer.Next()
		
		switch tokenType {
		case html.ErrorToken:
			return urls
			
		case html.StartTagToken, html.SelfClosingTagToken:
			token := tokenizer.Token()
			
			// æå–ä¸åŒæ ‡ç­¾çš„URLå±æ€§
			switch token.Data {
			case "a", "area", "link":
				urls = append(urls, extractAttr(token, "href", "link")...)
			case "img", "script", "iframe", "embed", "audio", "video", "source":
				urls = append(urls, extractAttr(token, "src", "resource")...)
			case "form":
				urls = append(urls, extractAttr(token, "action", "form")...)
			case "meta":
				// å¤„ç† <meta http-equiv="refresh" content="0;URL=http://..." />
				if isRefreshMeta(token) {
					if refreshURL := extractRefreshURL(token); refreshURL != "" {
						urls = append(urls, URLWithContext{
							URL:     refreshURL,
							Context: "meta-refresh",
							Tag:     "meta",
						})
					}
				}
			case "base":
				// å¤„ç†<base>æ ‡ç­¾
				urls = append(urls, extractAttr(token, "href", "base")...)
			case "object":
				urls = append(urls, extractAttr(token, "data", "resource")...)
			}
			
			// æå–styleå±æ€§ä¸­çš„URLï¼ˆbackground-imageç­‰ï¼‰
			if styleURLs := extractURLsFromStyle(token); len(styleURLs) > 0 {
				urls = append(urls, styleURLs...)
			}
		}
	}
}

func extractAttr(token html.Token, attrName, context string) []URLWithContext {
	for _, attr := range token.Attr {
		if attr.Key == attrName && attr.Val != "" {
			return []URLWithContext{{
				URL:     attr.Val,
				Context: context,
				Tag:     token.Data,
			}}
		}
	}
	return nil
}

func isRefreshMeta(token html.Token) bool {
	for _, attr := range token.Attr {
		if attr.Key == "http-equiv" && 
		   strings.EqualFold(attr.Val, "refresh") {
			return true
		}
	}
	return false
}

func extractRefreshURL(token html.Token) string {
	for _, attr := range token.Attr {
		if attr.Key == "content" {
			// content="0;URL='http://example.com'"
			parts := strings.Split(attr.Val, ";")
			for _, part := range parts {
				part = strings.TrimSpace(part)
				if strings.HasPrefix(strings.ToUpper(part), "URL=") {
					url := strings.TrimPrefix(part[4:], "'")
					url = strings.TrimSuffix(url, "'")
					url = strings.Trim(url, `"`)
					return url
				}
			}
		}
	}
	return ""
}

func extractURLsFromStyle(token html.Token) []URLWithContext {
	// ä»styleå±æ€§ä¸­æå–URLï¼šstyle="background-image: url('/img/bg.jpg')"
	for _, attr := range token.Attr {
		if attr.Key == "style" {
			// æ­£åˆ™åŒ¹é… url(...)
			re := regexp.MustCompile(`url\s*\(\s*['"]?([^'")]+)['"]?\s*\)`)
			matches := re.FindAllStringSubmatch(attr.Val, -1)
			
			var urls []URLWithContext
			for _, match := range matches {
				if len(match) > 1 {
					urls = append(urls, URLWithContext{
						URL:     match[1],
						Context: "css-inline",
						Tag:     token.Data,
					})
				}
			}
			return urls
		}
	}
	return nil
}
```

#### æ–¹æ¡ˆ2ï¼šä½¿ç”¨goqueryï¼ˆå·²åœ¨é¡¹ç›®ä¸­ï¼‰

**ä¼˜ç‚¹**ï¼š
- jQueryé£æ ¼è¯­æ³•ï¼Œæ˜“ç”¨
- å·²é›†æˆåœ¨`static_crawler.go`ä¸­

**ä¿æŒç°æœ‰ä»£ç **ï¼Œä½†å¢å¼ºé”™è¯¯å¤„ç†ï¼š
```go
// åœ¨static_crawler.goçš„ParseHTMLæ–¹æ³•ä¸­
collector.OnHTML("a[href]", func(e *colly.HTMLElement) {
	link := e.Attr("href")
	
	// è§£ç HTMLå®ä½“
	link = html.UnescapeString(link)
	
	// ... åç»­å¤„ç†
})
```

### 2.3 JSæ¸²æŸ“é¡µé¢å¤„ç†ç­–ç•¥

#### æ¨èï¼šæ··åˆç­–ç•¥ï¼ˆæŒ‰åœºæ™¯é€‰æ‹©ï¼‰

```go
package core

import (
	"regexp"
	"strings"
)

// JSRenderingStrategy JSæ¸²æŸ“ç­–ç•¥
type JSRenderingStrategy int

const (
	// StaticExtraction é™æ€æå–ï¼ˆæ­£åˆ™ï¼‰
	StaticExtraction JSRenderingStrategy = iota
	// EnhancedParsing å¢å¼ºè§£æï¼ˆASTåˆ†æï¼‰
	EnhancedParsing
	// HeadlessBrowser Headlessæµè§ˆå™¨ï¼ˆå®Œæ•´æ‰§è¡Œï¼‰
	HeadlessBrowser
)

// ShouldUseHeadless åˆ¤æ–­æ˜¯å¦åº”è¯¥ä½¿ç”¨Headlessæµè§ˆå™¨
func ShouldUseHeadless(htmlContent string) bool {
	// æ£€æµ‹SPAæ¡†æ¶ç‰¹å¾
	spaFrameworks := []string{
		"<div id=\"app\">",        // Vue
		"<div id=\"root\">",       // React
		"ng-app",                  // Angular
		"data-reactroot",          // React
		"__NEXT_DATA__",           // Next.js
	}
	
	for _, pattern := range spaFrameworks {
		if strings.Contains(htmlContent, pattern) {
			return true
		}
	}
	
	// æ£€æµ‹å¤§é‡AJAXè°ƒç”¨
	ajaxCount := strings.Count(htmlContent, "fetch(") +
		strings.Count(htmlContent, "$.ajax") +
		strings.Count(htmlContent, "axios.")
	
	if ajaxCount > 10 {
		return true
	}
	
	return false
}

// EnhancedJSAnalyzer å¢å¼ºçš„JSåˆ†æå™¨
type EnhancedJSAnalyzer struct {
	patterns []*JSURLPattern
}

type JSURLPattern struct {
	Name    string
	Pattern *regexp.Regexp
	Extract func(match []string) string
}

func NewEnhancedJSAnalyzer() *EnhancedJSAnalyzer {
	analyzer := &EnhancedJSAnalyzer{
		patterns: make([]*JSURLPattern, 0),
	}
	
	// 1. Fetch API
	analyzer.AddPattern("fetch",
		`fetch\s*\(\s*['"\x60]([^'"\x60]+)['"\x60]`,
		func(match []string) string { return match[1] })
	
	// 2. XMLHttpRequest
	analyzer.AddPattern("xhr.open",
		`xhr\.open\s*\(\s*['"](?:GET|POST|PUT|DELETE)['"],\s*['"\x60]([^'"\x60]+)['"\x60]`,
		func(match []string) string { return match[1] })
	
	// 3. Axios
	analyzer.AddPattern("axios",
		`axios\.\w+\s*\(\s*['"\x60]([^'"\x60]+)['"\x60]`,
		func(match []string) string { return match[1] })
	
	// 4. jQuery AJAX
	analyzer.AddPattern("jquery.ajax",
		`\$\.(?:ajax|get|post)\s*\(\s*['"\x60]([^'"\x60]+)['"\x60]`,
		func(match []string) string { return match[1] })
	
	// 5. åŠ¨æ€import (ES6)
	analyzer.AddPattern("dynamic-import",
		`import\s*\(\s*['"\x60]([^'"\x60]+)['"\x60]\s*\)`,
		func(match []string) string { return match[1] })
	
	// 6. new URL()
	analyzer.AddPattern("new-url",
		`new\s+URL\s*\(\s*['"\x60]([^'"\x60]+)['"\x60]`,
		func(match []string) string { return match[1] })
	
	// 7. Router (Vue/React)
	analyzer.AddPattern("router.push",
		`(?:router\.push|history\.pushState)\s*\([^)]*['"\x60]([^'"\x60]+)['"\x60]`,
		func(match []string) string { return match[1] })
	
	// 8. locationæ“ä½œ
	analyzer.AddPattern("location",
		`(?:window\.)?location\.(?:href|assign|replace)\s*=?\s*['"\x60]([^'"\x60]+)['"\x60]`,
		func(match []string) string { return match[1] })
	
	// 9. APIé…ç½®å¯¹è±¡
	analyzer.AddPattern("api-config",
		`(?:apiUrl|baseURL|endpoint|API_BASE)\s*[:=]\s*['"\x60]([^'"\x60]+)['"\x60]`,
		func(match []string) string { return match[1] })
	
	// 10. æ¨¡æ¿å­—ç¬¦ä¸²ä¸­çš„URL
	analyzer.AddPattern("template-literal",
		"`([^`]*(?:https?://|/api/|/v\\d+/)[^`]*)`",
		func(match []string) string { return match[1] })
	
	return analyzer
}

func (a *EnhancedJSAnalyzer) AddPattern(name, pattern string, extractor func([]string) string) {
	re := regexp.MustCompile(pattern)
	a.patterns = append(a.patterns, &JSURLPattern{
		Name:    name,
		Pattern: re,
		Extract: extractor,
	})
}

func (a *EnhancedJSAnalyzer) ExtractURLs(jsCode string) []string {
	urls := make([]string, 0)
	seen := make(map[string]bool)
	
	for _, p := range a.patterns {
		matches := p.Pattern.FindAllStringSubmatch(jsCode, -1)
		for _, match := range matches {
			if len(match) > 1 {
				url := p.Extract(match)
				url = strings.Trim(url, `"'\x60 `)
				
				// è¿‡æ»¤å˜é‡
				if !isLikelyVariable(url) && !seen[url] {
					seen[url] = true
					urls = append(urls, url)
				}
			}
		}
	}
	
	return urls
}

func isLikelyVariable(s string) bool {
	// åŒ…å«æ¨¡æ¿è¯­æ³•
	if strings.Contains(s, "${") || strings.Contains(s, "#{") {
		return true
	}
	// åŒ…å«æ‹¼æ¥ç¬¦å·
	if strings.Contains(s, " + ") || strings.Contains(s, " . ") {
		return true
	}
	// å…¨å¤§å†™ä¸”ä¸åƒURL
	if s == strings.ToUpper(s) && !strings.Contains(s, "/") {
		return true
	}
	// åŒ…å«æ˜æ˜¾çš„å˜é‡å
	varNames := []string{"${", "{{", "}}", "undefined", "null"}
	for _, vn := range varNames {
		if strings.Contains(s, vn) {
			return true
		}
	}
	return false
}
```

**ä½•æ—¶ä½¿ç”¨Headlessæµè§ˆå™¨**ï¼š
```go
// ä½¿ç”¨chromedpç¤ºä¾‹ï¼ˆä»…åœ¨å¿…è¦æ—¶ï¼‰
import (
	"context"
	"github.com/chromedp/chromedp"
	"time"
)

func RenderWithHeadless(targetURL string) (string, []string, error) {
	ctx, cancel := chromedp.NewContext(context.Background())
	defer cancel()
	
	// è®¾ç½®è¶…æ—¶
	ctx, cancel = context.WithTimeout(ctx, 30*time.Second)
	defer cancel()
	
	var htmlContent string
	var discoveredURLs []string
	
	err := chromedp.Run(ctx,
		chromedp.Navigate(targetURL),
		chromedp.WaitVisible("body", chromedp.ByQuery),
		chromedp.Sleep(2*time.Second), // ç­‰å¾…AJAX
		chromedp.OuterHTML("html", &htmlContent),
		
		// æå–æ‰€æœ‰é“¾æ¥
		chromedp.Evaluate(`
			Array.from(document.querySelectorAll('a[href]'))
				.map(a => a.href)
		`, &discoveredURLs),
	)
	
	return htmlContent, discoveredURLs, err
}
```

### 2.4 URLè§£æç»†èŠ‚å®ç°

#### ä½¿ç”¨net/url.Parseã€ResolveReferenceã€path.Clean

å·²åœ¨`core/url_canonicalizer.go`ä¸­å®ç°ï¼Œå…³é”®ä»£ç ï¼š

```go
// 1. URLè§£æ
parsedURL, err := url.Parse(rawURL)

// 2. ç›¸å¯¹URLè§£æ
baseURL, _ := url.Parse("https://example.com/dir/page.html")
relativeURL, _ := url.Parse("../other/file.html")
absoluteURL := baseURL.ResolveReference(relativeURL)
// ç»“æœï¼šhttps://example.com/other/file.html

// 3. è·¯å¾„æ¸…ç†
cleanPath := path.Clean(parsedURL.Path)
// "/api//users/../admin" -> "/api/admin"
```

#### IDN -> Punycode (golang.org/x/net/idna)

**å®‰è£…**ï¼š
```bash
go get golang.org/x/net/idna
```

**ä½¿ç”¨ç¤ºä¾‹**ï¼š
```go
import "golang.org/x/net/idna"

// ä¸­æ–‡åŸŸåè½¬Punycode
domain := "ä¸­æ–‡.com"
punycode, err := idna.ToASCII(domain)
// ç»“æœï¼šxn--fiq228c.com

// Punycodeè½¬ä¸­æ–‡
unicode, err := idna.ToUnicode("xn--fiq228c.com")
// ç»“æœï¼šä¸­æ–‡.com
```

### 2.5 è§„èŒƒåŒ–ç­–ç•¥æ€»ç»“

| æ“ä½œ | ç¤ºä¾‹ | å®ç°æ–¹æ³• |
|------|------|----------|
| **Percent-decoding** | `hello%20world` | è§`normalizePercentEncoding()` |
| **é‡å¤æ–œæ ** | `//api///users` -> `/api/users` | `path.Clean()` |
| **å°¾æ–œæ ** | `/api/users/` -> `/api/users` | å¯é€‰ï¼Œè§†éœ€æ±‚ |
| **é»˜è®¤ç«¯å£** | `:80`, `:443` ç§»é™¤ | è§`stripDefaultPort` |
| **åè®®è§„èŒƒ** | `http` -> `https` (å¯é€‰) | è§`normalizeProtocol` |
| **åŸŸåå°å†™** | `Example.COM` -> `example.com` | `strings.ToLower()` |
| **å‚æ•°æ’åº** | `?b=2&a=1` -> `?a=1&b=2` | è§`sortQueryString()` |

---

## 3) å‚æ•°æå–ä¸æ­£å¸¸åŒ–ï¼ˆå¿…é¡»åŒ…å«ï¼‰

### 3.1 Queryå‚æ•°æå–ï¼ˆurl.ParseQueryï¼‰

```go
package core

import (
	"net/url"
	"sort"
	"strings"
)

// ParamExtractor å‚æ•°æå–å™¨
type ParamExtractor struct{}

// ExtractQueryParams æå–URLæŸ¥è¯¢å‚æ•°
func (e *ParamExtractor) ExtractQueryParams(rawURL string) (map[string][]string, error) {
	parsedURL, err := url.Parse(rawURL)
	if err != nil {
		return nil, err
	}
	
	// ä½¿ç”¨æ ‡å‡†åº“è§£æ
	params := parsedURL.Query()
	
	return params, nil
}

// ExtractQueryParamsString ä»æŸ¥è¯¢å­—ç¬¦ä¸²ç›´æ¥æå–
func (e *ParamExtractor) ExtractQueryParamsString(queryString string) (map[string][]string, error) {
	// ç§»é™¤å‰å¯¼?
	queryString = strings.TrimPrefix(queryString, "?")
	
	params, err := url.ParseQuery(queryString)
	if err != nil {
		return nil, err
	}
	
	return params, nil
}
```

### 3.2 POST/PUT form-bodyã€JSON bodyå‚æ•°æå–

```go
import (
	"encoding/json"
	"io"
	"mime"
	"net/http"
	"net/url"
	"strings"
)

// ExtractPOSTParams æå–POSTè¯·æ±‚å‚æ•°
func (e *ParamExtractor) ExtractPOSTParams(req *http.Request) (map[string][]string, error) {
	contentType, _, err := mime.ParseMediaType(req.Header.Get("Content-Type"))
	if err != nil {
		contentType = "application/x-www-form-urlencoded" // é»˜è®¤
	}
	
	switch contentType {
	case "application/x-www-form-urlencoded":
		// Formè¡¨å•
		if err := req.ParseForm(); err != nil {
			return nil, err
		}
		return req.PostForm, nil
		
	case "multipart/form-data":
		// æ–‡ä»¶ä¸Šä¼ è¡¨å•
		if err := req.ParseMultipartForm(32 << 20); err != nil { // 32MBé™åˆ¶
			return nil, err
		}
		return req.MultipartForm.Value, nil
		
	case "application/json":
		// JSON body
		return e.extractJSONParams(req.Body)
		
	default:
		// å°è¯•ä½œä¸ºformè§£æ
		if err := req.ParseForm(); err == nil {
			return req.PostForm, nil
		}
		return nil, fmt.Errorf("unsupported content-type: %s", contentType)
	}
}

// extractJSONParams ä»JSON bodyä¸­æå–å‚æ•°
func (e *ParamExtractor) extractJSONParams(body io.Reader) (map[string][]string, error) {
	var jsonData map[string]interface{}
	
	if err := json.NewDecoder(body).Decode(&jsonData); err != nil {
		return nil, err
	}
	
	// è½¬æ¢ä¸ºurl.Valuesæ ¼å¼
	params := make(map[string][]string)
	e.flattenJSON(jsonData, "", params)
	
	return params, nil
}

// flattenJSON é€’å½’å±•å¹³JSONï¼ˆå¤„ç†åµŒå¥—å¯¹è±¡ï¼‰
func (e *ParamExtractor) flattenJSON(data interface{}, prefix string, result map[string][]string) {
	switch v := data.(type) {
	case map[string]interface{}:
		for key, val := range v {
			newPrefix := key
			if prefix != "" {
				newPrefix = prefix + "." + key
			}
			e.flattenJSON(val, newPrefix, result)
		}
		
	case []interface{}:
		for i, val := range v {
			newPrefix := prefix + "[" + fmt.Sprintf("%d", i) + "]"
			e.flattenJSON(val, newPrefix, result)
		}
		
	default:
		// åŸºæœ¬ç±»å‹
		result[prefix] = append(result[prefix], fmt.Sprintf("%v", v))
	}
}

// ExtractURLsFromJSON JSONä¸­çš„URLæå–
func (e *ParamExtractor) ExtractURLsFromJSON(jsonBody string) []string {
	urls := make([]string, 0)
	seen := make(map[string]bool)
	
	// æ­£åˆ™åŒ¹é…URL
	urlPattern := regexp.MustCompile(`"(https?://[^"]+)"`)
	pathPattern := regexp.MustCompile(`"(/[a-zA-Z0-9/_\-\.]+)"`)
	
	// æå–å®Œæ•´URL
	for _, match := range urlPattern.FindAllStringSubmatch(jsonBody, -1) {
		if len(match) > 1 && !seen[match[1]] {
			seen[match[1]] = true
			urls = append(urls, match[1])
		}
	}
	
	// æå–APIè·¯å¾„
	for _, match := range pathPattern.FindAllStringSubmatch(jsonBody, -1) {
		if len(match) > 1 && !seen[match[1]] {
			// åˆ¤æ–­æ˜¯å¦åƒAPIè·¯å¾„
			if strings.HasPrefix(match[1], "/api/") ||
			   regexp.MustCompile(`^/v\d+/`).MatchString(match[1]) {
				seen[match[1]] = true
				urls = append(urls, match[1])
			}
		}
	}
	
	return urls
}
```

### 3.3 Queryå‚æ•°æ’åº/å»é‡ç­–ç•¥

```go
// NormalizeQueryParams è§„èŒƒåŒ–æŸ¥è¯¢å‚æ•°
func NormalizeQueryParams(params url.Values) string {
	if len(params) == 0 {
		return ""
	}
	
	// 1. æå–æ‰€æœ‰é”®å¹¶æ’åº
	keys := make([]string, 0, len(params))
	for k := range params {
		keys = append(keys, k)
	}
	sort.Strings(keys)
	
	// 2. æ„å»ºè§„èŒƒåŒ–çš„æŸ¥è¯¢å­—ç¬¦ä¸²
	var parts []string
	for _, k := range keys {
		// å¯¹åŒä¸€é”®çš„å¤šä¸ªå€¼ä¹Ÿæ’åº
		values := params[k]
		sort.Strings(values)
		
		// å»é‡
		uniqueValues := removeDuplicates(values)
		
		for _, v := range uniqueValues {
			parts = append(parts, url.QueryEscape(k)+"="+url.QueryEscape(v))
		}
	}
	
	return strings.Join(parts, "&")
}

func removeDuplicates(values []string) []string {
	seen := make(map[string]bool)
	result := make([]string, 0)
	
	for _, v := range values {
		if !seen[v] {
			seen[v] = true
			result = append(result, v)
		}
	}
	
	return result
}
```

### 3.4 Trackingå‚æ•°è¿‡æ»¤

```go
// TrackingParamFilter Trackingå‚æ•°è¿‡æ»¤å™¨
type TrackingParamFilter struct {
	trackingParams map[string]bool
}

func NewTrackingParamFilter() *TrackingParamFilter {
	f := &TrackingParamFilter{
		trackingParams: make(map[string]bool),
	}
	
	// é»˜è®¤Trackingå‚æ•°åˆ—è¡¨
	defaultTracking := []string{
		// Google Analytics
		"utm_source", "utm_medium", "utm_campaign", "utm_content", "utm_term",
		"_ga", "_gid", "_gac", "_gl",
		
		// å¹¿å‘Šå¹³å°
		"gclid",    // Google Ads
		"fbclid",   // Facebook
		"msclkid",  // Microsoft Advertising
		"mc_cid",   // Mailchimp Campaign ID
		"mc_eid",   // Mailchimp Email ID
		
		// ç¤¾äº¤åª’ä½“
		"igshid",   // Instagram
		"twclid",   // Twitter
		
		// å…¶ä»–å¸¸è§
		"ref", "referrer", "source", "campaign_id",
		"ad_id", "adgroup_id", "creative_id",
		"fbadid", "wickedid",
	}
	
	for _, p := range defaultTracking {
		f.trackingParams[strings.ToLower(p)] = true
	}
	
	return f
}

// FilterParams è¿‡æ»¤trackingå‚æ•°
func (f *TrackingParamFilter) FilterParams(params url.Values) url.Values {
	filtered := make(url.Values)
	
	for k, v := range params {
		if !f.trackingParams[strings.ToLower(k)] {
			filtered[k] = v
		}
	}
	
	return filtered
}

// AddTrackingParam æ·»åŠ è‡ªå®šä¹‰trackingå‚æ•°
func (f *TrackingParamFilter) AddTrackingParam(param string) {
	f.trackingParams[strings.ToLower(param)] = true
}

// IsTrackingParam åˆ¤æ–­æ˜¯å¦ä¸ºtrackingå‚æ•°
func (f *TrackingParamFilter) IsTrackingParam(param string) bool {
	return f.trackingParams[strings.ToLower(param)]
}
```

**å¯æ‰©å±•é…ç½®**ï¼ˆJSONæ ¼å¼ï¼‰ï¼š
```json
{
  "tracking_params": {
    "enabled": true,
    "default_list": [
      "utm_source", "utm_medium", "utm_campaign", "utm_content", "utm_term",
      "gclid", "fbclid", "msclkid", "mc_cid", "mc_eid",
      "_ga", "_gid", "ref", "referrer"
    ],
    "custom_list": [
      "custom_param1",
      "custom_param2"
    ]
  }
}
```

### 3.5 æ•æ„Ÿå‚æ•°æ£€æµ‹ï¼ˆä½è¯¯æŠ¥ï¼‰

```go
package core

import (
	"regexp"
	"strings"
)

// SensitiveParamDetector æ•æ„Ÿå‚æ•°æ£€æµ‹å™¨
type SensitiveParamDetector struct {
	patterns []*ParamPattern
}

type ParamPattern struct {
	Name      string
	Pattern   *regexp.Regexp
	Severity  string // HIGH, MEDIUM, LOW
	Category  string // auth, sensitive, dangerous
}

func NewSensitiveParamDetector() *SensitiveParamDetector {
	d := &SensitiveParamDetector{
		patterns: make([]*ParamPattern, 0),
	}
	
	// === é«˜ç²¾åº¦æ¨¡å¼ï¼šé¿å…è¯¯æŠ¥ ===
	
	// 1. è®¤è¯ç›¸å…³ï¼ˆé«˜å±ï¼‰
	d.AddPattern("token", `^(token|access_token|auth_token|csrf_token|xsrf_token)$`, "HIGH", "auth")
	d.AddPattern("api_key", `^(api_key|apikey|app_key|appkey)$`, "HIGH", "auth")
	d.AddPattern("secret", `^(secret|client_secret|app_secret|api_secret)$`, "HIGH", "auth")
	d.AddPattern("password", `^(password|passwd|pwd|pass)$`, "HIGH", "auth")
	d.AddPattern("auth", `^(authorization|auth|authenticate)$`, "MEDIUM", "auth")
	
	// 2. ä¼šè¯ç›¸å…³ï¼ˆä¸­å±ï¼‰
	d.AddPattern("session", `^(session|session_id|sessionid|sid)$`, "MEDIUM", "sensitive")
	d.AddPattern("cookie", `^(cookie|set_cookie)$`, "MEDIUM", "sensitive")
	
	// 3. æ•æ„Ÿä¿¡æ¯ï¼ˆä¸­å±ï¼‰
	d.AddPattern("email", `^(email|e_mail|mail)$`, "MEDIUM", "sensitive")
	d.AddPattern("phone", `^(phone|telephone|mobile|cellphone)$`, "MEDIUM", "sensitive")
	d.AddPattern("ssn", `^(ssn|social_security|id_card|identity)$`, "HIGH", "sensitive")
	d.AddPattern("card", `^(credit_card|card_number|card_no|cvv|cvc)$`, "HIGH", "sensitive")
	
	// 4. å±é™©æ“ä½œï¼ˆé«˜å± - ç²¾ç¡®åŒ¹é…ï¼‰
	d.AddPattern("cmd", `^(cmd|command|exec|execute|system|shell)$`, "HIGH", "dangerous")
	d.AddPattern("eval", `^(eval|code|script|function)$`, "HIGH", "dangerous")
	
	// 5. æ–‡ä»¶æ“ä½œï¼ˆé«˜å± - ç²¾ç¡®åŒ¹é…ï¼Œé¿å…è¯¯æŠ¥ï¼‰
	d.AddPattern("file_path", `^(file|filename|filepath|path|dir|directory)$`, "HIGH", "dangerous")
	d.AddPattern("upload", `^(upload|download|read|write|include|require)$`, "MEDIUM", "dangerous")
	
	// 6. SQLæ³¨å…¥é£é™©ï¼ˆä½å± - æ›´ç²¾ç¡®çš„æ¨¡å¼ï¼‰
	// æ³¨æ„ï¼šåªåŒ¹é…å•ç‹¬çš„"id"ï¼Œä¸åŒ¹é…"valid"ã€"video_id"ç­‰
	d.AddPattern("sql_param", `^(id|user_id|uid|account_id)$`, "LOW", "sql")
	
	return d
}

func (d *SensitiveParamDetector) AddPattern(name, pattern, severity, category string) {
	re := regexp.MustCompile(pattern)
	d.patterns = append(d.patterns, &ParamPattern{
		Name:     name,
		Pattern:  re,
		Severity: severity,
		Category: category,
	})
}

// DetectParam æ£€æµ‹å‚æ•°æ•æ„Ÿæ€§
func (d *SensitiveParamDetector) DetectParam(paramName string) *ParamSensitivity {
	paramLower := strings.ToLower(paramName)
	
	for _, p := range d.patterns {
		if p.Pattern.MatchString(paramLower) {
			return &ParamSensitivity{
				ParamName: paramName,
				Matched:   p.Name,
				Severity:  p.Severity,
				Category:  p.Category,
				IsSensitive: true,
			}
		}
	}
	
	// é¢å¤–çš„å¯å‘å¼æ£€æµ‹ï¼ˆæ›´ç²¾ç¡®ï¼‰
	if sensitivity := d.heuristicDetect(paramName); sensitivity != nil {
		return sensitivity
	}
	
	return &ParamSensitivity{
		ParamName:   paramName,
		IsSensitive: false,
	}
}

type ParamSensitivity struct {
	ParamName   string
	Matched     string
	Severity    string
	Category    string
	IsSensitive bool
	Confidence  float64 // 0-1, ç½®ä¿¡åº¦
}

// heuristicDetect å¯å‘å¼æ£€æµ‹ï¼ˆåŸºäºå€¼çš„ç‰¹å¾ï¼‰
func (d *SensitiveParamDetector) heuristicDetect(paramName string) *ParamSensitivity {
	// è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤æ‚çš„å¯å‘å¼è§„åˆ™
	return nil
}

// DetectParamValue æ£€æµ‹å‚æ•°å€¼çš„æ•æ„Ÿæ€§ï¼ˆåŸºäºå€¼ç‰¹å¾ï¼‰
func (d *SensitiveParamDetector) DetectParamValue(paramName, paramValue string) *ValueSensitivity {
	result := &ValueSensitivity{
		ParamName:  paramName,
		ParamValue: paramValue,
	}
	
	// 1. JWT Tokenæ£€æµ‹
	if isJWTToken(paramValue) {
		result.Type = "JWT_TOKEN"
		result.Severity = "HIGH"
		result.IsSensitive = true
		result.Confidence = 0.95
		return result
	}
	
	// 2. UUIDæ£€æµ‹
	if isUUID(paramValue) {
		result.Type = "UUID"
		result.Severity = "LOW"
		result.IsSensitive = true
		result.Confidence = 0.9
		return result
	}
	
	// 3. MD5/SHAå“ˆå¸Œæ£€æµ‹
	if hashType := detectHashType(paramValue); hashType != "" {
		result.Type = hashType
		result.Severity = "MEDIUM"
		result.IsSensitive = true
		result.Confidence = 0.85
		return result
	}
	
	// 4. Base64æ£€æµ‹ï¼ˆé•¿åº¦>20ä¸”ç¬¦åˆæ ¼å¼ï¼‰
	if isBase64(paramValue) && len(paramValue) > 20 {
		result.Type = "BASE64"
		result.Severity = "MEDIUM"
		result.IsSensitive = true
		result.Confidence = 0.7
		return result
	}
	
	// 5. API Keyæ¨¡å¼ï¼ˆé«˜ç†µå€¼ + ç‰¹å®šé•¿åº¦ï¼‰
	if entropy := calculateEntropy(paramValue); entropy > 4.5 && len(paramValue) > 16 {
		result.Type = "API_KEY_LIKELY"
		result.Severity = "HIGH"
		result.IsSensitive = true
		result.Confidence = 0.8
		return result
	}
	
	return result
}

type ValueSensitivity struct {
	ParamName   string
	ParamValue  string
	Type        string  // JWT_TOKEN, UUID, MD5, SHA256, BASE64, API_KEYç­‰
	Severity    string
	IsSensitive bool
	Confidence  float64
}

// === è¾…åŠ©æ£€æµ‹å‡½æ•° ===

func isJWTToken(value string) bool {
	// JWTæ ¼å¼: header.payload.signature
	parts := strings.Split(value, ".")
	if len(parts) != 3 {
		return false
	}
	
	// æ¯éƒ¨åˆ†éƒ½åº”è¯¥æ˜¯Base64
	for _, part := range parts {
		if len(part) < 10 || !isBase64(part) {
			return false
		}
	}
	
	return true
}

func isUUID(value string) bool {
	uuidPattern := regexp.MustCompile(`^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$`)
	return uuidPattern.MatchString(strings.ToLower(value))
}

func detectHashType(value string) string {
	value = strings.ToLower(value)
	
	if matched, _ := regexp.MatchString(`^[a-f0-9]{32}$`, value); matched {
		return "MD5"
	}
	if matched, _ := regexp.MatchString(`^[a-f0-9]{40}$`, value); matched {
		return "SHA1"
	}
	if matched, _ := regexp.MatchString(`^[a-f0-9]{64}$`, value); matched {
		return "SHA256"
	}
	
	return ""
}

func isBase64(value string) bool {
	base64Pattern := regexp.MustCompile(`^[A-Za-z0-9+/]+=*$`)
	return base64Pattern.MatchString(value) && len(value)%4 == 0
}

// calculateEntropy è®¡ç®—å­—ç¬¦ä¸²ç†µå€¼ï¼ˆä¿¡æ¯ç†µï¼‰
func calculateEntropy(s string) float64 {
	if len(s) == 0 {
		return 0
	}
	
	// ç»Ÿè®¡å­—ç¬¦é¢‘ç‡
	freq := make(map[rune]int)
	for _, c := range s {
		freq[c]++
	}
	
	// è®¡ç®—ç†µ
	var entropy float64
	length := float64(len(s))
	for _, count := range freq {
		p := float64(count) / length
		entropy -= p * math.Log2(p)
	}
	
	return entropy
}
```

**ç¤ºä¾‹æ­£åˆ™ï¼ˆç”¨äºé…ç½®æ–‡ä»¶ï¼‰**ï¼š
```json
{
  "sensitive_params": {
    "high": [
      {"name": "token", "pattern": "^(token|access_token|auth_token)$"},
      {"name": "api_key", "pattern": "^(api_key|apikey)$"},
      {"name": "password", "pattern": "^(password|passwd|pwd)$"}
    ],
    "medium": [
      {"name": "email", "pattern": "^(email|e_mail)$"},
      {"name": "session", "pattern": "^(session|session_id)$"}
    ],
    "low": [
      {"name": "id", "pattern": "^(id|user_id|uid)$"}
    ]
  },
  "value_patterns": {
    "jwt": "^[A-Za-z0-9-_]+\\.[A-Za-z0-9-_]+\\.[A-Za-z0-9-_]+$",
    "uuid": "^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$",
    "md5": "^[a-f0-9]{32}$",
    "sha256": "^[a-f0-9]{64}$"
  }
}
```

---

## 4) è¿‡æ»¤ç­–ç•¥è®¾è®¡ï¼ˆå¿…é¡»åŒ…å«ï¼‰

### 4.1 å»é‡ï¼šCanonical URLæŒ‡çº¹

```go
package core

import (
	"crypto/sha256"
	"encoding/hex"
	"sync"
)

// ConcurrentDeduplicator å¹¶å‘å®‰å…¨çš„å»é‡å™¨
type ConcurrentDeduplicator struct {
	seen      sync.Map // å¹¶å‘å®‰å…¨çš„map
	canonicalizer *URLCanonicalizer
}

func NewConcurrentDeduplicator() *ConcurrentDeduplicator {
	return &ConcurrentDeduplicator{
		canonicalizer: NewURLCanonicalizer(),
	}
}

// IsDuplicate æ£€æŸ¥URLæ˜¯å¦é‡å¤
func (d *ConcurrentDeduplicator) IsDuplicate(rawURL string) bool {
	// 1. è§„èŒƒåŒ–URL
	canonical, err := d.canonicalizer.CanonicalizeURL(rawURL)
	if err != nil {
		canonical = rawURL // å‡ºé”™åˆ™ä½¿ç”¨åŸURL
	}
	
	// 2. è®¡ç®—æŒ‡çº¹ï¼ˆSHA256å“ˆå¸Œï¼‰
	fingerprint := d.calculateFingerprint(canonical)
	
	// 3. æ£€æŸ¥å¹¶è®¾ç½®ï¼ˆåŸå­æ“ä½œï¼‰
	_, loaded := d.seen.LoadOrStore(fingerprint, true)
	
	return loaded // trueè¡¨ç¤ºå·²å­˜åœ¨ï¼ˆé‡å¤ï¼‰
}

// calculateFingerprint è®¡ç®—URLæŒ‡çº¹
func (d *ConcurrentDeduplicator) calculateFingerprint(url string) string {
	// ä½¿ç”¨SHA256å“ˆå¸Œ
	hash := sha256.Sum256([]byte(url))
	return hex.EncodeToString(hash[:])
}

// Add æ·»åŠ URLï¼ˆä¸æ£€æŸ¥é‡å¤ï¼‰
func (d *ConcurrentDeduplicator) Add(rawURL string) {
	canonical, err := d.canonicalizer.CanonicalizeURL(rawURL)
	if err != nil {
		canonical = rawURL
	}
	
	fingerprint := d.calculateFingerprint(canonical)
	d.seen.Store(fingerprint, true)
}

// Count è¿”å›å»é‡åçš„URLæ•°é‡
func (d *ConcurrentDeduplicator) Count() int {
	count := 0
	d.seen.Range(func(_, _ interface{}) bool {
		count++
		return true
	})
	return count
}

// Clear æ¸…ç©ºå»é‡å™¨
func (d *ConcurrentDeduplicator) Clear() {
	d.seen = sync.Map{}
}
```

### 4.2 ç™½åå• vs é»‘åå• vs å¯å‘å¼è§„åˆ™

```go
package core

import (
	"regexp"
	"strings"
)

// FilterStrategy è¿‡æ»¤ç­–ç•¥
type FilterStrategy int

const (
	Whitelist FilterStrategy = iota // ç™½åå•æ¨¡å¼
	Blacklist                        // é»‘åå•æ¨¡å¼
	Heuristic                        // å¯å‘å¼è§„åˆ™
	Combined                         // ç»„åˆæ¨¡å¼ï¼ˆæ¨èï¼‰
)

// URLFilter URLè¿‡æ»¤å™¨
type URLFilter struct {
	strategy FilterStrategy
	
	// ç™½åå•
	whitelistDomains []string
	whitelistPaths   []*regexp.Regexp
	
	// é»‘åå•
	blacklistDomains []string
	blacklistPaths   []*regexp.Regexp
	blacklistExtensions []string
	
	// å¯å‘å¼è§„åˆ™
	heuristicScoreThreshold float64
}

func NewURLFilter(strategy FilterStrategy) *URLFilter {
	return &URLFilter{
		strategy: strategy,
		whitelistDomains: make([]string, 0),
		whitelistPaths: make([]*regexp.Regexp, 0),
		blacklistDomains: make([]string, 0),
		blacklistPaths: make([]*regexp.Regexp, 0),
		blacklistExtensions: make([]string, 0),
		heuristicScoreThreshold: 0.5,
	}
}

// ShouldCrawl åˆ¤æ–­URLæ˜¯å¦åº”è¯¥çˆ¬å–
func (f *URLFilter) ShouldCrawl(rawURL string) (bool, string) {
	parsedURL, err := url.Parse(rawURL)
	if err != nil {
		return false, "URLè§£æå¤±è´¥"
	}
	
	switch f.strategy {
	case Whitelist:
		return f.checkWhitelist(parsedURL)
		
	case Blacklist:
		return f.checkBlacklist(parsedURL)
		
	case Heuristic:
		return f.checkHeuristic(parsedURL)
		
	case Combined:
		// ç»„åˆç­–ç•¥ï¼šæŒ‰ä¼˜å…ˆçº§æ£€æŸ¥
		
		// 1. é»‘åå•ä¼˜å…ˆï¼ˆå¿«é€Ÿæ’é™¤ï¼‰
		if allowed, reason := f.checkBlacklist(parsedURL); !allowed {
			return false, reason
		}
		
		// 2. ç™½åå•æ£€æŸ¥ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
		if len(f.whitelistDomains) > 0 || len(f.whitelistPaths) > 0 {
			if allowed, reason := f.checkWhitelist(parsedURL); !allowed {
				return false, reason
			}
		}
		
		// 3. å¯å‘å¼è§„åˆ™
		if allowed, reason := f.checkHeuristic(parsedURL); !allowed {
			return false, reason
		}
		
		return true, ""
		
	default:
		return true, ""
	}
}

// checkWhitelist ç™½åå•æ£€æŸ¥
func (f *URLFilter) checkWhitelist(parsedURL *url.URL) (bool, string) {
	// 1. æ£€æŸ¥åŸŸåç™½åå•
	if len(f.whitelistDomains) > 0 {
		found := false
		for _, domain := range f.whitelistDomains {
			if strings.Contains(parsedURL.Host, domain) {
				found = true
				break
			}
		}
		if !found {
			return false, "åŸŸåä¸åœ¨ç™½åå•ä¸­"
		}
	}
	
	// 2. æ£€æŸ¥è·¯å¾„ç™½åå•
	if len(f.whitelistPaths) > 0 {
		found := false
		for _, pathRe := range f.whitelistPaths {
			if pathRe.MatchString(parsedURL.Path) {
				found = true
				break
			}
		}
		if !found {
			return false, "è·¯å¾„ä¸åœ¨ç™½åå•ä¸­"
		}
	}
	
	return true, ""
}

// checkBlacklist é»‘åå•æ£€æŸ¥
func (f *URLFilter) checkBlacklist(parsedURL *url.URL) (bool, string) {
	// 1. æ£€æŸ¥åŸŸåé»‘åå•
	for _, domain := range f.blacklistDomains {
		if strings.Contains(parsedURL.Host, domain) {
			return false, "åŸŸååœ¨é»‘åå•ä¸­: " + domain
		}
	}
	
	// 2. æ£€æŸ¥è·¯å¾„é»‘åå•
	for _, pathRe := range f.blacklistPaths {
		if pathRe.MatchString(parsedURL.Path) {
			return false, "è·¯å¾„åŒ¹é…é»‘åå•è§„åˆ™"
		}
	}
	
	// 3. æ£€æŸ¥æ–‡ä»¶æ‰©å±•åé»‘åå•
	for _, ext := range f.blacklistExtensions {
		if strings.HasSuffix(strings.ToLower(parsedURL.Path), "."+ext) {
			return false, "æ–‡ä»¶æ‰©å±•ååœ¨é»‘åå•ä¸­: " + ext
		}
	}
	
	return true, ""
}

// checkHeuristic å¯å‘å¼è§„åˆ™æ£€æŸ¥
func (f *URLFilter) checkHeuristic(parsedURL *url.URL) (bool, string) {
	score := f.calculateURLScore(parsedURL)
	
	if score < f.heuristicScoreThreshold {
		return false, fmt.Sprintf("å¯å‘å¼åˆ†æ•°è¿‡ä½: %.2f < %.2f", score, f.heuristicScoreThreshold)
	}
	
	return true, ""
}

// calculateURLScore è®¡ç®—URLåˆ†æ•°ï¼ˆ0-1ï¼‰
func (f *URLFilter) calculateURLScore(parsedURL *url.URL) float64 {
	var score float64 = 0.5 // åŸºç¡€åˆ†æ•°
	
	path := parsedURL.Path
	query := parsedURL.RawQuery
	
	// 1. è·¯å¾„é•¿åº¦ï¼ˆé€‚ä¸­æœ€å¥½ï¼‰
	pathLen := len(path)
	if pathLen > 5 && pathLen < 100 {
		score += 0.1
	} else if pathLen >= 200 {
		score -= 0.2 // è¿‡é•¿çš„è·¯å¾„å¯èƒ½æ˜¯åƒåœ¾
	}
	
	// 2. åŒ…å«å…³é”®ä¸šåŠ¡è·¯å¾„
	businessKeywords := []string{
		"/api/", "/admin/", "/user/", "/manage/",
		"/login", "/auth", "/dashboard",
	}
	for _, keyword := range businessKeywords {
		if strings.Contains(path, keyword) {
			score += 0.2
			break
		}
	}
	
	// 3. æœ‰æŸ¥è¯¢å‚æ•°åŠ åˆ†ï¼ˆå‚æ•°åŒ–URLæ›´æœ‰ä»·å€¼ï¼‰
	if query != "" {
		score += 0.1
	}
	
	// 4. è·¯å¾„å±‚çº§ï¼ˆ2-4å±‚æœ€ä½³ï¼‰
	segments := strings.Split(strings.Trim(path, "/"), "/")
	if len(segments) >= 2 && len(segments) <= 4 {
		score += 0.1
	}
	
	// 5. åŒ…å«æ•°å­—IDï¼ˆå¯èƒ½æ˜¯åŠ¨æ€èµ„æºï¼‰
	if regexp.MustCompile(`/\d+`).MatchString(path) {
		score += 0.05
	}
	
	// 6. åŒ…å«RESTåŠ¨è¯ï¼ˆCRUDæ“ä½œï¼‰
	restVerbs := []string{"/create", "/edit", "/update", "/delete", "/list"}
	for _, verb := range restVerbs {
		if strings.Contains(path, verb) {
			score += 0.15
			break
		}
	}
	
	// ç¡®ä¿åˆ†æ•°åœ¨[0, 1]èŒƒå›´å†…
	if score > 1.0 {
		score = 1.0
	} else if score < 0 {
		score = 0
	}
	
	return score
}

// === é…ç½®æ–¹æ³• ===

func (f *URLFilter) AddWhitelistDomain(domain string) {
	f.whitelistDomains = append(f.whitelistDomains, domain)
}

func (f *URLFilter) AddWhitelistPath(pathPattern string) error {
	re, err := regexp.Compile(pathPattern)
	if err != nil {
		return err
	}
	f.whitelistPaths = append(f.whitelistPaths, re)
	return nil
}

func (f *URLFilter) AddBlacklistDomain(domain string) {
	f.blacklistDomains = append(f.blacklistDomains, domain)
}

func (f *URLFilter) AddBlacklistPath(pathPattern string) error {
	re, err := regexp.Compile(pathPattern)
	if err != nil {
		return err
	}
	f.blacklistPaths = append(f.blacklistPaths, re)
	return nil
}

func (f *URLFilter) AddBlacklistExtension(ext string) {
	f.blacklistExtensions = append(f.blacklistExtensions, strings.ToLower(ext))
}
```

### 4.3 æ–‡ä»¶æ‰©å±•åè¿‡æ»¤

```go
// ExtensionFilter æ‰©å±•åè¿‡æ»¤å™¨
type ExtensionFilter struct {
	// é™æ€èµ„æºæ‰©å±•åï¼ˆé»˜è®¤æ’é™¤ï¼‰
	staticExtensions map[string]bool
	
	// åŠ¨æ€èµ„æºæ‰©å±•åï¼ˆå…è®¸ï¼‰
	dynamicExtensions map[string]bool
	
	// è‡ªå®šä¹‰é…ç½®
	customBlacklist map[string]bool
	customWhitelist map[string]bool
}

func NewExtensionFilter() *ExtensionFilter {
	f := &ExtensionFilter{
		staticExtensions:  make(map[string]bool),
		dynamicExtensions: make(map[string]bool),
		customBlacklist:   make(map[string]bool),
		customWhitelist:   make(map[string]bool),
	}
	
	// åˆå§‹åŒ–é™æ€èµ„æºæ‰©å±•å
	staticList := []string{
		// å›¾ç‰‡
		"jpg", "jpeg", "png", "gif", "bmp", "svg", "ico", "webp",
		// è§†é¢‘
		"mp4", "avi", "mov", "wmv", "flv", "mkv", "webm",
		// éŸ³é¢‘
		"mp3", "wav", "ogg", "m4a", "flac",
		// å­—ä½“
		"woff", "woff2", "ttf", "eot", "otf",
		// æ–‡æ¡£
		"pdf", "doc", "docx", "xls", "xlsx", "ppt", "pptx",
		// å‹ç¼©åŒ…
		"zip", "rar", "tar", "gz", "7z", "bz2",
		// æ ·å¼
		"css", "scss", "sass", "less",
	}
	
	for _, ext := range staticList {
		f.staticExtensions[ext] = true
	}
	
	// åŠ¨æ€èµ„æºæ‰©å±•åï¼ˆé€šå¸¸å…è®¸ï¼‰
	dynamicList := []string{
		"php", "asp", "aspx", "jsp", "do", "action",
		"html", "htm", "shtml", "xhtml",
		"json", "xml", "api",
		// æ³¨æ„ï¼šjså·²ä»é»‘åå•ç§»é™¤ï¼ˆéœ€è¦è®¿é—®ä»¥æå–URLï¼‰
	}
	
	for _, ext := range dynamicList {
		f.dynamicExtensions[ext] = true
	}
	
	return f
}

// ShouldFilter åˆ¤æ–­URLæ˜¯å¦åº”è¯¥è¢«è¿‡æ»¤ï¼ˆåŸºäºæ‰©å±•åï¼‰
func (f *ExtensionFilter) ShouldFilter(rawURL string) (bool, string) {
	parsedURL, err := url.Parse(rawURL)
	if err != nil {
		return false, ""
	}
	
	path := parsedURL.Path
	ext := extractExtension(path)
	
	if ext == "" {
		return false, "" // æ— æ‰©å±•åï¼Œä¸è¿‡æ»¤
	}
	
	ext = strings.ToLower(ext)
	
	// 1. æ£€æŸ¥è‡ªå®šä¹‰ç™½åå•ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
	if f.customWhitelist[ext] {
		return false, ""
	}
	
	// 2. æ£€æŸ¥è‡ªå®šä¹‰é»‘åå•
	if f.customBlacklist[ext] {
		return true, "æ‰©å±•ååœ¨è‡ªå®šä¹‰é»‘åå•ä¸­: " + ext
	}
	
	// 3. æ£€æŸ¥é™æ€èµ„æºæ‰©å±•å
	if f.staticExtensions[ext] {
		return true, "é™æ€èµ„æºæ‰©å±•å: " + ext
	}
	
	// 4. åŠ¨æ€èµ„æºæ‰©å±•åå…è®¸
	if f.dynamicExtensions[ext] {
		return false, ""
	}
	
	// 5. æœªçŸ¥æ‰©å±•åï¼Œé»˜è®¤ä¸è¿‡æ»¤
	return false, ""
}

func extractExtension(path string) string {
	// ç§»é™¤æŸ¥è¯¢å‚æ•°å’Œé”šç‚¹
	path = strings.Split(path, "?")[0]
	path = strings.Split(path, "#")[0]
	
	// æå–æ‰©å±•å
	lastDot := strings.LastIndex(path, ".")
	lastSlash := strings.LastIndex(path, "/")
	
	if lastDot > lastSlash && lastDot != -1 {
		return path[lastDot+1:]
	}
	
	return ""
}
```

### 4.4 åŠ¨æ€å‚æ•°é˜ˆå€¼é™åˆ¶

```go
// ParamThresholdFilter å‚æ•°é˜ˆå€¼è¿‡æ»¤å™¨
type ParamThresholdFilter struct {
	maxParamCount  int // æœ€å¤§å‚æ•°æ•°é‡
	maxParamLength int // å•ä¸ªå‚æ•°å€¼æœ€å¤§é•¿åº¦
	maxTotalLength int // æ‰€æœ‰å‚æ•°æ€»é•¿åº¦
}

func NewParamThresholdFilter() *ParamThresholdFilter {
	return &ParamThresholdFilter{
		maxParamCount:  20,   // é»˜è®¤æœ€å¤š20ä¸ªå‚æ•°
		maxParamLength: 500,  // å•ä¸ªå‚æ•°å€¼æœ€é•¿500å­—ç¬¦
		maxTotalLength: 2000, // æ€»é•¿åº¦2000å­—ç¬¦
	}
}

// ShouldFilter åˆ¤æ–­URLæ˜¯å¦å› å‚æ•°è¶…é™è€Œè¢«è¿‡æ»¤
func (f *ParamThresholdFilter) ShouldFilter(rawURL string) (bool, string) {
	parsedURL, err := url.Parse(rawURL)
	if err != nil {
		return false, ""
	}
	
	query := parsedURL.Query()
	
	// 1. æ£€æŸ¥å‚æ•°æ•°é‡
	if len(query) > f.maxParamCount {
		return true, fmt.Sprintf("å‚æ•°æ•°é‡è¶…é™: %d > %d", len(query), f.maxParamCount)
	}
	
	// 2. æ£€æŸ¥å•ä¸ªå‚æ•°å€¼é•¿åº¦
	totalLength := 0
	for key, values := range query {
		for _, val := range values {
			if len(val) > f.maxParamLength {
				return true, fmt.Sprintf("å‚æ•°'%s'å€¼è¿‡é•¿: %d > %d", key, len(val), f.maxParamLength)
			}
			totalLength += len(val)
		}
	}
	
	// 3. æ£€æŸ¥æ€»é•¿åº¦
	if totalLength > f.maxTotalLength {
		return true, fmt.Sprintf("å‚æ•°æ€»é•¿åº¦è¶…é™: %d > %d", totalLength, f.maxTotalLength)
	}
	
	return false, ""
}
```

### 4.5 è¯¯æŠ¥æ§åˆ¶ç¤ºä¾‹

```go
// FalsePositiveControl è¯¯æŠ¥æ§åˆ¶å™¨
type FalsePositiveControl struct {
	// å¸¸è§çš„éæ•æ„Ÿ"id"å‚æ•°
	safeIDParams map[string]bool
}

func NewFalsePositiveControl() *FalsePositiveControl {
	c := &FalsePositiveControl{
		safeIDParams: make(map[string]bool),
	}
	
	// åˆå§‹åŒ–å®‰å…¨çš„"id"å‚æ•°åˆ—è¡¨ï¼ˆä¸åº”æ ‡è®°ä¸ºSQLæ³¨å…¥é£é™©ï¼‰
	safeList := []string{
		"video_id", "vid", "videoid",
		"grid_id", "grid",
		"valid", "validation",
		"slide", "slider",
		"fluid", "liquid",
		"pyramid", "period",
	}
	
	for _, param := range safeList {
		c.safeIDParams[strings.ToLower(param)] = true
	}
	
	return c
}

// IsSafeIDParam åˆ¤æ–­å‚æ•°æ˜¯å¦ä¸ºå®‰å…¨çš„"id"å‚æ•°
func (c *FalsePositiveControl) IsSafeIDParam(paramName string) bool {
	return c.safeIDParams[strings.ToLower(paramName)]
}

// ShouldReportAsSQL åˆ¤æ–­æ˜¯å¦åº”è¯¥æŠ¥å‘Šä¸ºSQLæ³¨å…¥é£é™©
func (c *FalsePositiveControl) ShouldReportAsSQL(paramName string) bool {
	paramLower := strings.ToLower(paramName)
	
	// å¦‚æœåœ¨å®‰å…¨åˆ—è¡¨ä¸­ï¼Œä¸æŠ¥å‘Š
	if c.IsSafeIDParam(paramLower) {
		return false
	}
	
	// ç²¾ç¡®åŒ¹é…"id"ç›¸å…³å‚æ•°ï¼ˆé¿å…è¯¯æŠ¥ï¼‰
	sqlRiskParams := []string{
		"id", "user_id", "uid", "account_id", "order_id", "product_id",
	}
	
	for _, riskParam := range sqlRiskParams {
		if paramLower == riskParam {
			return true
		}
	}
	
	return false
}
```

---

**ï¼ˆç”±äºç¯‡å¹…é™åˆ¶ï¼Œæˆ‘å°†ç»§ç»­åœ¨ä¸‹ä¸€ä¸ªæ–‡ä»¶ä¸­è¾“å‡ºå‰©ä½™çš„5-9éƒ¨åˆ†ï¼‰**

