# 快速开始 - v2.6 第一周实施指南

## 🎯 本周目标

**完成结构化日志系统 + 实时监控指标**

**预计时间**: 5个工作日  
**难度**: ⭐⭐⭐ (中等)  
**收益**: ⭐⭐⭐⭐⭐ (极高)

---

## 📅 Day 1-3: 结构化日志系统

### Day 1: 设计和基础实现 (8小时)

#### 上午 (4小时): 设计日志系统

**1. 创建日志接口** (1h)

创建文件: `core/logger.go`

```go
package core

import (
	"context"
	"log/slog"
	"os"
)

// Logger 日志接口
type Logger interface {
	Debug(msg string, args ...any)
	Info(msg string, args ...any)
	Warn(msg string, args ...any)
	Error(msg string, args ...any)
	With(args ...any) Logger
}

// SlogLogger 基于 slog 的实现
type SlogLogger struct {
	logger *slog.Logger
}

// NewLogger 创建新的日志记录器
func NewLogger(level slog.Level, output *os.File) Logger {
	handler := slog.NewJSONHandler(output, &slog.HandlerOptions{
		Level: level,
		ReplaceAttr: func(groups []string, a slog.Attr) slog.Attr {
			// 自定义时间格式
			if a.Key == slog.TimeKey {
				return slog.String("timestamp", a.Value.Time().Format("2006-01-02 15:04:05"))
			}
			return a
		},
	})
	
	return &SlogLogger{
		logger: slog.New(handler),
	}
}

func (l *SlogLogger) Debug(msg string, args ...any) {
	l.logger.Debug(msg, args...)
}

func (l *SlogLogger) Info(msg string, args ...any) {
	l.logger.Info(msg, args...)
}

func (l *SlogLogger) Warn(msg string, args ...any) {
	l.logger.Warn(msg, args...)
}

func (l *SlogLogger) Error(msg string, args ...any) {
	l.logger.Error(msg, args...)
}

func (l *SlogLogger) With(args ...any) Logger {
	return &SlogLogger{
		logger: l.logger.With(args...),
	}
}

// 全局日志实例
var DefaultLogger Logger

func init() {
	DefaultLogger = NewLogger(slog.LevelInfo, os.Stdout)
}

// 便捷方法
func Debug(msg string, args ...any) { DefaultLogger.Debug(msg, args...) }
func Info(msg string, args ...any)  { DefaultLogger.Info(msg, args...) }
func Warn(msg string, args ...any)  { DefaultLogger.Warn(msg, args...) }
func Error(msg string, args ...any) { DefaultLogger.Error(msg, args...) }
```

**2. 添加日志配置** (1h)

更新 `config/config.go`:

```go
// LogSettings 日志设置
type LogSettings struct {
	Level      string // DEBUG, INFO, WARN, ERROR
	OutputFile string // 日志文件路径，空表示 stdout
	Format     string // json, text
}

// 在 Config 结构体中添加
type Config struct {
	// ... 现有字段
	LogSettings LogSettings
}

// 在 NewDefaultConfig 中添加
func NewDefaultConfig() *Config {
	return &Config{
		// ... 现有配置
		LogSettings: LogSettings{
			Level:      "INFO",
			OutputFile: "",
			Format:     "json",
		},
	}
}
```

**3. 命令行参数** (30min)

更新 `cmd/spider/main.go`:

```go
var (
	// ... 现有参数
	logLevel  string
	logFile   string
	logFormat string
)

func init() {
	// ... 现有参数定义
	flag.StringVar(&logLevel, "log-level", "info", "日志级别: debug, info, warn, error")
	flag.StringVar(&logFile, "log-file", "", "日志文件路径（空表示输出到控制台）")
	flag.StringVar(&logFormat, "log-format", "json", "日志格式: json, text")
}
```

**4. 编写测试** (1.5h)

创建文件: `core/logger_test.go`

```go
package core

import (
	"bytes"
	"log/slog"
	"os"
	"strings"
	"testing"
)

func TestLogger(t *testing.T) {
	// 创建测试缓冲区
	var buf bytes.Buffer
	logger := NewLogger(slog.LevelDebug, &buf)
	
	// 测试 Info
	logger.Info("test message", "key", "value")
	output := buf.String()
	
	if !strings.Contains(output, "test message") {
		t.Errorf("日志应该包含消息")
	}
	if !strings.Contains(output, "key") {
		t.Errorf("日志应该包含键值对")
	}
}

func TestLogLevels(t *testing.T) {
	var buf bytes.Buffer
	logger := NewLogger(slog.LevelWarn, &buf)
	
	// Info 应该被过滤
	logger.Info("info message")
	if buf.Len() > 0 {
		t.Errorf("INFO 日志应该被过滤")
	}
	
	// Warn 应该输出
	logger.Warn("warn message")
	if buf.Len() == 0 {
		t.Errorf("WARN 日志应该输出")
	}
}
```

#### 下午 (4小时): 替换现有日志

**5. 替换 Spider 中的日志** (2h)

更新 `core/spider.go`:

```go
// 在 Spider 结构体中添加
type Spider struct {
	// ... 现有字段
	logger Logger
}

// 在 NewSpider 中初始化
func NewSpider(cfg *config.Config) *Spider {
	// 创建日志记录器
	var logOutput *os.File = os.Stdout
	if cfg.LogSettings.OutputFile != "" {
		var err error
		logOutput, err = os.OpenFile(cfg.LogSettings.OutputFile, 
			os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0644)
		if err != nil {
			log.Printf("无法打开日志文件: %v", err)
			logOutput = os.Stdout
		}
	}
	
	level := parseLogLevel(cfg.LogSettings.Level)
	logger := NewLogger(level, logOutput)
	
	spider := &Spider{
		// ... 现有初始化
		logger: logger,
	}
	
	return spider
}

// 解析日志级别
func parseLogLevel(level string) slog.Level {
	switch strings.ToUpper(level) {
	case "DEBUG":
		return slog.LevelDebug
	case "INFO":
		return slog.LevelInfo
	case "WARN":
		return slog.LevelWarn
	case "ERROR":
		return slog.LevelError
	default:
		return slog.LevelInfo
	}
}

// 替换日志调用
func (s *Spider) Start(targetURL string) error {
	// ❌ fmt.Printf("开始爬取URL: %s\n", targetURL)
	// ✅ 使用结构化日志
	s.logger.Info("开始爬取",
		"url", targetURL,
		"target_domain", s.targetDomain,
		"max_depth", s.config.DepthSettings.MaxDepth)
	
	// ... 其他代码
}
```

**6. 批量替换** (2h)

使用以下模式替换所有日志：

```go
// 替换模式
// fmt.Printf("xxx") → s.logger.Info("xxx")
// fmt.Printf("xxx: %v", err) → s.logger.Error("xxx", "error", err)
// fmt.Println("xxx") → s.logger.Info("xxx")
```

**重点文件**:
- `core/spider.go` (约 88 处)
- `core/static_crawler.go` (约 14 处)
- `core/dynamic_crawler.go` (约 21 处)

---

### Day 2: 完成日志替换 (8小时)

#### 上午 (4小时): 继续替换日志

**继续替换文件**:
- `core/param_handler.go`
- `core/js_analyzer.go`
- `core/form_filler.go`
- 其他 core 文件

**替换示例**:

```go
// Before
fmt.Printf("发现 %d 个链接\n", len(links))

// After
s.logger.Info("链接发现完成",
	"count", len(links),
	"url", currentURL)

// Before
fmt.Printf("错误: %v\n", err)

// After
s.logger.Error("操作失败",
	"error", err,
	"url", url,
	"operation", "crawl")
```

#### 下午 (4小时): 测试和验证

**7. 集成测试** (2h)

```bash
# 测试不同日志级别
./spider.exe -url https://example.com -log-level debug
./spider.exe -url https://example.com -log-level info
./spider.exe -url https://example.com -log-level warn

# 测试日志文件
./spider.exe -url https://example.com -log-file spider.log

# 验证日志格式
cat spider.log | jq .
```

**8. 文档更新** (1h)

更新 `README.md`:

```markdown
## 日志配置

### 日志级别

```bash
# DEBUG - 详细调试信息
spider -url https://example.com -log-level debug

# INFO - 一般信息（默认）
spider -url https://example.com -log-level info

# WARN - 警告信息
spider -url https://example.com -log-level warn

# ERROR - 仅错误
spider -url https://example.com -log-level error
```

### 日志文件

```bash
# 输出到文件
spider -url https://example.com -log-file ./spider.log

# 日志格式（JSON）
{"timestamp":"2025-10-24 10:00:00","level":"INFO","msg":"开始爬取","url":"https://example.com"}
```
```

**9. 代码审查** (1h)

检查清单:
- [ ] 所有 `fmt.Printf` 已替换
- [ ] 所有 `fmt.Println` 已替换
- [ ] 日志包含足够的上下文信息
- [ ] 日志级别使用正确
- [ ] 敏感信息已脱敏

---

### Day 3: 优化和完善 (8小时)

#### 上午 (4小时): 日志增强

**10. 添加请求追踪** (2h)

```go
// 生成唯一请求ID
import "github.com/google/uuid"

func (s *Spider) Start(targetURL string) error {
	requestID := uuid.New().String()
	logger := s.logger.With("request_id", requestID)
	
	logger.Info("开始爬取", "url", targetURL)
	// ... 使用 logger
}
```

**11. 性能统计日志** (2h)

```go
func (s *Spider) crawlURL(targetURL string) (*Result, error) {
	start := time.Now()
	defer func() {
		elapsed := time.Since(start)
		s.logger.Debug("URL爬取完成",
			"url", targetURL,
			"elapsed_ms", elapsed.Milliseconds(),
			"success", err == nil)
	}()
	
	// ... 爬取逻辑
}
```

#### 下午 (4小时): 日志分析工具

**12. 创建日志分析脚本** (2h)

创建文件: `tools/analyze_logs.sh`

```bash
#!/bin/bash
# 日志分析工具

LOG_FILE=$1

if [ -z "$LOG_FILE" ]; then
    echo "Usage: $0 <log_file>"
    exit 1
fi

echo "=== 日志统计 ==="
echo "总日志数: $(wc -l < $LOG_FILE)"
echo "INFO: $(grep -c '"level":"INFO"' $LOG_FILE)"
echo "WARN: $(grep -c '"level":"WARN"' $LOG_FILE)"
echo "ERROR: $(grep -c '"level":"ERROR"' $LOG_FILE)"

echo ""
echo "=== 错误统计 ==="
grep '"level":"ERROR"' $LOG_FILE | jq -r '.msg' | sort | uniq -c | sort -rn

echo ""
echo "=== 性能统计 ==="
grep 'elapsed_ms' $LOG_FILE | jq -r '.elapsed_ms' | awk '
{
    sum+=$1; 
    count++; 
    if($1>max) max=$1; 
    if($1<min || min==0) min=$1
} 
END {
    print "平均: "sum/count" ms"
    print "最小: "min" ms"
    print "最大: "max" ms"
}'
```

**13. 编写完整测试** (2h)

```go
// core/spider_logging_test.go
func TestSpiderLogging(t *testing.T) {
	// 创建临时日志文件
	tmpfile, err := os.CreateTemp("", "spider-test-*.log")
	require.NoError(t, err)
	defer os.Remove(tmpfile.Name())
	
	// 配置
	cfg := config.NewDefaultConfig()
	cfg.TargetURL = "https://httpbin.org/html"
	cfg.LogSettings.OutputFile = tmpfile.Name()
	cfg.LogSettings.Level = "DEBUG"
	
	// 运行爬虫
	spider := NewSpider(cfg)
	defer spider.Close()
	
	err = spider.Start(cfg.TargetURL)
	require.NoError(t, err)
	
	// 验证日志
	content, err := os.ReadFile(tmpfile.Name())
	require.NoError(t, err)
	
	// 检查日志内容
	assert.Contains(t, string(content), "开始爬取")
	assert.Contains(t, string(content), cfg.TargetURL)
}
```

---

## 📅 Day 4-5: 实时监控指标

### Day 4: 指标系统实现 (8小时)

#### 上午 (4小时): 设计指标系统

**14. 创建指标结构** (2h)

创建文件: `core/metrics.go`

```go
package core

import (
	"sync"
	"sync/atomic"
	"time"
)

// Metrics 爬虫指标
type Metrics struct {
	// 基础计数器（使用 atomic 保证并发安全）
	totalRequests   int64
	successRequests int64
	failedRequests  int64
	totalURLs       int64
	totalForms      int64
	totalAPIs       int64
	totalLinks      int64
	
	// 时间统计
	startTime     time.Time
	totalDuration time.Duration
	
	// 响应时间统计
	responseTimes []time.Duration
	mu            sync.RWMutex
	
	// HTTP状态码统计
	statusCodes map[int]int64
	statusMu    sync.RWMutex
	
	// 错误统计
	errorTypes map[string]int64
	errorMu    sync.RWMutex
}

// NewMetrics 创建指标收集器
func NewMetrics() *Metrics {
	return &Metrics{
		startTime:     time.Now(),
		responseTimes: make([]time.Duration, 0, 10000),
		statusCodes:   make(map[int]int64),
		errorTypes:    make(map[string]int64),
	}
}

// IncrementRequests 增加请求计数
func (m *Metrics) IncrementRequests() {
	atomic.AddInt64(&m.totalRequests, 1)
}

// IncrementSuccess 增加成功计数
func (m *Metrics) IncrementSuccess() {
	atomic.AddInt64(&m.successRequests, 1)
}

// RecordResponseTime 记录响应时间
func (m *Metrics) RecordResponseTime(duration time.Duration) {
	m.mu.Lock()
	defer m.mu.Unlock()
	m.responseTimes = append(m.responseTimes, duration)
}

// RecordStatusCode 记录HTTP状态码
func (m *Metrics) RecordStatusCode(code int) {
	m.statusMu.Lock()
	defer m.statusMu.Unlock()
	m.statusCodes[code]++
}

// GetSnapshot 获取指标快照
func (m *Metrics) GetSnapshot() *MetricsSnapshot {
	m.mu.RLock()
	m.statusMu.RLock()
	m.errorMu.RLock()
	defer m.mu.RUnlock()
	defer m.statusMu.RUnlock()
	defer m.errorMu.RUnlock()
	
	elapsed := time.Since(m.startTime)
	
	snapshot := &MetricsSnapshot{
		TotalRequests:   atomic.LoadInt64(&m.totalRequests),
		SuccessRequests: atomic.LoadInt64(&m.successRequests),
		FailedRequests:  atomic.LoadInt64(&m.failedRequests),
		Elapsed:         elapsed,
	}
	
	// 计算速率
	if elapsed.Seconds() > 0 {
		snapshot.RequestsPerSec = float64(snapshot.TotalRequests) / elapsed.Seconds()
	}
	
	// 计算响应时间
	if len(m.responseTimes) > 0 {
		snapshot.AvgResponseTime = m.calculateAverage()
	}
	
	return snapshot
}

// MetricsSnapshot 指标快照
type MetricsSnapshot struct {
	TotalRequests   int64
	SuccessRequests int64
	FailedRequests  int64
	Elapsed         time.Duration
	RequestsPerSec  float64
	AvgResponseTime time.Duration
}
```

**15. 集成到 Spider** (2h)

```go
// 在 Spider 中添加
type Spider struct {
	// ... 现有字段
	metrics *Metrics
}

// 在 NewSpider 中初始化
func NewSpider(cfg *config.Config) *Spider {
	spider := &Spider{
		// ... 现有初始化
		metrics: NewMetrics(),
	}
	return spider
}

// 在 crawlURL 中记录指标
func (s *Spider) crawlURL(targetURL string) (*Result, error) {
	s.metrics.IncrementRequests()
	
	start := time.Now()
	result, err := s.staticCrawler.Crawl(parsedURL)
	elapsed := time.Since(start)
	
	s.metrics.RecordResponseTime(elapsed)
	
	if err != nil {
		s.metrics.IncrementFailure()
		return nil, err
	}
	
	s.metrics.IncrementSuccess()
	s.metrics.RecordStatusCode(result.StatusCode)
	
	return result, nil
}
```

#### 下午 (4小时): 实时进度显示

**16. 实现进度条** (3h)

```go
// 添加实时进度显示
func (s *Spider) ShowProgress(ctx context.Context) {
	ticker := time.NewTicker(1 * time.Second)
	defer ticker.Stop()
	
	for {
		select {
		case <-ctx.Done():
			return
		case <-ticker.C:
			snapshot := s.metrics.GetSnapshot()
			s.printProgress(snapshot)
		}
	}
}

func (s *Spider) printProgress(m *MetricsSnapshot) {
	successRate := float64(0)
	if m.TotalRequests > 0 {
		successRate = float64(m.SuccessRequests) / float64(m.TotalRequests) * 100
	}
	
	fmt.Printf("\r[进度] 请求: %d | 成功: %d (%.1f%%) | 速度: %.1f req/s | 平均响应: %v",
		m.TotalRequests,
		m.SuccessRequests,
		successRate,
		m.RequestsPerSec,
		m.AvgResponseTime)
}
```

**17. 编写测试** (1h)

```go
func TestMetrics(t *testing.T) {
	m := NewMetrics()
	
	// 模拟请求
	m.IncrementRequests()
	m.IncrementSuccess()
	m.RecordResponseTime(100 * time.Millisecond)
	m.RecordStatusCode(200)
	
	// 获取快照
	snapshot := m.GetSnapshot()
	
	assert.Equal(t, int64(1), snapshot.TotalRequests)
	assert.Equal(t, int64(1), snapshot.SuccessRequests)
}
```

---

### Day 5: 完善和测试 (8小时)

#### 上午 (4小时): 集成测试

**18. 端到端测试** (2h)

```bash
# 测试日志 + 监控
./spider.exe -url https://httpbin.org \
  -depth 2 \
  -log-level debug \
  -log-file spider.log \
  -show-metrics

# 验证输出
# 应该看到:
# 1. 实时进度条
# 2. 日志文件生成
# 3. 最终统计报告
```

**19. 性能测试** (2h)

```go
func BenchmarkLogging(b *testing.B) {
	logger := NewLogger(slog.LevelInfo, io.Discard)
	
	b.ResetTimer()
	for i := 0; i < b.N; i++ {
		logger.Info("test", "key", "value")
	}
}

func BenchmarkMetrics(b *testing.B) {
	m := NewMetrics()
	
	b.ResetTimer()
	for i := 0; i < b.N; i++ {
		m.IncrementRequests()
		m.RecordResponseTime(100 * time.Millisecond)
	}
}
```

#### 下午 (4小时): 文档和发布

**20. 完善文档** (2h)

更新 `README.md`:

```markdown
## v2.6 新特性

### 结构化日志

Spider v2.6 引入了完整的结构化日志系统：

- ✅ 支持多级别日志（DEBUG/INFO/WARN/ERROR）
- ✅ JSON 格式输出
- ✅ 文件和控制台输出
- ✅ 请求追踪支持

### 实时监控

- ✅ 实时进度条
- ✅ 请求成功率
- ✅ 平均响应时间
- ✅ 爬取速率

### 使用示例

```bash
# 启用调试日志和实时监控
spider -url https://example.com \
  -log-level debug \
  -log-file spider.log \
  -show-metrics

# 输出示例
[进度] 请求: 145 | 成功: 142 (97.9%) | 速度: 12.3 req/s | 平均响应: 234ms
```
```

**21. 提交代码** (1h)

```bash
# 运行所有测试
go test -v ./...

# 检查代码
go vet ./...
golangci-lint run

# 提交
git add .
git commit -m "feat: 添加结构化日志和实时监控 (v2.6 Week 1)

- 实现基于 slog 的结构化日志系统
- 添加日志级别控制和文件输出
- 实现实时监控指标
- 添加进度条显示
- 完整的单元测试覆盖

相关 Issue: #xxx"

# 推送
git push origin develop/v2.6
```

**22. 创建 PR** (1h)

创建 Pull Request:
- 标题: `feat: 结构化日志和实时监控 (v2.6 Week 1)`
- 描述: 详细说明改动
- 截图: 展示新功能
- 测试: 说明测试情况

---

## ✅ 第一周完成检查清单

### 代码

- [ ] `core/logger.go` - 日志接口和实现
- [ ] `core/metrics.go` - 指标收集系统
- [ ] 所有 `fmt.Printf` 替换为结构化日志
- [ ] 集成到 Spider 主流程

### 测试

- [ ] `core/logger_test.go` - 日志测试
- [ ] `core/metrics_test.go` - 指标测试
- [ ] `core/spider_logging_test.go` - 集成测试
- [ ] 所有测试通过
- [ ] 性能测试无明显下降

### 文档

- [ ] README.md 更新
- [ ] 示例代码添加
- [ ] 命令行帮助更新

### 验收

```bash
# 1. 编译测试
go build -o spider.exe cmd/spider/main.go

# 2. 功能测试
./spider.exe -url https://httpbin.org -log-level debug -show-metrics

# 3. 日志测试
./spider.exe -url https://httpbin.org -log-file spider.log
cat spider.log | jq .

# 4. 单元测试
go test -v -cover ./... | grep coverage:
# 期望: coverage: 60%+

# 5. 性能测试
go test -bench=. -benchmem ./...
```

---

## 📊 预期成果

### 日志系统

**Before**:
```
开始爬取URL: https://example.com
发现 42 个链接
错误: connection timeout
```

**After**:
```json
{"timestamp":"2025-10-24 10:00:00","level":"INFO","msg":"开始爬取","url":"https://example.com","depth":5}
{"timestamp":"2025-10-24 10:00:01","level":"INFO","msg":"链接发现完成","count":42,"url":"https://example.com"}
{"timestamp":"2025-10-24 10:00:02","level":"ERROR","msg":"请求失败","error":"connection timeout","url":"https://example.com/page1"}
```

### 监控指标

**终端输出**:
```
[进度] 请求: 1247 | 成功: 1198 (96.1%) | 速度: 15.2 req/s | 平均响应: 187ms
```

**最终报告**:
```
============================================================
                        爬取统计
============================================================
总请求数:        1247
成功请求:        1198 (96.1%)
失败请求:        49 (3.9%)
发现URL数:       2456
发现表单数:      87
发现API数:       156

性能指标:
平均响应时间:    187ms
P50响应时间:     125ms
P95响应时间:     456ms
请求速率:        15.2 req/s

HTTP状态码分布:
  200: 1156 (93.0%)
  404: 35 (2.8%)
  500: 7 (0.6%)

运行时间:        82.1秒
============================================================
```

---

## 🎯 成功标准

完成本周任务后，您应该能够：

1. ✅ 运行爬虫时看到实时进度
2. ✅ 在日志文件中看到结构化日志
3. ✅ 使用不同日志级别控制输出
4. ✅ 查看详细的性能指标
5. ✅ 所有测试通过，覆盖率 > 60%

---

## 🆘 遇到问题?

### 常见问题

**Q: 编译错误 "undefined: slog"**  
A: 确保使用 Go 1.21+，slog 是标准库

**Q: 测试覆盖率不够**  
A: 重点测试核心逻辑，可以跳过一些简单的 getter/setter

**Q: 日志太多**  
A: 使用 `-log-level warn` 减少输出

### 获取帮助

- 📖 查看完整计划: `下一步迭代计划_v3.0.md`
- 💬 提交 Issue
- 📧 联系维护者

---

**开始时间**: 现在！  
**预计完成**: 5个工作日后  
**收益**: 极大提升可维护性和可调试性

**让我们开始吧！** 🚀

