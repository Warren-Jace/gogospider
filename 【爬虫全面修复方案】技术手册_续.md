# ğŸ”§ çˆ¬è™«ç¨‹åºå…¨é¢ä¿®å¤æ–¹æ¡ˆ - æŠ€æœ¯æ‰‹å†Œï¼ˆç»­ï¼‰

> æ¥ä¸Šæ–‡ï¼šã€çˆ¬è™«å…¨é¢ä¿®å¤æ–¹æ¡ˆã€‘æŠ€æœ¯æ‰‹å†Œ.md

---

## 5) å¹¶å‘/é˜Ÿåˆ—ä¸èµ„æºæ§åˆ¶

### 5.1 çˆ¬å–é˜Ÿåˆ—ç»“æ„å»ºè®®

```go
package core

import (
	"container/list"
	"context"
	"sync"
)

// CrawlQueue çˆ¬å–é˜Ÿåˆ—ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
type CrawlQueue struct {
	queue    *list.List
	mu       sync.Mutex
	notEmpty *sync.Cond
	closed   bool
	maxSize  int
}

// CrawlItem çˆ¬å–é¡¹
type CrawlItem struct {
	URL      string
	Depth    int
	Priority int
	Metadata map[string]interface{}
}

// NewCrawlQueue åˆ›å»ºçˆ¬å–é˜Ÿåˆ—
func NewCrawlQueue(maxSize int) *CrawlQueue {
	q := &CrawlQueue{
		queue:   list.New(),
		maxSize: maxSize,
	}
	q.notEmpty = sync.NewCond(&q.mu)
	return q
}

// Push æ·»åŠ URLåˆ°é˜Ÿåˆ—
func (q *CrawlQueue) Push(item *CrawlItem) error {
	q.mu.Lock()
	defer q.mu.Unlock()
	
	if q.closed {
		return fmt.Errorf("queue is closed")
	}
	
	// æ£€æŸ¥é˜Ÿåˆ—å¤§å°é™åˆ¶
	if q.maxSize > 0 && q.queue.Len() >= q.maxSize {
		return fmt.Errorf("queue is full (size: %d)", q.queue.Len())
	}
	
	q.queue.PushBack(item)
	q.notEmpty.Signal() // é€šçŸ¥ç­‰å¾…çš„æ¶ˆè´¹è€…
	
	return nil
}

// Pop ä»é˜Ÿåˆ—å–å‡ºURLï¼ˆé˜»å¡ï¼‰
func (q *CrawlQueue) Pop(ctx context.Context) (*CrawlItem, error) {
	q.mu.Lock()
	defer q.mu.Unlock()
	
	for q.queue.Len() == 0 && !q.closed {
		// ç­‰å¾…é€šçŸ¥æˆ–ctxå–æ¶ˆ
		done := make(chan struct{})
		go func() {
			q.notEmpty.Wait()
			close(done)
		}()
		
		select {
		case <-done:
			// è¢«å”¤é†’ï¼Œç»§ç»­æ£€æŸ¥
		case <-ctx.Done():
			return nil, ctx.Err()
		}
	}
	
	if q.closed && q.queue.Len() == 0 {
		return nil, fmt.Errorf("queue is closed and empty")
	}
	
	element := q.queue.Front()
	q.queue.Remove(element)
	
	return element.Value.(*CrawlItem), nil
}

// TryPop éé˜»å¡Pop
func (q *CrawlQueue) TryPop() (*CrawlItem, bool) {
	q.mu.Lock()
	defer q.mu.Unlock()
	
	if q.queue.Len() == 0 {
		return nil, false
	}
	
	element := q.queue.Front()
	q.queue.Remove(element)
	
	return element.Value.(*CrawlItem), true
}

// Len è·å–é˜Ÿåˆ—é•¿åº¦
func (q *CrawlQueue) Len() int {
	q.mu.Lock()
	defer q.mu.Unlock()
	return q.queue.Len()
}

// Close å…³é—­é˜Ÿåˆ—
func (q *CrawlQueue) Close() {
	q.mu.Lock()
	defer q.mu.Unlock()
	
	q.closed = true
	q.notEmpty.Broadcast() // å”¤é†’æ‰€æœ‰ç­‰å¾…çš„goroutine
}

// IsClosed æ£€æŸ¥é˜Ÿåˆ—æ˜¯å¦å·²å…³é—­
func (q *CrawlQueue) IsClosed() bool {
	q.mu.Lock()
	defer q.mu.Unlock()
	return q.closed
}
```

### 5.2 Goroutineæ± 

```go
package core

import (
	"context"
	"sync"
	"time"
)

// WorkerPool Goroutineå·¥ä½œæ± 
type WorkerPool struct {
	workerCount int
	jobQueue    chan Job
	wg          sync.WaitGroup
	ctx         context.Context
	cancel      context.CancelFunc
	
	// ç»Ÿè®¡ä¿¡æ¯
	processedJobs int64
	failedJobs    int64
	mu            sync.Mutex
}

// Job å·¥ä½œä»»åŠ¡æ¥å£
type Job interface {
	Execute() error
}

// NewWorkerPool åˆ›å»ºå·¥ä½œæ± 
func NewWorkerPool(workerCount int, queueSize int) *WorkerPool {
	ctx, cancel := context.WithCancel(context.Background())
	
	return &WorkerPool{
		workerCount: workerCount,
		jobQueue:    make(chan Job, queueSize),
		ctx:         ctx,
		cancel:      cancel,
	}
}

// Start å¯åŠ¨å·¥ä½œæ± 
func (p *WorkerPool) Start() {
	for i := 0; i < p.workerCount; i++ {
		p.wg.Add(1)
		go p.worker(i)
	}
}

// worker å·¥ä½œgoroutine
func (p *WorkerPool) worker(id int) {
	defer p.wg.Done()
	
	for {
		select {
		case <-p.ctx.Done():
			return
			
		case job, ok := <-p.jobQueue:
			if !ok {
				return // é˜Ÿåˆ—å·²å…³é—­
			}
			
			// æ‰§è¡Œä»»åŠ¡
			err := job.Execute()
			
			p.mu.Lock()
			if err != nil {
				p.failedJobs++
			} else {
				p.processedJobs++
			}
			p.mu.Unlock()
		}
	}
}

// Submit æäº¤ä»»åŠ¡
func (p *WorkerPool) Submit(job Job) error {
	select {
	case p.jobQueue <- job:
		return nil
	case <-p.ctx.Done():
		return fmt.Errorf("worker pool is shutting down")
	default:
		return fmt.Errorf("job queue is full")
	}
}

// Shutdown å…³é—­å·¥ä½œæ± ï¼ˆç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼‰
func (p *WorkerPool) Shutdown() {
	close(p.jobQueue)
	p.wg.Wait()
}

// ShutdownNow ç«‹å³å…³é—­å·¥ä½œæ± 
func (p *WorkerPool) ShutdownNow() {
	p.cancel()
	p.wg.Wait()
}

// GetStats è·å–ç»Ÿè®¡ä¿¡æ¯
func (p *WorkerPool) GetStats() (processed, failed int64) {
	p.mu.Lock()
	defer p.mu.Unlock()
	return p.processedJobs, p.failedJobs
}
```

### 5.3 è¯·æ±‚é€Ÿç‡ä¸é‡è¯•ç­–ç•¥

```go
package core

import (
	"context"
	"fmt"
	"time"
)

// RateLimiter é€Ÿç‡é™åˆ¶å™¨ï¼ˆToken Bucketç®—æ³•ï¼‰
type RateLimiter struct {
	rate       int           // æ¯ç§’è¯·æ±‚æ•°
	burstSize  int           // çªå‘å¤§å°
	tokens     int           // å½“å‰ä»¤ç‰Œæ•°
	lastRefill time.Time     // ä¸Šæ¬¡å¡«å……æ—¶é—´
	mu         sync.Mutex
}

// NewRateLimiter åˆ›å»ºé€Ÿç‡é™åˆ¶å™¨
func NewRateLimiter(requestsPerSecond int, burstSize int) *RateLimiter {
	return &RateLimiter{
		rate:       requestsPerSecond,
		burstSize:  burstSize,
		tokens:     burstSize,
		lastRefill: time.Now(),
	}
}

// Allow æ£€æŸ¥æ˜¯å¦å…è®¸è¯·æ±‚ï¼ˆéé˜»å¡ï¼‰
func (r *RateLimiter) Allow() bool {
	r.mu.Lock()
	defer r.mu.Unlock()
	
	r.refill()
	
	if r.tokens > 0 {
		r.tokens--
		return true
	}
	
	return false
}

// Wait ç­‰å¾…ç›´åˆ°å…è®¸è¯·æ±‚ï¼ˆé˜»å¡ï¼‰
func (r *RateLimiter) Wait(ctx context.Context) error {
	for {
		if r.Allow() {
			return nil
		}
		
		// è®¡ç®—ç­‰å¾…æ—¶é—´
		waitTime := time.Second / time.Duration(r.rate)
		
		select {
		case <-time.After(waitTime):
			// ç»§ç»­å¾ªç¯
		case <-ctx.Done():
			return ctx.Err()
		}
	}
}

// refill å¡«å……ä»¤ç‰Œ
func (r *RateLimiter) refill() {
	now := time.Now()
	elapsed := now.Sub(r.lastRefill)
	
	// è®¡ç®—åº”è¯¥æ·»åŠ çš„ä»¤ç‰Œæ•°
	tokensToAdd := int(elapsed.Seconds() * float64(r.rate))
	
	if tokensToAdd > 0 {
		r.tokens += tokensToAdd
		if r.tokens > r.burstSize {
			r.tokens = r.burstSize
		}
		r.lastRefill = now
	}
}

// RetryStrategy é‡è¯•ç­–ç•¥
type RetryStrategy struct {
	maxRetries     int
	initialDelay   time.Duration
	maxDelay       time.Duration
	backoffFactor  float64
}

func NewRetryStrategy() *RetryStrategy {
	return &RetryStrategy{
		maxRetries:    3,
		initialDelay:  1 * time.Second,
		maxDelay:      30 * time.Second,
		backoffFactor: 2.0,
	}
}

// ExecuteWithRetry æ‰§è¡Œå‡½æ•°å¹¶è‡ªåŠ¨é‡è¯•
func (r *RetryStrategy) ExecuteWithRetry(ctx context.Context, fn func() error) error {
	var lastErr error
	delay := r.initialDelay
	
	for attempt := 0; attempt <= r.maxRetries; attempt++ {
		// æ‰§è¡Œå‡½æ•°
		err := fn()
		if err == nil {
			return nil // æˆåŠŸ
		}
		
		lastErr = err
		
		// æœ€åä¸€æ¬¡å°è¯•å¤±è´¥
		if attempt == r.maxRetries {
			break
		}
		
		// ç­‰å¾…åé‡è¯•
		select {
		case <-time.After(delay):
			// æŒ‡æ•°é€€é¿
			delay = time.Duration(float64(delay) * r.backoffFactor)
			if delay > r.maxDelay {
				delay = r.maxDelay
			}
		case <-ctx.Done():
			return ctx.Err()
		}
	}
	
	return fmt.Errorf("é‡è¯•%dæ¬¡åå¤±è´¥: %w", r.maxRetries, lastErr)
}
```

### 5.4 Domain-level Rate Limiting

```go
package core

import (
	"net/url"
	"sync"
	"time"
)

// DomainRateLimiter åŸŸåçº§åˆ«çš„é€Ÿç‡é™åˆ¶å™¨
type DomainRateLimiter struct {
	limiters map[string]*RateLimiter
	mu       sync.RWMutex
	
	defaultRate  int
	defaultBurst int
}

func NewDomainRateLimiter(defaultRate, defaultBurst int) *DomainRateLimiter {
	return &DomainRateLimiter{
		limiters:     make(map[string]*RateLimiter),
		defaultRate:  defaultRate,
		defaultBurst: defaultBurst,
	}
}

// Wait ç­‰å¾…ç›´åˆ°å…è®¸è¯·æ±‚æŒ‡å®šåŸŸå
func (d *DomainRateLimiter) Wait(ctx context.Context, targetURL string) error {
	parsedURL, err := url.Parse(targetURL)
	if err != nil {
		return err
	}
	
	domain := parsedURL.Host
	limiter := d.getLimiter(domain)
	
	return limiter.Wait(ctx)
}

// getLimiter è·å–æˆ–åˆ›å»ºåŸŸåå¯¹åº”çš„é™åˆ¶å™¨
func (d *DomainRateLimiter) getLimiter(domain string) *RateLimiter {
	// å…ˆå°è¯•è¯»é”
	d.mu.RLock()
	limiter, exists := d.limiters[domain]
	d.mu.RUnlock()
	
	if exists {
		return limiter
	}
	
	// éœ€è¦åˆ›å»ºï¼Œä½¿ç”¨å†™é”
	d.mu.Lock()
	defer d.mu.Unlock()
	
	// Double-check
	limiter, exists = d.limiters[domain]
	if exists {
		return limiter
	}
	
	// åˆ›å»ºæ–°é™åˆ¶å™¨
	limiter = NewRateLimiter(d.defaultRate, d.defaultBurst)
	d.limiters[domain] = limiter
	
	return limiter
}

// SetDomainRate è®¾ç½®ç‰¹å®šåŸŸåçš„é€Ÿç‡
func (d *DomainRateLimiter) SetDomainRate(domain string, rate, burst int) {
	d.mu.Lock()
	defer d.mu.Unlock()
	
	d.limiters[domain] = NewRateLimiter(rate, burst)
}
```

### 5.5 é˜²æ­¢å†…å­˜çˆ†ç‚¸æ§åˆ¶

```go
package core

import (
	"fmt"
	"runtime"
	"sync"
	"time"
)

// MemoryController å†…å­˜æ§åˆ¶å™¨
type MemoryController struct {
	maxMemoryMB   int64
	checkInterval time.Duration
	stopChan      chan struct{}
	mu            sync.Mutex
	
	// å›è°ƒå‡½æ•°ï¼ˆå†…å­˜è¶…é™æ—¶ï¼‰
	onMemoryExceeded func()
}

func NewMemoryController(maxMemoryMB int64) *MemoryController {
	return &MemoryController{
		maxMemoryMB:   maxMemoryMB,
		checkInterval: 10 * time.Second,
		stopChan:      make(chan struct{}),
	}
}

// Start å¯åŠ¨å†…å­˜ç›‘æ§
func (m *MemoryController) Start() {
	go m.monitorLoop()
}

// Stop åœæ­¢å†…å­˜ç›‘æ§
func (m *MemoryController) Stop() {
	close(m.stopChan)
}

// monitorLoop ç›‘æ§å¾ªç¯
func (m *MemoryController) monitorLoop() {
	ticker := time.NewTicker(m.checkInterval)
	defer ticker.Stop()
	
	for {
		select {
		case <-ticker.C:
			m.checkMemory()
		case <-m.stopChan:
			return
		}
	}
}

// checkMemory æ£€æŸ¥å†…å­˜ä½¿ç”¨
func (m *MemoryController) checkMemory() {
	var memStats runtime.MemStats
	runtime.ReadMemStats(&memStats)
	
	// è½¬æ¢ä¸ºMB
	allocMB := int64(memStats.Alloc / 1024 / 1024)
	
	if allocMB > m.maxMemoryMB {
		fmt.Printf("[è­¦å‘Š] å†…å­˜ä½¿ç”¨è¶…é™: %d MB > %d MB\n", allocMB, m.maxMemoryMB)
		
		// å¼ºåˆ¶GC
		runtime.GC()
		
		// è°ƒç”¨å›è°ƒ
		if m.onMemoryExceeded != nil {
			m.onMemoryExceeded()
		}
	}
}

// SetOnMemoryExceeded è®¾ç½®å†…å­˜è¶…é™å›è°ƒ
func (m *MemoryController) SetOnMemoryExceeded(fn func()) {
	m.mu.Lock()
	defer m.mu.Unlock()
	m.onMemoryExceeded = fn
}

// GetMemoryUsage è·å–å½“å‰å†…å­˜ä½¿ç”¨ï¼ˆMBï¼‰
func (m *MemoryController) GetMemoryUsage() int64 {
	var memStats runtime.MemStats
	runtime.ReadMemStats(&memStats)
	return int64(memStats.Alloc / 1024 / 1024)
}

// ResourcePool èµ„æºæ± ï¼ˆé™åˆ¶èµ„æºæ•°é‡ï¼‰
type ResourcePool struct {
	resources chan interface{}
	maxSize   int
}

func NewResourcePool(maxSize int) *ResourcePool {
	return &ResourcePool{
		resources: make(chan interface{}, maxSize),
		maxSize:   maxSize,
	}
}

// Acquire è·å–èµ„æº
func (p *ResourcePool) Acquire(ctx context.Context) error {
	select {
	case p.resources <- struct{}{}:
		return nil
	case <-ctx.Done():
		return ctx.Err()
	}
}

// Release é‡Šæ”¾èµ„æº
func (p *ResourcePool) Release() {
	<-p.resources
}

// Size å½“å‰èµ„æºæ•°é‡
func (p *ResourcePool) Size() int {
	return len(p.resources)
}
```

---

## 6) å®‰å…¨/åˆè§„æ³¨æ„

### 6.1 Robots.txtè§£æä¸éµå®ˆ

```go
package core

import (
	"bufio"
	"fmt"
	"net/http"
	"net/url"
	"regexp"
	"strings"
	"time"
)

// RobotsParser Robots.txtè§£æå™¨
type RobotsParser struct {
	userAgent string
	rules     map[string]*RobotRules
	mu        sync.RWMutex
}

// RobotRules Robotsè§„åˆ™
type RobotRules struct {
	disallowPaths []string
	allowPaths    []string
	crawlDelay    time.Duration
	sitemaps      []string
}

func NewRobotsParser(userAgent string) *RobotsParser {
	return &RobotsParser{
		userAgent: userAgent,
		rules:     make(map[string]*RobotRules),
	}
}

// FetchAndParse è·å–å¹¶è§£ærobots.txt
func (r *RobotsParser) FetchAndParse(baseURL string) error {
	// æ„å»ºrobots.txt URL
	parsedURL, err := url.Parse(baseURL)
	if err != nil {
		return err
	}
	
	robotsURL := parsedURL.Scheme + "://" + parsedURL.Host + "/robots.txt"
	
	// è·å–robots.txt
	resp, err := http.Get(robotsURL)
	if err != nil {
		// robots.txtä¸å­˜åœ¨ï¼Œé»˜è®¤å…è®¸æ‰€æœ‰
		return nil
	}
	defer resp.Body.Close()
	
	if resp.StatusCode == 404 {
		// robots.txtä¸å­˜åœ¨ï¼Œé»˜è®¤å…è®¸æ‰€æœ‰
		return nil
	}
	
	// è§£ærobots.txt
	rules := &RobotRules{
		disallowPaths: make([]string, 0),
		allowPaths:    make([]string, 0),
		sitemaps:      make([]string, 0),
	}
	
	scanner := bufio.NewScanner(resp.Body)
	inRelevantSection := false
	
	for scanner.Scan() {
		line := strings.TrimSpace(scanner.Text())
		
		// è·³è¿‡æ³¨é‡Šå’Œç©ºè¡Œ
		if line == "" || strings.HasPrefix(line, "#") {
			continue
		}
		
		// è§£æUser-agent
		if strings.HasPrefix(strings.ToLower(line), "user-agent:") {
			agent := strings.TrimSpace(line[11:])
			if agent == "*" || strings.Contains(strings.ToLower(r.userAgent), strings.ToLower(agent)) {
				inRelevantSection = true
			} else {
				inRelevantSection = false
			}
			continue
		}
		
		if !inRelevantSection {
			continue
		}
		
		// è§£æDisallow
		if strings.HasPrefix(strings.ToLower(line), "disallow:") {
			path := strings.TrimSpace(line[9:])
			if path != "" {
				rules.disallowPaths = append(rules.disallowPaths, path)
			}
		}
		
		// è§£æAllow
		if strings.HasPrefix(strings.ToLower(line), "allow:") {
			path := strings.TrimSpace(line[6:])
			if path != "" {
				rules.allowPaths = append(rules.allowPaths, path)
			}
		}
		
		// è§£æCrawl-delay
		if strings.HasPrefix(strings.ToLower(line), "crawl-delay:") {
			delayStr := strings.TrimSpace(line[12:])
			if delay, err := time.ParseDuration(delayStr + "s"); err == nil {
				rules.crawlDelay = delay
			}
		}
		
		// è§£æSitemap
		if strings.HasPrefix(strings.ToLower(line), "sitemap:") {
			sitemap := strings.TrimSpace(line[8:])
			rules.sitemaps = append(rules.sitemaps, sitemap)
		}
	}
	
	// ä¿å­˜è§„åˆ™
	r.mu.Lock()
	r.rules[parsedURL.Host] = rules
	r.mu.Unlock()
	
	return nil
}

// IsAllowed æ£€æŸ¥URLæ˜¯å¦å…è®¸çˆ¬å–
func (r *RobotsParser) IsAllowed(targetURL string) bool {
	parsedURL, err := url.Parse(targetURL)
	if err != nil {
		return false
	}
	
	r.mu.RLock()
	rules, exists := r.rules[parsedURL.Host]
	r.mu.RUnlock()
	
	if !exists {
		// æ²¡æœ‰robots.txtè§„åˆ™ï¼Œé»˜è®¤å…è®¸
		return true
	}
	
	path := parsedURL.Path
	if path == "" {
		path = "/"
	}
	
	// 1. æ£€æŸ¥Allowè§„åˆ™ï¼ˆä¼˜å…ˆçº§é«˜ï¼‰
	for _, allowPath := range rules.allowPaths {
		if matchesPath(path, allowPath) {
			return true
		}
	}
	
	// 2. æ£€æŸ¥Disallowè§„åˆ™
	for _, disallowPath := range rules.disallowPaths {
		if matchesPath(path, disallowPath) {
			return false
		}
	}
	
	// 3. é»˜è®¤å…è®¸
	return true
}

// GetCrawlDelay è·å–çˆ¬å–å»¶è¿Ÿ
func (r *RobotsParser) GetCrawlDelay(targetURL string) time.Duration {
	parsedURL, err := url.Parse(targetURL)
	if err != nil {
		return 0
	}
	
	r.mu.RLock()
	rules, exists := r.rules[parsedURL.Host]
	r.mu.RUnlock()
	
	if !exists {
		return 0
	}
	
	return rules.crawlDelay
}

// matchesPath æ£€æŸ¥è·¯å¾„æ˜¯å¦åŒ¹é…robots.txtè§„åˆ™
func matchesPath(path, pattern string) bool {
	// ç®€å•é€šé…ç¬¦åŒ¹é…
	// * åŒ¹é…ä»»æ„å­—ç¬¦
	// $ åŒ¹é…è¡Œå°¾
	
	// è½¬æ¢ä¸ºæ­£åˆ™è¡¨è¾¾å¼
	regexPattern := regexp.QuoteMeta(pattern)
	regexPattern = strings.ReplaceAll(regexPattern, `\*`, `.*`)
	regexPattern = strings.ReplaceAll(regexPattern, `\$`, `$`)
	
	matched, _ := regexp.MatchString("^"+regexPattern, path)
	return matched
}
```

### 6.2 æ•æ„Ÿæ•°æ®å­˜å‚¨ä¸è„±æ•

```go
package core

import (
	"crypto/aes"
	"crypto/cipher"
	"crypto/rand"
	"crypto/sha256"
	"encoding/base64"
	"errors"
	"io"
)

// SensitiveDataHandler æ•æ„Ÿæ•°æ®å¤„ç†å™¨
type SensitiveDataHandler struct {
	encryptionKey []byte
	gcm          cipher.AEAD
}

func NewSensitiveDataHandler(password string) (*SensitiveDataHandler, error) {
	// ä»å¯†ç ç”Ÿæˆå¯†é’¥
	key := sha256.Sum256([]byte(password))
	
	block, err := aes.NewCipher(key[:])
	if err != nil {
		return nil, err
	}
	
	gcm, err := cipher.NewGCM(block)
	if err != nil {
		return nil, err
	}
	
	return &SensitiveDataHandler{
		encryptionKey: key[:],
		gcm:          gcm,
	}, nil
}

// Encrypt åŠ å¯†æ•æ„Ÿæ•°æ®
func (h *SensitiveDataHandler) Encrypt(plaintext string) (string, error) {
	nonce := make([]byte, h.gcm.NonceSize())
	if _, err := io.ReadFull(rand.Reader, nonce); err != nil {
		return "", err
	}
	
	ciphertext := h.gcm.Seal(nonce, nonce, []byte(plaintext), nil)
	return base64.StdEncoding.EncodeToString(ciphertext), nil
}

// Decrypt è§£å¯†æ•æ„Ÿæ•°æ®
func (h *SensitiveDataHandler) Decrypt(ciphertext string) (string, error) {
	data, err := base64.StdEncoding.DecodeString(ciphertext)
	if err != nil {
		return "", err
	}
	
	nonceSize := h.gcm.NonceSize()
	if len(data) < nonceSize {
		return "", errors.New("ciphertext too short")
	}
	
	nonce, ciphertext := data[:nonceSize], data[nonceSize:]
	plaintext, err := h.gcm.Open(nil, nonce, ciphertext, nil)
	if err != nil {
		return "", err
	}
	
	return string(plaintext), nil
}

// Mask è„±æ•æ˜¾ç¤º
func Mask(value string) string {
	if len(value) <= 8 {
		return strings.Repeat("*", len(value))
	}
	
	// æ˜¾ç¤ºå‰4ä½å’Œå4ä½
	return value[:4] + strings.Repeat("*", len(value)-8) + value[len(value)-4:]
}

// SensitiveInfo æ•æ„Ÿä¿¡æ¯ï¼ˆå¢å¼ºç‰ˆï¼‰
type SensitiveInfoSecure struct {
	Type          string
	Value         string // è„±æ•åçš„å€¼
	EncryptedValue string // åŠ å¯†åçš„å®Œæ•´å€¼
	Location      string
	Severity      string
	SourceURL     string
	Timestamp     time.Time
}

// SaveSensitiveInfo å®‰å…¨ä¿å­˜æ•æ„Ÿä¿¡æ¯
func SaveSensitiveInfo(info *SensitiveInfo, handler *SensitiveDataHandler) (*SensitiveInfoSecure, error) {
	// åŠ å¯†å®Œæ•´å€¼
	encrypted, err := handler.Encrypt(info.FullValue)
	if err != nil {
		return nil, err
	}
	
	return &SensitiveInfoSecure{
		Type:          info.Type,
		Value:         Mask(info.FullValue), // è„±æ•æ˜¾ç¤º
		EncryptedValue: encrypted,            // åŠ å¯†å­˜å‚¨
		Location:      info.Location,
		Severity:      info.Severity,
		SourceURL:     info.SourceURL,
		Timestamp:     time.Now(),
	}, nil
}
```

---

## 7) å•å…ƒæµ‹è¯•/é›†æˆæµ‹è¯•å»ºè®®

### 7.1 å•å…ƒæµ‹è¯•æ¡†æ¶

```go
package core_test

import (
	"testing"
	"github.com/stretchr/testify/assert"
	"spider-golang/core"
)

// æ¨èä½¿ç”¨testifyåº“
// go get github.com/stretchr/testify
```

### 7.2 å…¸å‹æµ‹è¯•ç”¨ä¾‹ï¼ˆè‡³å°‘10ä¸ªï¼‰

```go
package core_test

import (
	"testing"
	"spider-golang/core"
)

// Test Case 1: URLè§„èŒƒåŒ– - é»˜è®¤ç«¯å£ç§»é™¤
func TestURLCanonicalizer_RemoveDefaultPort(t *testing.T) {
	tests := []struct {
		input    string
		expected string
	}{
		{"http://example.com:80/path", "http://example.com/path"},
		{"https://example.com:443/path", "https://example.com/path"},
		{"http://example.com:8080/path", "http://example.com:8080/path"}, // éé»˜è®¤ç«¯å£ä¿ç•™
	}
	
	c := core.NewURLCanonicalizer()
	
	for _, tt := range tests {
		t.Run(tt.input, func(t *testing.T) {
			result, err := c.CanonicalizeURL(tt.input)
			if err != nil {
				t.Errorf("Error: %v", err)
			}
			if result != tt.expected {
				t.Errorf("Got: %s, Expected: %s", result, tt.expected)
			}
		})
	}
}

// Test Case 2: URLè§„èŒƒåŒ– - IDNåŸŸå
func TestURLCanonicalizer_IDN(t *testing.T) {
	tests := []struct {
		input    string
		expected string
	}{
		{"https://ä¸­æ–‡.com/è·¯å¾„", "https://xn--fiq228c.com/%E8%B7%AF%E5%BE%84"},
		{"https://mÃ¼nchen.de/test", "https://xn--mnchen-3ya.de/test"},
	}
	
	c := core.NewURLCanonicalizer()
	
	for _, tt := range tests {
		t.Run(tt.input, func(t *testing.T) {
			result, err := c.CanonicalizeURL(tt.input)
			if err != nil {
				t.Errorf("Error: %v", err)
			}
			if result != tt.expected {
				t.Errorf("Got: %s, Expected: %s", result, tt.expected)
			}
		})
	}
}

// Test Case 3: URLè§„èŒƒåŒ– - å‚æ•°æ’åº
func TestURLCanonicalizer_QuerySort(t *testing.T) {
	tests := []struct {
		input    string
		expected string
	}{
		{
			"http://example.com?z=3&a=1&m=2",
			"http://example.com?a=1&m=2&z=3",
		},
		{
			"http://example.com?id=123&name=test&id=456",
			"http://example.com?id=123&id=456&name=test",
		},
	}
	
	c := core.NewURLCanonicalizer()
	
	for _, tt := range tests {
		t.Run(tt.input, func(t *testing.T) {
			result, err := c.CanonicalizeURL(tt.input)
			if err != nil {
				t.Errorf("Error: %v", err)
			}
			if result != tt.expected {
				t.Errorf("Got: %s, Expected: %s", result, tt.expected)
			}
		})
	}
}

// Test Case 4: Trackingå‚æ•°è¿‡æ»¤
func TestTrackingParamFilter_Filter(t *testing.T) {
	filter := core.NewTrackingParamFilter()
	
	tests := []struct {
		input    string
		expected string
	}{
		{
			"http://example.com?id=1&utm_source=google&name=test",
			"http://example.com?id=1&name=test",
		},
		{
			"http://example.com?gclid=abc123&fbclid=def456&id=1",
			"http://example.com?id=1",
		},
	}
	
	canonicalizer := core.NewURLCanonicalizer()
	
	for _, tt := range tests {
		t.Run(tt.input, func(t *testing.T) {
			result, err := canonicalizer.CanonicalizeURL(tt.input)
			if err != nil {
				t.Errorf("Error: %v", err)
			}
			if result != tt.expected {
				t.Errorf("Got: %s, Expected: %s", result, tt.expected)
			}
		})
	}
}

// Test Case 5: æ•æ„Ÿå‚æ•°æ£€æµ‹ - é¿å…è¯¯æŠ¥
func TestSensitiveParamDetector_NoFalsePositive(t *testing.T) {
	detector := core.NewSensitiveParamDetector()
	
	tests := []struct {
		paramName   string
		shouldFlag  bool
		description string
	}{
		{"video_id", false, "video_idä¸åº”è¢«æ ‡è®°ä¸ºæ•æ„Ÿ"},
		{"valid", false, "validä¸åº”è¢«æ ‡è®°ä¸ºæ•æ„Ÿ"},
		{"grid", false, "gridä¸åº”è¢«æ ‡è®°ä¸ºæ•æ„Ÿ"},
		{"id", true, "å•ç‹¬çš„idåº”è¢«æ ‡è®°"},
		{"user_id", true, "user_idåº”è¢«æ ‡è®°"},
		{"token", true, "tokenåº”è¢«æ ‡è®°ä¸ºæ•æ„Ÿ"},
		{"password", true, "passwordåº”è¢«æ ‡è®°ä¸ºæ•æ„Ÿ"},
	}
	
	for _, tt := range tests {
		t.Run(tt.description, func(t *testing.T) {
			result := detector.DetectParam(tt.paramName)
			if tt.shouldFlag && !result.IsSensitive {
				t.Errorf("%såº”è¢«æ ‡è®°ä¸ºæ•æ„Ÿä½†æœªæ ‡è®°", tt.paramName)
			}
			if !tt.shouldFlag && result.IsSensitive {
				t.Errorf("%sä¸åº”è¢«æ ‡è®°ä¸ºæ•æ„Ÿä½†è¢«æ ‡è®°äº†", tt.paramName)
			}
		})
	}
}

// Test Case 6: JWT Tokenæ£€æµ‹
func TestSensitiveParamDetector_JWTDetection(t *testing.T) {
	detector := core.NewSensitiveParamDetector()
	
	tests := []struct {
		value    string
		isJWT    bool
	}{
		{
			"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ.SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5c",
			true,
		},
		{"not-a-jwt-token", false},
		{"abc.def.ghi", false}, // æ ¼å¼åƒä½†å†…å®¹ä¸æ˜¯Base64
	}
	
	for _, tt := range tests {
		t.Run(tt.value[:20]+"...", func(t *testing.T) {
			result := detector.DetectParamValue("token", tt.value)
			if tt.isJWT && result.Type != "JWT_TOKEN" {
				t.Errorf("åº”æ£€æµ‹ä¸ºJWT token")
			}
			if !tt.isJWT && result.Type == "JWT_TOKEN" {
				t.Errorf("ä¸åº”æ£€æµ‹ä¸ºJWT token")
			}
		})
	}
}

// Test Case 7: å¹¶å‘å»é‡æµ‹è¯•
func TestConcurrentDeduplicator_ThreadSafe(t *testing.T) {
	dedup := core.NewConcurrentDeduplicator()
	
	var wg sync.WaitGroup
	urls := []string{
		"http://example.com/page1",
		"http://example.com/page2",
		"http://example.com/page1", // é‡å¤
	}
	
	// å¹¶å‘æ·»åŠ 
	for _, url := range urls {
		wg.Add(1)
		go func(u string) {
			defer wg.Done()
			dedup.IsDuplicate(u)
		}(url)
	}
	
	wg.Wait()
	
	// éªŒè¯å»é‡åæ•°é‡
	count := dedup.Count()
	if count != 2 {
		t.Errorf("å»é‡ååº”æœ‰2ä¸ªå”¯ä¸€URLï¼Œå®é™…: %d", count)
	}
}

// Test Case 8: é€Ÿç‡é™åˆ¶å™¨æµ‹è¯•
func TestRateLimiter_Basic(t *testing.T) {
	limiter := core.NewRateLimiter(10, 5) // 10 req/s, burst 5
	
	// å‰5ä¸ªè¯·æ±‚åº”ç«‹å³å…è®¸ï¼ˆburstï¼‰
	for i := 0; i < 5; i++ {
		if !limiter.Allow() {
			t.Errorf("Burstè¯·æ±‚ %d åº”è¢«å…è®¸", i)
		}
	}
	
	// ç¬¬6ä¸ªè¯·æ±‚åº”è¢«æ‹’ç»ï¼ˆéœ€è¦ç­‰å¾…ï¼‰
	if limiter.Allow() {
		t.Errorf("è¶…å‡ºburstçš„è¯·æ±‚åº”è¢«æ‹’ç»")
	}
	
	// ç­‰å¾…100msååº”å…è®¸1ä¸ªè¯·æ±‚
	time.Sleep(100 * time.Millisecond)
	if !limiter.Allow() {
		t.Errorf("ç­‰å¾…åçš„è¯·æ±‚åº”è¢«å…è®¸")
	}
}

// Test Case 9: Robots.txtè§£æ
func TestRobotsParser_Parse(t *testing.T) {
	parser := core.NewRobotsParser("TestBot")
	
	// æ¨¡æ‹Ÿrobots.txtå†…å®¹
	robotsTxt := `
User-agent: *
Disallow: /admin/
Disallow: /private/

User-agent: TestBot
Allow: /admin/public/
Crawl-delay: 2

Sitemap: http://example.com/sitemap.xml
`
	
	// è§£æï¼ˆè¿™é‡Œéœ€è¦mock HTTPå“åº”ï¼‰
	// å®é™…æµ‹è¯•ä¸­å¯ä»¥ä½¿ç”¨httpteståŒ…
	
	// æµ‹è¯•URLæ˜¯å¦å…è®¸
	tests := []struct {
		url     string
		allowed bool
	}{
		{"http://example.com/admin/secret", false},
		{"http://example.com/admin/public/page", true},
		{"http://example.com/public/page", true},
	}
	
	// TODO: å®ç°å®Œæ•´çš„æµ‹è¯•
}

// Test Case 10: Baseæ ‡ç­¾URLè§£æ
func TestURLResolver_BaseTag(t *testing.T) {
	resolver, _ := core.NewURLResolver("https://example.com/dir/page.html")
	
	// è®¾ç½®baseæ ‡ç­¾
	resolver.SetBaseHref("/api/v2/")
	
	tests := []struct {
		relativeURL string
		expected    string
	}{
		{"users", "https://example.com/api/v2/users"},
		{"../v1/data", "https://example.com/api/v1/data"},
		{"/absolute", "https://example.com/absolute"},
	}
	
	for _, tt := range tests {
		t.Run(tt.relativeURL, func(t *testing.T) {
			result, err := resolver.ResolveURL(tt.relativeURL)
			if err != nil {
				t.Errorf("Error: %v", err)
			}
			if result != tt.expected {
				t.Errorf("Got: %s, Expected: %s", result, tt.expected)
			}
		})
	}
}

// Test Case 11: å‚æ•°å€¼åˆ†ç±»æµ‹è¯•
func TestSmartParamDedup_ValueClassification(t *testing.T) {
	dedup := core.NewSmartParamDeduplicator(3, true)
	
	tests := []struct {
		value    string
		category string
	}{
		{"123", core.ValueTypeNumeric1_5},
		{"550e8400-e29b-41d4-a716-446655440000", core.ValueTypeUUID},
		{"5d41402abc4b2a76b9719d911017c592", core.ValueTypeMD5},
		{"admin", core.ValueTypeAlpha1_5},
		{"", core.ValueTypeEmpty},
	}
	
	for _, tt := range tests {
		t.Run(tt.value, func(t *testing.T) {
			category := dedup.classifyParamValue(tt.value)
			if category != tt.category {
				t.Errorf("Got: %s, Expected: %s", category, tt.category)
			}
		})
	}
}

// Test Case 12: HTML tokenizeræµ‹è¯•
func TestTokenBasedExtractor_ExtractURLs(t *testing.T) {
	extractor := core.TokenBasedExtractor{}
	
	html := `
<!DOCTYPE html>
<html>
<head>
	<base href="/api/v2/">
	<meta http-equiv="refresh" content="0;URL='http://redirect.com'" />
</head>
<body>
	<a href="users">Users</a>
	<img src="/images/logo.png" />
	<script src="app.js"></script>
</body>
</html>
`
	
	urls := extractor.ExtractURLsFromHTML(strings.NewReader(html))
	
	// éªŒè¯æå–çš„URLæ•°é‡å’Œå†…å®¹
	if len(urls) < 4 {
		t.Errorf("åº”è‡³å°‘æå–4ä¸ªURLï¼Œå®é™…: %d", len(urls))
	}
	
	// éªŒè¯å„ç±»URLæ˜¯å¦è¢«æå–
	contexts := make(map[string]bool)
	for _, u := range urls {
		contexts[u.Context] = true
	}
	
	expectedContexts := []string{"base", "meta-refresh", "link", "resource"}
	for _, ctx := range expectedContexts {
		if !contexts[ctx] {
			t.Errorf("æœªæå–åˆ°context: %s", ctx)
		}
	}
}
```

### 7.3 é›†æˆæµ‹è¯•ç¤ºä¾‹

```go
package integration_test

import (
	"context"
	"testing"
	"time"
	"spider-golang/core"
	"spider-golang/config"
)

// TestFullCrawlWorkflow å®Œæ•´çˆ¬å–æµç¨‹é›†æˆæµ‹è¯•
func TestFullCrawlWorkflow(t *testing.T) {
	// 1. å‡†å¤‡é…ç½®
	cfg := config.NewDefaultConfig()
	cfg.TargetURL = "http://testsite.local"
	cfg.DepthSettings.MaxDepth = 2
	
	// 2. åˆ›å»ºçˆ¬è™«
	spider := core.NewSpider(cfg)
	
	// 3. å¯åŠ¨çˆ¬å–
	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()
	
	err := spider.Start(ctx)
	if err != nil {
		t.Fatalf("çˆ¬å–å¤±è´¥: %v", err)
	}
	
	// 4. éªŒè¯ç»“æœ
	stats := spider.GetStatistics()
	
	if stats.TotalURLs == 0 {
		t.Error("æœªçˆ¬å–åˆ°ä»»ä½•URL")
	}
	
	if stats.UniqueURLs == 0 {
		t.Error("æœªå‘ç°ä»»ä½•å”¯ä¸€URL")
	}
	
	// éªŒè¯å»é‡ç”Ÿæ•ˆ
	if stats.DuplicateURLs < stats.TotalURLs/10 {
		t.Logf("è­¦å‘Š: å»é‡ç‡å¯èƒ½è¿‡ä½")
	}
}
```

---

## 8) æœ€å°å¯è¿è¡Œä»£ç ç‰‡æ®µ

### 8.1 canonicalizeï¼ˆURLè§„èŒƒåŒ–ï¼‰

```go
package main

import (
	"fmt"
	"net/url"
	"path"
	"sort"
	"strings"
	"golang.org/x/net/idna"
)

func canonicalizeURL(rawURL string) string {
	parsedURL, err := url.Parse(rawURL)
	if err != nil {
		return rawURL
	}
	
	// 1. åè®®å°å†™
	scheme := strings.ToLower(parsedURL.Scheme)
	
	// 2. åŸŸå - IDNè½¬Punycode + å°å†™
	host := parsedURL.Host
	hostPart, port := splitHostPort(host)
	
	// IDNå¤„ç†
	if needsPunycode(hostPart) {
		if punycoded, err := idna.ToASCII(hostPart); err == nil {
			hostPart = punycoded
		}
	}
	hostPart = strings.ToLower(hostPart)
	
	// ç§»é™¤é»˜è®¤ç«¯å£
	if (scheme == "http" && port == "80") || (scheme == "https" && port == "443") {
		port = ""
	}
	
	if port != "" {
		host = hostPart + ":" + port
	} else {
		host = hostPart
	}
	
	// 3. è·¯å¾„è§„èŒƒåŒ–
	pathStr := path.Clean(parsedURL.Path)
	if pathStr != "" && !strings.HasPrefix(pathStr, "/") {
		pathStr = "/" + pathStr
	}
	
	// 4. å‚æ•°æ’åº
	query := parsedURL.Query()
	keys := make([]string, 0, len(query))
	for k := range query {
		keys = append(keys, k)
	}
	sort.Strings(keys)
	
	var parts []string
	for _, k := range keys {
		values := query[k]
		sort.Strings(values)
		for _, v := range values {
			parts = append(parts, url.QueryEscape(k)+"="+url.QueryEscape(v))
		}
	}
	queryStr := strings.Join(parts, "&")
	
	// 5. é‡ç»„URL
	result := scheme + "://" + host + pathStr
	if queryStr != "" {
		result += "?" + queryStr
	}
	
	return result
}

func splitHostPort(hostport string) (host, port string) {
	if idx := strings.LastIndex(hostport, ":"); idx != -1 {
		return hostport[:idx], hostport[idx+1:]
	}
	return hostport, ""
}

func needsPunycode(host string) bool {
	for _, r := range host {
		if r > 127 {
			return true
		}
	}
	return false
}

func main() {
	tests := []string{
		"HTTP://Example.COM:80/path?b=2&a=1",
		"https://ä¸­æ–‡.com/è·¯å¾„",
		"http://example.com//api///users//",
	}
	
	for _, test := range tests {
		fmt.Printf("åŸURL: %s\n", test)
		fmt.Printf("è§„èŒƒ: %s\n\n", canonicalizeURL(test))
	}
}
```

### 8.2 extractParamsï¼ˆå‚æ•°æå–ï¼‰

```go
package main

import (
	"encoding/json"
	"fmt"
	"io"
	"net/url"
	"strings"
)

func extractParams(rawURL string) (map[string][]string, error) {
	parsedURL, err := url.Parse(rawURL)
	if err != nil {
		return nil, err
	}
	
	return parsedURL.Query(), nil
}

func extractJSONParams(jsonBody string) map[string][]string {
	var data map[string]interface{}
	if err := json.Unmarshal([]byte(jsonBody), &data); err != nil {
		return nil
	}
	
	params := make(map[string][]string)
	flattenJSON(data, "", params)
	return params
}

func flattenJSON(data interface{}, prefix string, result map[string][]string) {
	switch v := data.(type) {
	case map[string]interface{}:
		for key, val := range v {
			newPrefix := key
			if prefix != "" {
				newPrefix = prefix + "." + key
			}
			flattenJSON(val, newPrefix, result)
		}
	case []interface{}:
		for i, val := range v {
			newPrefix := prefix + "[" + fmt.Sprintf("%d", i) + "]"
			flattenJSON(val, newPrefix, result)
		}
	default:
		result[prefix] = append(result[prefix], fmt.Sprintf("%v", v))
	}
}

func main() {
	// Queryå‚æ•°æå–
	url1 := "http://example.com/api?id=123&name=test&tags=go&tags=web"
	params, _ := extractParams(url1)
	fmt.Println("Queryå‚æ•°:", params)
	
	// JSONå‚æ•°æå–
	jsonBody := `{"user": {"id": 1, "name": "Alice"}, "tags": ["go", "web"]}`
	jsonParams := extractJSONParams(jsonBody)
	fmt.Println("JSONå‚æ•°:", jsonParams)
}
```

### 8.3 isSensitiveParamï¼ˆæ•æ„Ÿå‚æ•°æ£€æµ‹ï¼‰

```go
package main

import (
	"fmt"
	"regexp"
	"strings"
)

type ParamSensitivity struct {
	ParamName   string
	IsSensitive bool
	Severity    string // HIGH, MEDIUM, LOW
	Category    string // auth, sensitive, dangerous
}

func isSensitiveParam(paramName string) *ParamSensitivity {
	paramLower := strings.ToLower(paramName)
	
	// é«˜å±è®¤è¯å‚æ•°
	highAuthParams := []string{"token", "access_token", "api_key", "apikey", "password", "passwd", "pwd", "secret"}
	for _, p := range highAuthParams {
		if paramLower == p {
			return &ParamSensitivity{
				ParamName:   paramName,
				IsSensitive: true,
				Severity:    "HIGH",
				Category:    "auth",
			}
		}
	}
	
	// ä¸­å±æ•æ„Ÿå‚æ•°
	mediumParams := []string{"email", "phone", "session", "session_id", "cookie"}
	for _, p := range mediumParams {
		if paramLower == p {
			return &ParamSensitivity{
				ParamName:   paramName,
				IsSensitive: true,
				Severity:    "MEDIUM",
				Category:    "sensitive",
			}
		}
	}
	
	// å±é™©æ“ä½œå‚æ•°ï¼ˆç²¾ç¡®åŒ¹é…ï¼‰
	dangerousParams := []string{"cmd", "command", "exec", "file", "path"}
	for _, p := range dangerousParams {
		if paramLower == p {
			return &ParamSensitivity{
				ParamName:   paramName,
				IsSensitive: true,
				Severity:    "HIGH",
				Category:    "dangerous",
			}
		}
	}
	
	// SQLæ³¨å…¥é£é™©ï¼ˆç²¾ç¡®åŒ¹é…ï¼Œé¿å…è¯¯æŠ¥ï¼‰
	if matched, _ := regexp.MatchString(`^(id|user_id|uid|account_id)$`, paramLower); matched {
		return &ParamSensitivity{
			ParamName:   paramName,
			IsSensitive: true,
			Severity:    "LOW",
			Category:    "sql",
		}
	}
	
	return &ParamSensitivity{
		ParamName:   paramName,
		IsSensitive: false,
	}
}

func main() {
	tests := []string{"token", "video_id", "valid", "id", "password", "email"}
	
	for _, param := range tests {
		result := isSensitiveParam(param)
		if result.IsSensitive {
			fmt.Printf("å‚æ•°: %s - æ•æ„Ÿ [%s/%s]\n", param, result.Severity, result.Category)
		} else {
			fmt.Printf("å‚æ•°: %s - æ­£å¸¸\n", param)
		}
	}
}
```

### 8.4 dedupeï¼ˆå»é‡ï¼‰

```go
package main

import (
	"crypto/sha256"
	"encoding/hex"
	"fmt"
	"sync"
)

type Deduplicator struct {
	seen sync.Map
}

func NewDeduplicator() *Deduplicator {
	return &Deduplicator{}
}

func (d *Deduplicator) IsDuplicate(url string) bool {
	// è®¡ç®—URLæŒ‡çº¹
	fingerprint := d.calculateFingerprint(url)
	
	// æ£€æŸ¥å¹¶è®¾ç½®ï¼ˆåŸå­æ“ä½œï¼‰
	_, loaded := d.seen.LoadOrStore(fingerprint, true)
	
	return loaded // trueè¡¨ç¤ºé‡å¤
}

func (d *Deduplicator) calculateFingerprint(url string) string {
	// è¿™é‡Œåº”å…ˆè§„èŒƒåŒ–URLï¼Œç„¶åè®¡ç®—å“ˆå¸Œ
	// ç®€åŒ–ç‰ˆæœ¬ç›´æ¥è®¡ç®—
	hash := sha256.Sum256([]byte(url))
	return hex.EncodeToString(hash[:])
}

func main() {
	dedup := NewDeduplicator()
	
	urls := []string{
		"http://example.com/page1",
		"http://example.com/page2",
		"http://example.com/page1", // é‡å¤
		"http://example.com/page3",
	}
	
	for _, url := range urls {
		if dedup.IsDuplicate(url) {
			fmt.Printf("é‡å¤: %s\n", url)
		} else {
			fmt.Printf("æ–°URL: %s\n", url)
		}
	}
}
```

---

## 9) ä¼˜å…ˆçº§ä¸è¿­ä»£è®¡åˆ’

### 9.1 å¿«é€Ÿä¿®å¤ï¼ˆP0 - ç«‹å³æ‰§è¡Œï¼Œ1å‘¨å†…ï¼‰

| ä¼˜å…ˆçº§ | é—®é¢˜ | ä¿®å¤æ–¹æ¡ˆ | é¢„è®¡æ—¶é—´ | é£é™© |
|--------|------|----------|---------|------|
| **P0-1** | ç¼ºå°‘`<base>`æ ‡ç­¾æ”¯æŒ | å®ç°`URLResolver`ï¼Œåœ¨HTMLè§£ææ—¶æå–base | 1å¤© | ä½ |
| **P0-2** | Trackingå‚æ•°æœªè¿‡æ»¤å¯¼è‡´é‡å¤çˆ¬å– | å®ç°`TrackingParamFilter` | 0.5å¤© | ä½ |
| **P0-3** | URLè§„èŒƒåŒ–ä¸å®Œæ•´ | å®Œå–„`URLCanonicalizer`ï¼ˆIDNã€å»é‡æ–œæ ã€é»˜è®¤ç«¯å£ï¼‰ | 2å¤© | ä¸­ |
| **P0-4** | æ•æ„Ÿå‚æ•°æ£€æµ‹è¯¯æŠ¥é«˜ | ä¿®å¤`SensitiveParamDetector`ï¼Œä½¿ç”¨ç²¾ç¡®åŒ¹é… | 1å¤© | ä½ |
| **P0-5** | æ•æ„Ÿæ•°æ®æœªåŠ å¯†å­˜å‚¨ | å®ç°`SensitiveDataHandler`ï¼ŒåŠ å¯†å­˜å‚¨ | 1å¤© | ä½ |

**æ€»è®¡**ï¼š5.5å¤©

### 9.2 é‡è¦æ”¹è¿›ï¼ˆP1 - 2å‘¨å†…ï¼‰

| ä¼˜å…ˆçº§ | é—®é¢˜ | ä¿®å¤æ–¹æ¡ˆ | é¢„è®¡æ—¶é—´ | é£é™© |
|--------|------|----------|---------|------|
| **P1-1** | HTMLè§£æä½¿ç”¨æ­£åˆ™ | è¿ç§»åˆ°`golang.org/x/net/html` tokenizer | 2å¤© | ä¸­ |
| **P1-2** | JSåŠ¨æ€URLæå–ä¸å®Œæ•´ | å®ç°`EnhancedJSAnalyzer` | 2å¤© | ä¸­ |
| **P1-3** | ç¼ºå°‘robots.txtæ”¯æŒ | å®ç°`RobotsParser` | 1å¤© | ä½ |
| **P1-4** | å¹¶å‘å»é‡å¯èƒ½ä¸å®‰å…¨ | ä½¿ç”¨`sync.Map`æ›¿æ¢æ™®é€šmap | 0.5å¤© | ä½ |
| **P1-5** | ç¼ºå°‘domain-levelé™é€Ÿ | å®ç°`DomainRateLimiter` | 1å¤© | ä½ |

**æ€»è®¡**ï¼š6.5å¤©

### 9.3 é•¿æœŸä¼˜åŒ–ï¼ˆP2 - 1ä¸ªæœˆå†…ï¼‰

| ä¼˜å…ˆçº§ | åŠŸèƒ½ | æ–¹æ¡ˆ | é¢„è®¡æ—¶é—´ | ä»·å€¼ |
|--------|------|------|---------|------|
| **P2-1** | Headlessæµè§ˆå™¨æ”¯æŒ | é›†æˆchromedpï¼ŒæŒ‰éœ€å¯ç”¨ | 3å¤© | é«˜ |
| **P2-2** | å®Œæ•´çš„æµ‹è¯•è¦†ç›– | ç¼–å†™å•å…ƒæµ‹è¯•+é›†æˆæµ‹è¯• | 5å¤© | é«˜ |
| **P2-3** | æ€§èƒ½ç›‘æ§ä¸ä¼˜åŒ– | å®ç°`MemoryController`ã€æ€§èƒ½profiling | 2å¤© | ä¸­ |
| **P2-4** | é…ç½®æ–‡ä»¶åŒ– | å°†ç¡¬ç¼–ç é…ç½®è¿ç§»åˆ°JSON | 2å¤© | ä¸­ |
| **P2-5** | æ—¥å¿—ä¸ç›‘æ§å¢å¼º | ç»“æ„åŒ–æ—¥å¿—ã€å®æ—¶ç›‘æ§Dashboard | 3å¤© | ä¸­ |

**æ€»è®¡**ï¼š15å¤©

### 9.4 è¿­ä»£è·¯çº¿å›¾

```
Week 1-2: P0å¿«é€Ÿä¿®å¤ï¼ˆå…³é”®bugï¼‰
â”œâ”€â”€ Day 1-2: URLè§„èŒƒåŒ–å®Œå–„
â”œâ”€â”€ Day 3: Baseæ ‡ç­¾æ”¯æŒ
â”œâ”€â”€ Day 4: Trackingå‚æ•°è¿‡æ»¤
â”œâ”€â”€ Day 5: æ•æ„Ÿå‚æ•°æ£€æµ‹ä¿®å¤
â””â”€â”€ Day 6-7: æ•æ„Ÿæ•°æ®åŠ å¯† + æµ‹è¯•

Week 3-4: P1é‡è¦æ”¹è¿›
â”œâ”€â”€ Day 8-9: HTML tokenizerè¿ç§»
â”œâ”€â”€ Day 10-11: JSåˆ†æå™¨å¢å¼º
â”œâ”€â”€ Day 12: Robots.txtæ”¯æŒ
â”œâ”€â”€ Day 13: å¹¶å‘å®‰å…¨ä¿®å¤
â””â”€â”€ Day 14: Domainé™é€Ÿå®ç°

Week 5-8: P2é•¿æœŸä¼˜åŒ–
â”œâ”€â”€ Week 5: Headlessæµè§ˆå™¨é›†æˆ
â”œâ”€â”€ Week 6-7: æµ‹è¯•è¦†ç›–ä¸CI/CD
â””â”€â”€ Week 8: æ€§èƒ½ä¼˜åŒ–ä¸ç›‘æ§
```

### 9.5 å‰¯ä½œç”¨ä¸å…¼å®¹æ€§é—®é¢˜

#### æ½œåœ¨å‰¯ä½œç”¨

1. **URLè§„èŒƒåŒ–å¯èƒ½æ”¹å˜ç°æœ‰å»é‡é€»è¾‘**
   - **å½±å“**ï¼šä¹‹å‰è¢«è®¤ä¸ºä¸åŒçš„URLå¯èƒ½å˜æˆç›¸åŒ
   - **ç¼“è§£**ï¼šæä¾›é…ç½®å¼€å…³ï¼Œå…è®¸é€æ­¥è¿ç§»

2. **Trackingå‚æ•°è¿‡æ»¤å¯èƒ½è¯¯åˆ æœ‰ç”¨å‚æ•°**
   - **å½±å“**ï¼šæŸäº›ç½‘ç«™å¯èƒ½ä½¿ç”¨"ref"ä½œä¸ºä¸šåŠ¡å‚æ•°
   - **ç¼“è§£**ï¼šæä¾›ç™½åå•é…ç½®ï¼Œå…è®¸ä¿ç•™ç‰¹å®šå‚æ•°

3. **Robots.txtéµå®ˆå¯èƒ½å‡å°‘çˆ¬å–è¦†ç›–ç‡**
   - **å½±å“**ï¼šæŸäº›URLå¯èƒ½è¢«ç¦æ­¢
   - **ç¼“è§£**ï¼šæä¾›é…ç½®å¼€å…³ï¼Œå¯é€‰æ‹©æ€§éµå®ˆ

4. **æ•æ„Ÿå‚æ•°æ£€æµ‹ä¿®å¤åå¯èƒ½æ¼æŠ¥**
   - **å½±å“**ï¼šä»å®½æ¾æ”¹ä¸ºä¸¥æ ¼ï¼Œå¯èƒ½æ¼æ‰ä¸€äº›è¾¹ç¼˜æƒ…å†µ
   - **ç¼“è§£**ï¼šä¿ç•™å¯é…ç½®çš„è‡ªå®šä¹‰è§„åˆ™

#### å…¼å®¹æ€§ä¿è¯

1. **å‘åå…¼å®¹**ï¼š
   - æ‰€æœ‰æ–°åŠŸèƒ½é€šè¿‡é…ç½®å¼€å…³æ§åˆ¶
   - é»˜è®¤è¡Œä¸ºä¿æŒä¸å˜ï¼Œéœ€æ‰‹åŠ¨å¯ç”¨æ–°åŠŸèƒ½

2. **æ¸è¿›å¼è¿ç§»**ï¼š
   ```json
   {
     "url_normalization": {
       "enabled": true,
       "features": {
         "idn_punycode": true,
         "remove_default_port": true,
         "remove_duplicate_slashes": true,
         "sort_query_params": true,
         "remove_tracking_params": false  // é»˜è®¤å…³é—­ï¼Œç”¨æˆ·é€‰æ‹©å¯ç”¨
       }
     }
   }
   ```

3. **æµ‹è¯•è¦†ç›–**ï¼š
   - æ¯ä¸ªæ–°åŠŸèƒ½éƒ½æœ‰å¯¹åº”çš„å•å…ƒæµ‹è¯•
   - å›å½’æµ‹è¯•ç¡®ä¿ä¸ç ´åç°æœ‰åŠŸèƒ½

---

## 10) éªŒè¯ç”¨çš„ç¤ºä¾‹URLåˆ—è¡¨

```
# åŸºç¡€URLè§„èŒƒåŒ–æµ‹è¯•
http://Example.COM:80/path          # åŸŸåå¤§å°å†™ã€é»˜è®¤ç«¯å£
https://ä¸­æ–‡.com/è·¯å¾„                 # IDNåŸŸå
http://example.com//api///users//   # é‡å¤æ–œæ 

# Trackingå‚æ•°è¿‡æ»¤æµ‹è¯•
http://example.com/page?id=1&utm_source=google&utm_medium=cpc
http://example.com/page?id=1&gclid=abc123&fbclid=def456

# å‚æ•°æ’åºæµ‹è¯•
http://example.com?z=3&a=1&m=2      # åº”æ’åºä¸º ?a=1&m=2&z=3

# Baseæ ‡ç­¾æµ‹è¯•
<base href="/api/v2/">
<a href="users">                    # åº”è§£æä¸º /api/v2/users

# æ•æ„Ÿå‚æ•°æ£€æµ‹æµ‹è¯•
?token=abc123                       # é«˜å±
?video_id=123                       # æ­£å¸¸ï¼ˆä¸åº”è¯¯æŠ¥ï¼‰
?password=secret                    # é«˜å±
?valid=true                         # æ­£å¸¸ï¼ˆä¸åº”è¯¯æŠ¥ï¼‰

# JWTæ£€æµ‹æµ‹è¯•
eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIn0.dozjgNryP4J3jVmNHl0w5N_XgL0n3I9PlFUP0THsR8U

# URLæå–æµ‹è¯•ï¼ˆJSä»£ç ï¼‰
fetch('/api/users')
axios.get('/api/products')
import('./module.js')
new URL('/path', location.origin)

# HTML tokenizeræµ‹è¯•
<meta http-equiv="refresh" content="0;URL='http://redirect.com'" />
<link rel="stylesheet" href="/css/style.css" />
<img src="data:image/png;base64,..." />  # åº”è¿‡æ»¤data URL

# Robots.txtæµ‹è¯•
Disallow: /admin/
Allow: /admin/public/

# å¹¶å‘æµ‹è¯•URLï¼ˆé‡å¤ï¼‰
http://example.com/page1
http://example.com/page1
http://example.com/page1
```

---

## æ€»ç»“

æœ¬ä¿®å¤æ–¹æ¡ˆæ¶µç›–äº†çˆ¬è™«ç¨‹åºçš„æ ¸å¿ƒé—®é¢˜ï¼š

1. âœ… **é“¾æ¥æå–**ï¼šBaseæ ‡ç­¾æ”¯æŒã€HTML tokenizerã€JSå¢å¼ºåˆ†æ
2. âœ… **URLè§„èŒƒåŒ–**ï¼šIDNã€å»é‡æ–œæ ã€é»˜è®¤ç«¯å£ã€å‚æ•°æ’åºã€Trackingè¿‡æ»¤
3. âœ… **å‚æ•°å¤„ç†**ï¼šQuery/POST/JSONæå–ã€æ•æ„Ÿæ£€æµ‹ï¼ˆä½è¯¯æŠ¥ï¼‰
4. âœ… **è¿‡æ»¤ç­–ç•¥**ï¼šå¹¶å‘å®‰å…¨å»é‡ã€ç™½é»‘åå•ã€å¯å‘å¼è§„åˆ™
5. âœ… **å¹¶å‘æ§åˆ¶**ï¼šWorkeræ± ã€é€Ÿç‡é™åˆ¶ã€å†…å­˜æ§åˆ¶
6. âœ… **å®‰å…¨åˆè§„**ï¼šRobots.txtã€æ•æ„Ÿæ•°æ®åŠ å¯†
7. âœ… **æµ‹è¯•è¦†ç›–**ï¼š12ä¸ªå…¸å‹æµ‹è¯•ç”¨ä¾‹
8. âœ… **å¯è¿è¡Œä»£ç **ï¼š4ä¸ªæ ¸å¿ƒåŠŸèƒ½ç‰‡æ®µ
9. âœ… **è¿­ä»£è®¡åˆ’**ï¼šP0-P2ä¼˜å…ˆçº§ï¼Œæ˜ç¡®æ—¶é—´çº¿

**å»ºè®®æ‰§è¡Œé¡ºåº**ï¼šP0 -> P1 -> P2

**å…³é”®ä¾èµ–**ï¼š
```bash
go get golang.org/x/net/html
go get golang.org/x/net/idna
go get github.com/stretchr/testify
# å¯é€‰
go get github.com/chromedp/chromedp
```

æ‰€æœ‰ä»£ç ç‰‡æ®µå‡å¯ç›´æ¥å¤åˆ¶ä½¿ç”¨ï¼Œé…ç½®æ–‡ä»¶æä¾›äº†çµæ´»æ€§ï¼Œæµ‹è¯•ç”¨ä¾‹ç¡®ä¿è´¨é‡ã€‚

