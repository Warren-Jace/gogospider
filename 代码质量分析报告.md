# Spider-golang çˆ¬è™«ç³»ç»Ÿ - å…¨é¢åˆ†ææŠ¥å‘Š

## ğŸ“‹ æ‰§è¡Œæ‘˜è¦

ä½œä¸ºçˆ¬è™«ä¸“å®¶ï¼Œæˆ‘å¯¹å½“å‰çš„ Spider-golang é¡¹ç›®è¿›è¡Œäº†å…¨é¢å®¡æŸ¥ã€‚è¯¥é¡¹ç›®å…·æœ‰å¼ºå¤§çš„åŠŸèƒ½å’Œè‰¯å¥½çš„æ¶æ„åŸºç¡€ï¼Œä½†å­˜åœ¨ä¸€äº›éœ€è¦ä¼˜åŒ–çš„å…³é”®é—®é¢˜ã€‚

**å½“å‰çŠ¶æ€**: ğŸŸ¡ **è‰¯å¥½ï¼Œä½†éœ€æ”¹è¿›** (7/10)

---

## âš ï¸ ä¸¥é‡é—®é¢˜ (å¿…é¡»ä¿®å¤)

### 1. **èµ„æºæ³„æ¼é£é™©** âŒ é«˜ä¼˜å…ˆçº§

**é—®é¢˜**: ç¼ºå°‘èµ„æºæ¸…ç†æœºåˆ¶ï¼Œå¯èƒ½å¯¼è‡´å†…å­˜æ³„æ¼å’Œ goroutine æ³„æ¼

```go
// core/spider.go - NewSpider()
resultChan := make(chan Result, 100)
stopChan := make(chan struct{})
// âŒ è¿™äº› channel ä»æœªè¢«å…³é—­
```

**å½±å“**:
- é•¿æ—¶é—´è¿è¡Œå¯èƒ½å¯¼è‡´å†…å­˜æ³„æ¼
- Goroutine å¯èƒ½æ°¸ä¹…æŒ‚èµ·
- æ— æ³•ä¼˜é›…å…³é—­ç¨‹åº

**å»ºè®®ä¿®å¤**:
```go
// åœ¨ Spider ç»“æ„ä½“ä¸­æ·»åŠ 
type Spider struct {
    // ... ç°æœ‰å­—æ®µ
    done chan struct{}
    wg   sync.WaitGroup
}

// åœ¨ Start() ä¸­ä½¿ç”¨ defer
func (s *Spider) Start(targetURL string) error {
    defer close(s.done)
    defer s.wg.Wait()
    // ... ç°æœ‰ä»£ç 
}
```

---

### 2. **Context ç®¡ç†ä¸å½“** âŒ é«˜ä¼˜å…ˆçº§

**é—®é¢˜**: DynamicCrawler ä¸­çš„ context ç”Ÿå‘½å‘¨æœŸç®¡ç†æ··ä¹±

```go
// core/dynamic_crawler.go
func NewDynamicCrawler() *DynamicCrawlerImpl {
    ctx, cancel := context.WithTimeout(context.Background(), 180*time.Second)
    return &DynamicCrawlerImpl{
        ctx:    ctx,     // âŒ è¿™ä¸ª context ä¼šåœ¨ 180 ç§’åè‡ªåŠ¨è¶…æ—¶
        cancel: cancel,
    }
}
```

**å½±å“**:
- 180ç§’åæ‰€æœ‰æ“ä½œä¼šå¤±è´¥
- cancel å‡½æ•°å¯èƒ½è¢«å¤šæ¬¡è°ƒç”¨ï¼ˆpanicé£é™©ï¼‰
- æ— æ³•æ§åˆ¶å•ä¸ªè¯·æ±‚çš„è¶…æ—¶

**å»ºè®®ä¿®å¤**:
```go
// æ¯æ¬¡ Crawl æ—¶åˆ›å»ºæ–°çš„ context
func (d *DynamicCrawlerImpl) Crawl(targetURL *url.URL) (*Result, error) {
    // ä½¿ç”¨çˆ¶ context è€Œéå…±äº«çš„å›ºå®š context
    ctx, cancel := context.WithTimeout(context.Background(), d.timeout)
    defer cancel()
    // ...
}
```

---

### 3. **é”™è¯¯å¤„ç†ä¸ä¸€è‡´** âš ï¸ ä¸­ä¼˜å…ˆçº§

**é—®é¢˜**: é”™è¯¯åªæ˜¯æ‰“å°ï¼Œæ²¡æœ‰ä¼ æ’­æˆ–è®°å½•

```go
// core/spider.go:209-210
if err != nil {
    fmt.Printf("é™æ€çˆ¬è™«é”™è¯¯: %v\n", err)  // âŒ é”™è¯¯è¢«åæ‰
}
```

**å½±å“**:
- æ— æ³•è¯Šæ–­å¤±è´¥åŸå› 
- é”™è¯¯æ—¥å¿—æ··ä¹±
- éš¾ä»¥ç›‘æ§å’Œå‘Šè­¦

**å»ºè®®ä¿®å¤**:
```go
// ä½¿ç”¨ç»“æ„åŒ–æ—¥å¿—
import "log/slog"

if err != nil {
    slog.Error("é™æ€çˆ¬è™«å¤±è´¥",
        "url", targetURL,
        "error", err,
        "depth", depth)
    // å¯é€‰ï¼šç´¯ç§¯é”™è¯¯ç»Ÿè®¡
    s.stats.IncrementErrors()
}
```

---

### 4. **å¹¶å‘å®‰å…¨é—®é¢˜** âš ï¸ ä¸­ä¼˜å…ˆçº§

**é—®é¢˜**: å¤šå¤„å­˜åœ¨æ½œåœ¨çš„ç«æ€æ¡ä»¶

```go
// core/spider.go:237-239
if len(paramFuzzURLs) > 1 && len(s.results) > 0 {
    s.mutex.Lock()
    s.results[0].Links = append(...)  // âš ï¸ æ£€æŸ¥å’Œä¿®æ”¹ä¹‹é—´æ²¡æœ‰é”
    s.mutex.Unlock()
}
```

**å»ºè®®ä¿®å¤**:
```go
s.mutex.Lock()
if len(s.results) > 0 && len(paramFuzzURLs) > 1 {
    s.results[0].Links = append(...)
}
s.mutex.Unlock()
```

---

## ğŸ”§ æ¶æ„é—®é¢˜

### 5. **é…ç½®ç®¡ç†ä¸çµæ´»** âš ï¸

**é—®é¢˜**:
- é…ç½®ç»“æ„è¿‡äºåµŒå¥—ï¼ˆ`config.StrategySettings.EnableStaticCrawler`ï¼‰
- ç¼ºå°‘é…ç½®éªŒè¯
- æ²¡æœ‰é…ç½®æ–‡ä»¶åŠ è½½åŠŸèƒ½

**å»ºè®®**:
```go
// æ·»åŠ é…ç½®éªŒè¯
func (c *Config) Validate() error {
    if c.TargetURL == "" {
        return errors.New("ç›®æ ‡URLä¸èƒ½ä¸ºç©º")
    }
    if c.DepthSettings.MaxDepth < 0 {
        return errors.New("æœ€å¤§æ·±åº¦ä¸èƒ½ä¸ºè´Ÿæ•°")
    }
    return nil
}
```

---

### 6. **æ—¥å¿—ç³»ç»Ÿæ··ä¹±** âš ï¸

**é—®é¢˜**:
- åŒæ—¶ä½¿ç”¨ `fmt.Printf` å’Œ `log.*`
- æ²¡æœ‰æ—¥å¿—çº§åˆ«æ§åˆ¶
- æ— æ³•åŒºåˆ†è°ƒè¯•ä¿¡æ¯å’Œé”™è¯¯ä¿¡æ¯
- è¾“å‡ºæ ¼å¼ä¸ç»Ÿä¸€

**å½“å‰çŠ¶æ€**:
```go
fmt.Printf("å¼€å§‹çˆ¬å–URL: %s\n", targetURL)  // ä¿¡æ¯
fmt.Printf("é™æ€çˆ¬è™«é”™è¯¯: %v\n", err)        // é”™è¯¯
log.Fatalf("çˆ¬å–å¤±è´¥: %v", err)              // è‡´å‘½é”™è¯¯
```

**å»ºè®®ä¿®å¤**:
```go
// ä½¿ç”¨ç»“æ„åŒ–æ—¥å¿—åº“
import (
    "log/slog"
    "os"
)

// åœ¨åˆå§‹åŒ–æ—¶é…ç½®
func init() {
    logger := slog.New(slog.NewJSONHandler(os.Stdout, &slog.HandlerOptions{
        Level: slog.LevelInfo,
    }))
    slog.SetDefault(logger)
}

// ä½¿ç”¨ç¤ºä¾‹
slog.Info("å¼€å§‹çˆ¬å–", "url", targetURL, "depth", maxDepth)
slog.Error("çˆ¬å–å¤±è´¥", "url", targetURL, "error", err)
slog.Debug("è§£æHTML", "links", linkCount)
```

---

### 7. **ç¼ºå°‘ç›‘æ§å’ŒæŒ‡æ ‡** ğŸ“Š

**é—®é¢˜**: æ— æ³•äº†è§£çˆ¬è™«è¿è¡ŒçŠ¶æ€

**å»ºè®®æ·»åŠ **:
```go
type CrawlerStats struct {
    TotalRequests    int64
    SuccessRequests  int64
    FailedRequests   int64
    TotalURLs        int64
    TotalForms       int64
    TotalAPIs        int64
    StartTime        time.Time
    RequestsPerSec   float64
    AvgResponseTime  time.Duration
}

func (s *Spider) GetStats() *CrawlerStats {
    // è¿”å›å®æ—¶ç»Ÿè®¡
}
```

---

## ğŸš€ æ€§èƒ½é—®é¢˜

### 8. **å†…å­˜ç®¡ç†æ¬ ä½³** ğŸ’¾

**é—®é¢˜**:
- ä¿å­˜æ‰€æœ‰ HTML å†…å®¹åˆ°å†…å­˜ (`result.HTMLContent`)
- æ— å†…å­˜ä½¿ç”¨ä¸Šé™
- å¤§å‹ç½‘ç«™å¯èƒ½å¯¼è‡´ OOM

**å»ºè®®**:
```go
// åªä¿å­˜å¿…è¦ä¿¡æ¯ï¼ŒHTML å¯é€‰
type Result struct {
    URL         string
    StatusCode  int
    // HTMLContent string  // âŒ åˆ é™¤æˆ–æ”¹ä¸ºå¯é€‰
    HTMLDigest  string    // âœ… åªä¿å­˜æ‘˜è¦/å“ˆå¸Œ
}

// å¯é€‰ï¼šå¤§HTMLå†™å…¥ä¸´æ—¶æ–‡ä»¶
if len(htmlContent) > 1*1024*1024 { // > 1MB
    s.saveToDisk(url, htmlContent)
}
```

---

### 9. **Worker Pool æ•ˆç‡é—®é¢˜** âš™ï¸

**é—®é¢˜**:
```go
// core/spider.go:902
layerWorkerPool := NewWorkerPool(30, 20)  // âŒ æ¯å±‚åˆ›å»ºæ–°çš„ pool
```

**å½±å“**:
- é‡å¤åˆ›å»º/é”€æ¯ goroutine
- èµ„æºæµªè´¹

**å»ºè®®**:
```go
// å¤ç”¨å…¨å±€ worker pool
func (s *Spider) Start(targetURL string) error {
    defer s.workerPool.Stop()  // ç¡®ä¿æ¸…ç†
    // ...
}
```

---

### 10. **HTTP å®¢æˆ·ç«¯æœªå¤ç”¨** ğŸŒ

**é—®é¢˜**: æ¯æ¬¡è¯·æ±‚å¯èƒ½åˆ›å»ºæ–°è¿æ¥

**å»ºè®®**:
```go
// åœ¨ Spider åˆå§‹åŒ–æ—¶åˆ›å»ºå…±äº«çš„ HTTP å®¢æˆ·ç«¯
var httpClient = &http.Client{
    Timeout: 30 * time.Second,
    Transport: &http.Transport{
        MaxIdleConns:        100,
        MaxIdleConnsPerHost: 10,
        IdleConnTimeout:     90 * time.Second,
    },
}
```

---

## ğŸ›¡ï¸ å®‰å…¨é—®é¢˜

### 11. **ç¼ºå°‘è¾“å…¥éªŒè¯** ğŸ”’

**é—®é¢˜**: URL å’Œå‚æ•°æ²¡æœ‰å……åˆ†éªŒè¯

**å»ºè®®**:
```go
func validateURL(rawURL string) error {
    parsed, err := url.Parse(rawURL)
    if err != nil {
        return fmt.Errorf("æ— æ•ˆURL: %w", err)
    }
    
    // æ£€æŸ¥åè®®
    if parsed.Scheme != "http" && parsed.Scheme != "https" {
        return fmt.Errorf("ä¸æ”¯æŒçš„åè®®: %s", parsed.Scheme)
    }
    
    // é˜²æ­¢ SSRF
    if isPrivateIP(parsed.Host) && !allowPrivateIPs {
        return fmt.Errorf("ç¦æ­¢è®¿é—®å†…ç½‘åœ°å€")
    }
    
    return nil
}
```

---

### 12. **æ•æ„Ÿä¿¡æ¯å¯èƒ½æ³„æ¼** ğŸ”

**é—®é¢˜**: Cookieã€Headers å¯èƒ½è¢«è®°å½•åˆ°æ—¥å¿—/æ–‡ä»¶

**å»ºè®®**:
```go
// æ•æ„Ÿå­—æ®µè„±æ•
func sanitizeHeaders(headers map[string]string) map[string]string {
    sensitive := []string{"Cookie", "Authorization", "X-API-Key"}
    result := make(map[string]string)
    for k, v := range headers {
        if contains(sensitive, k) {
            result[k] = "***REDACTED***"
        } else {
            result[k] = v
        }
    }
    return result
}
```

---

## ğŸ§ª æµ‹è¯•é—®é¢˜

### 13. **å®Œå…¨ç¼ºå°‘æµ‹è¯•** âŒ

**å½±å“**: æ— æ³•ä¿è¯ä»£ç è´¨é‡å’Œé‡æ„å®‰å…¨

**å»ºè®®æ·»åŠ **:
```go
// core/spider_test.go
func TestSpiderBasicCrawl(t *testing.T) {
    // ä½¿ç”¨ httptest åˆ›å»ºæµ‹è¯•æœåŠ¡å™¨
    ts := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        w.Write([]byte(`<html><a href="/test">Test</a></html>`))
    }))
    defer ts.Close()
    
    cfg := config.NewDefaultConfig()
    cfg.TargetURL = ts.URL
    
    spider := NewSpider(cfg)
    err := spider.Start(ts.URL)
    
    assert.NoError(t, err)
    results := spider.GetResults()
    assert.Greater(t, len(results), 0)
}
```

---

## ğŸ“ ä»£ç è´¨é‡é—®é¢˜

### 14. **ä»£ç é‡å¤** ğŸ”

**é—®é¢˜**: å¤šå¤„ç›¸ä¼¼çš„é”™è¯¯å¤„ç†ã€æ—¥å¿—è¾“å‡º

**å»ºè®®**:
```go
// æå–é€šç”¨å‡½æ•°
func (s *Spider) crawlWithFallback(url *url.URL) (*Result, error) {
    result, err := s.staticCrawler.Crawl(url)
    if err != nil && s.config.StrategySettings.EnableDynamicCrawler {
        slog.Warn("é™æ€çˆ¬è™«å¤±è´¥ï¼Œå°è¯•åŠ¨æ€çˆ¬è™«", "url", url, "error", err)
        result, err = s.dynamicCrawler.Crawl(url)
    }
    return result, err
}
```

---

### 15. **Magic Numbers** ğŸ”¢

**é—®é¢˜**: ç¡¬ç¼–ç çš„æ•°å­—æ•£å¸ƒåœ¨ä»£ç ä¸­

```go
// âŒ Bad
layerWorkerPool := NewWorkerPool(30, 20)
if len(htmlContent) > 1*1024*1024 {
```

**å»ºè®®**:
```go
// âœ… Good
const (
    DefaultWorkerCount = 30
    DefaultMaxQPS      = 20
    MaxHTMLSize        = 1 * 1024 * 1024  // 1MB
)
```

---

### 16. **æ¥å£ä½¿ç”¨ä¸å……åˆ†** ğŸ”Œ

**é—®é¢˜**: å¾ˆå¤šç»„ä»¶ç›´æ¥ä¾èµ–å…·ä½“å®ç°ï¼Œéš¾ä»¥æµ‹è¯•å’Œæ›¿æ¢

**å»ºè®®**:
```go
// å®šä¹‰æ¥å£
type Logger interface {
    Info(msg string, args ...any)
    Error(msg string, args ...any)
    Debug(msg string, args ...any)
}

type Spider struct {
    logger Logger  // å¯æ³¨å…¥ï¼Œæ–¹ä¾¿æµ‹è¯•
}
```

---

## ğŸ“š æ–‡æ¡£é—®é¢˜

### 17. **API æ–‡æ¡£ä¸è¶³** ğŸ“–

**å»ºè®®**:
```go
// Spider æ˜¯ä¸»çˆ¬è™«åè°ƒå™¨ï¼Œè´Ÿè´£ç®¡ç†é™æ€å’ŒåŠ¨æ€çˆ¬è™«ï¼Œ
// å¤„ç†URLå»é‡ã€å‚æ•°çˆ†ç ´ã€è¡¨å•å¤„ç†ç­‰åŠŸèƒ½ã€‚
//
// ä½¿ç”¨ç¤ºä¾‹:
//   cfg := config.NewDefaultConfig()
//   cfg.TargetURL = "https://example.com"
//   spider := NewSpider(cfg)
//   if err := spider.Start(cfg.TargetURL); err != nil {
//       log.Fatal(err)
//   }
//   results := spider.GetResults()
type Spider struct {
    // ...
}
```

---

## âœ… ä¼˜ç‚¹æ€»ç»“

### åšå¾—å¥½çš„åœ°æ–¹ ğŸ‘

1. **åŠŸèƒ½ä¸°å¯Œ**: æ”¯æŒé™æ€/åŠ¨æ€çˆ¬è™«ã€JSåˆ†æã€å‚æ•°çˆ†ç ´ç­‰
2. **æ¨¡å—åŒ–è®¾è®¡**: å„ç»„ä»¶èŒè´£æ¸…æ™°
3. **å¹¶å‘å¤„ç†**: ä½¿ç”¨ Worker Pool ç®¡ç†å¹¶å‘
4. **æ™ºèƒ½å»é‡**: æ”¯æŒ DOM ç›¸ä¼¼åº¦æ£€æµ‹
5. **æ‰©å±•æ€§**: æ˜“äºæ·»åŠ æ–°çš„çˆ¬è™«ç­–ç•¥

---

## ğŸ¯ æ”¹è¿›ä¼˜å…ˆçº§

### P0 - ç«‹å³ä¿®å¤
- [ ] ä¿®å¤èµ„æºæ³„æ¼é—®é¢˜ï¼ˆchannelã€goroutineï¼‰
- [ ] ä¿®å¤ context ç®¡ç†é—®é¢˜
- [ ] æ·»åŠ åŸºæœ¬çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—

### P1 - è¿‘æœŸæ”¹è¿›
- [ ] æ·»åŠ é…ç½®éªŒè¯
- [ ] å®ç°ç»“æ„åŒ–æ—¥å¿—
- [ ] ä¿®å¤å¹¶å‘å®‰å…¨é—®é¢˜
- [ ] ä¼˜åŒ–å†…å­˜ä½¿ç”¨

### P2 - é•¿æœŸä¼˜åŒ–
- [ ] æ·»åŠ å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•
- [ ] æ·»åŠ æ€§èƒ½ç›‘æ§
- [ ] å®Œå–„ API æ–‡æ¡£
- [ ] é‡æ„é‡å¤ä»£ç 

---

## ğŸ”¨ å»ºè®®çš„é‡æ„æ­¥éª¤

### ç¬¬ä¸€é˜¶æ®µï¼šä¿®å¤ä¸¥é‡é—®é¢˜ï¼ˆ1-2å¤©ï¼‰
1. å®ç°ä¼˜é›…å…³é—­æœºåˆ¶
2. ä¿®å¤ context ç”Ÿå‘½å‘¨æœŸ
3. ç»Ÿä¸€é”™è¯¯å¤„ç†

### ç¬¬äºŒé˜¶æ®µï¼šè´¨é‡æå‡ï¼ˆ3-5å¤©ï¼‰
1. å®ç°ç»“æ„åŒ–æ—¥å¿—ç³»ç»Ÿ
2. æ·»åŠ é…ç½®éªŒè¯å’ŒåŠ è½½
3. ä¼˜åŒ–å†…å­˜ç®¡ç†
4. æ·»åŠ æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•

### ç¬¬ä¸‰é˜¶æ®µï¼šåŠŸèƒ½å¢å¼ºï¼ˆ1-2å‘¨ï¼‰
1. æ·»åŠ ç›‘æ§æŒ‡æ ‡
2. å®ç°æ–­ç‚¹ç»­çˆ¬
3. æ”¯æŒåˆ†å¸ƒå¼çˆ¬å–
4. æ€§èƒ½è°ƒä¼˜

---

## ğŸ“Š ä»£ç è´¨é‡è¯„åˆ†

| ç»´åº¦ | è¯„åˆ† | è¯´æ˜ |
|-----|------|------|
| åŠŸèƒ½å®Œæ•´æ€§ | 9/10 | âœ… åŠŸèƒ½ä¸°å¯Œ |
| æ¶æ„è®¾è®¡ | 7/10 | âš ï¸ æ¨¡å—åŒ–å¥½ä½†è€¦åˆåº¦é«˜ |
| é”™è¯¯å¤„ç† | 4/10 | âŒ é”™è¯¯å¤„ç†ä¸å……åˆ† |
| èµ„æºç®¡ç† | 3/10 | âŒ å­˜åœ¨æ³„æ¼é£é™© |
| æµ‹è¯•è¦†ç›– | 0/10 | âŒ å®Œå…¨ç¼ºå¤± |
| æ–‡æ¡£è´¨é‡ | 5/10 | âš ï¸ æœ‰ README ä½† API æ–‡æ¡£ä¸è¶³ |
| æ€§èƒ½ä¼˜åŒ– | 6/10 | âš ï¸ æœ‰ä¼˜åŒ–ä½†ä¸å¤Ÿ |
| ä»£ç è§„èŒƒ | 6/10 | âš ï¸ åŸºæœ¬éµå¾ªä½†ä¸ä¸€è‡´ |
| **ç»¼åˆè¯„åˆ†** | **6.3/10** | ğŸŸ¡ **è‰¯å¥½ï¼Œéœ€æ”¹è¿›** |

---

## ğŸ“ æœ€ä½³å®è·µå»ºè®®

### 1. éµå¾ª Go æƒ¯ç”¨æ³•
```go
// âœ… Good: è¿”å›é”™è¯¯è€Œé panic
func process() error {
    if err := doSomething(); err != nil {
        return fmt.Errorf("å¤„ç†å¤±è´¥: %w", err)
    }
    return nil
}

// âŒ Bad: ä½¿ç”¨ panic
func process() {
    if err := doSomething(); err != nil {
        panic(err)
    }
}
```

### 2. ä½¿ç”¨ Context ä¼ é€’
```go
// âœ… Good: ä¼ é€’ context
func (s *Spider) Crawl(ctx context.Context, url string) error {
    // å¯ä»¥å–æ¶ˆæ“ä½œ
}
```

### 3. å®ç° Closer æ¥å£
```go
type Spider struct { ... }

func (s *Spider) Close() error {
    close(s.done)
    s.wg.Wait()
    return s.cleanup()
}
```

---

## ğŸ“Œ æ€»ç»“

Spider-golang æ˜¯ä¸€ä¸ª**åŠŸèƒ½å¼ºå¤§**çš„çˆ¬è™«é¡¹ç›®ï¼Œåœ¨ URL å‘ç°å’Œæ™ºèƒ½åˆ†ææ–¹é¢è¡¨ç°å‡ºè‰²ã€‚ä½†åœ¨**å·¥ç¨‹è´¨é‡**æ–¹é¢è¿˜æœ‰è¾ƒå¤§æå‡ç©ºé—´ã€‚

**æ ¸å¿ƒå»ºè®®**:
1. ğŸ”´ **ç«‹å³ä¿®å¤èµ„æºæ³„æ¼å’Œ context ç®¡ç†é—®é¢˜**
2. ğŸŸ¡ **å°½å¿«æ·»åŠ æµ‹è¯•å’Œæ”¹è¿›æ—¥å¿—ç³»ç»Ÿ**
3. ğŸŸ¢ **æŒç»­ä¼˜åŒ–æ€§èƒ½å’Œä»£ç è´¨é‡**

é€šè¿‡ç³»ç»Ÿæ€§çš„æ”¹è¿›ï¼Œè¯¥é¡¹ç›®æœ‰æ½œåŠ›æˆä¸º**ç”Ÿäº§çº§åˆ«**çš„ä¸“ä¸šçˆ¬è™«å·¥å…·ã€‚

---

**æŠ¥å‘Šæ—¥æœŸ**: 2025-10-24  
**åˆ†æè€…**: çˆ¬è™«æ¶æ„ä¸“å®¶  
**ç‰ˆæœ¬**: Spider-golang v2.5

